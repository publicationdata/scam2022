{"type":{"0":"R","1":"R","2":"W","3":"W","4":"W","5":"W","6":"W","7":"R","8":"R","9":"R","10":"R","11":"R","12":"R","13":"R","14":"R","15":"R","16":"R","17":"R","18":"R","19":"R","20":"R","21":"R","22":"R","23":"R","24":"R","25":"R","26":"R","27":"R","28":"R","29":"R","30":"R","31":"R","32":"R","33":"R","34":"R","35":"R","36":"R","37":"R","38":"R","39":"R","40":"R","41":"R","42":"R","43":"R"},"module":{"0":"imagenet_utils","1":"mobilenet","2":"mobilenet","3":"mobilenet","4":"mobilenet","5":"mobilenet","6":"mobilenet","7":"xception","8":"xception","9":"xception","10":"xception","11":"xception","12":"xception","13":"xception","14":"xception","15":"xception","16":"xception","17":"xception","18":"xception","19":"xception","20":"xception","21":"xception","22":"xception","23":"xception","24":"xception","25":"xception","26":"xception","27":"xception","28":"xception","29":"xception","30":"xception","31":"xception","32":"xception","33":"xception","34":"xception","35":"xception","36":"xception","37":"xception","38":"xception","39":"xception","40":"xception","41":"xception","42":"xception","43":"xception"},"obj":{"0":"decode_predictions","1":"DepthwiseConv2D.compute_output_shape","2":"DepthwiseConv2D.build","3":"DepthwiseConv2D.build","4":"DepthwiseConv2D.build","5":"DepthwiseConv2D.build","6":"DepthwiseConv2D.build","7":"","8":"","9":"","10":"","11":"","12":"","13":"","14":"","15":"","16":"","17":"","18":"","19":"","20":"","21":"","22":"","23":"","24":"","25":"","26":"","27":"","28":"","29":"","30":"","31":"","32":"","33":"","34":"","35":"","36":"","37":"","38":"","39":"","40":"","41":"","42":"","43":""},"lnum":{"0":42,"1":261,"2":222,"3":230,"4":236,"5":238,"6":239,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"17":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1},"col":{"0":32,"1":4,"2":8,"3":12,"4":12,"5":8,"6":8,"7":0,"8":0,"9":0,"10":0,"11":0,"12":0,"13":0,"14":0,"15":0,"16":0,"17":0,"18":0,"19":0,"20":0,"21":0,"22":0,"23":0,"24":0,"25":0,"26":0,"27":0,"28":0,"29":0,"30":0,"31":0,"32":0,"33":0,"34":0,"35":0,"36":0,"37":0,"38":0,"39":0,"40":0,"41":0,"42":0,"43":0},"filename":{"0":"imagenet_utils.py","1":"mobilenet.py","2":"mobilenet.py","3":"mobilenet.py","4":"mobilenet.py","5":"mobilenet.py","6":"mobilenet.py","7":"xception.py","8":"xception.py","9":"xception.py","10":"xception.py","11":"xception.py","12":"xception.py","13":"xception.py","14":"xception.py","15":"xception.py","16":"xception.py","17":"xception.py","18":"xception.py","19":"xception.py","20":"xception.py","21":"xception.py","22":"xception.py","23":"xception.py","24":"xception.py","25":"xception.py","26":"xception.py","27":"xception.py","28":"xception.py","29":"xception.py","30":"xception.py","31":"xception.py","32":"xception.py","33":"xception.py","34":"xception.py","35":"xception.py","36":"xception.py","37":"xception.py","38":"xception.py","39":"xception.py","40":"xception.py","41":"xception.py","42":"xception.py","43":"xception.py"},"symbol":{"0":"consider-using-with","1":"inconsistent-return-statements","2":"attribute-defined-outside-init","3":"attribute-defined-outside-init","4":"attribute-defined-outside-init","5":"attribute-defined-outside-init","6":"attribute-defined-outside-init","7":"duplicate-code","8":"duplicate-code","9":"duplicate-code","10":"duplicate-code","11":"duplicate-code","12":"duplicate-code","13":"duplicate-code","14":"duplicate-code","15":"duplicate-code","16":"duplicate-code","17":"duplicate-code","18":"duplicate-code","19":"duplicate-code","20":"duplicate-code","21":"duplicate-code","22":"duplicate-code","23":"duplicate-code","24":"duplicate-code","25":"duplicate-code","26":"duplicate-code","27":"duplicate-code","28":"duplicate-code","29":"duplicate-code","30":"duplicate-code","31":"duplicate-code","32":"duplicate-code","33":"duplicate-code","34":"duplicate-code","35":"duplicate-code","36":"duplicate-code","37":"duplicate-code","38":"duplicate-code","39":"duplicate-code","40":"duplicate-code","41":"duplicate-code","42":"duplicate-code","43":"duplicate-code"},"text":{"0":"Consider using 'with' for resource-allocating operations","1":"Either all return statements in a function should return an expression, or none of them should.","2":"Attribute 'depthwise_kernel' defined outside __init__","3":"Attribute 'bias' defined outside __init__","4":"Attribute 'bias' defined outside __init__","5":"Attribute 'input_spec' defined outside __init__","6":"Attribute 'built' defined outside __init__","7":"Similar lines in 2 files\n==vgg16:36\n==vgg19:34\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG19 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=\"channels_last\"` in your Keras config\n    at ~\/.keras\/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=48,\n                                      data_format=K.image_data_format(),\n                                      include_top=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)","8":"Similar lines in 3 files\n==resnet50:126\n==vgg16:36\n==vgg19:34\n          input_tensor=None, input_shape=None,\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG16 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=\"channels_last\"` in your Keras config\n    at ~\/.keras\/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape","9":"Similar lines in 2 files\n==inception_v3:90\n==resnet50:127\n             pooling=None,\n             classes=1000):\n    \"\"\"Instantiates the ResNet50 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=\"channels_last\"` in your Keras config\n    at ~\/.keras\/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 197.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape","10":"Similar lines in 3 files\n==inception_v3:90\n==vgg16:37\n==vgg19:35\n          pooling=None,\n          classes=1000):\n    \"\"\"Instantiates the VGG19 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=\"channels_last\"` in your Keras config\n    at ~\/.keras\/keras.json.\n\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 48.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n    # Determine proper input shape","11":"Similar lines in 2 files\n==inception_resnet_v2:182\n==inception_v3:87\n                weights='imagenet',\n                input_tensor=None,\n                input_shape=None,\n                pooling=None,\n                classes=1000):\n    \"\"\"Instantiates the Inception v3 architecture.\n\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=\"channels_last\"` in your Keras config\n    at ~\/.keras\/keras.json.\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n    Note that the default input image size for this model is 299x299.\n\n    Arguments:\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or \"imagenet\" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(299, 299, 3)` (with `channels_last` data format)\n            or `(3, 299, 299)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 139.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n\n    Returns:\n        A Keras model instance.\n\n    Raises:\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"","12":"Similar lines in 2 files\n==vgg16:167\n==vgg19:168\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='block5_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~\/.keras\/keras.json.')\n    return model\n\n\nif __name__ == '__main__':","13":"Similar lines in 2 files\n==vgg16:136\n==vgg19:137\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    if include_top:\n        # Classification block\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.","14":"Similar lines in 2 files\n==inception_resnet_v2:339\n==inception_v3:341\n    if include_top:\n        # Classification block\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n","15":"Similar lines in 3 files\n==resnet50:273\n==vgg16:178\n==vgg19:179\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~\/.keras\/keras.json.')\n    return model\n\n\nif __name__ == '__main__':","16":"Similar lines in 3 files\n==inception_resnet_v2:341\n==inception_v3:343\n==xception:230\n        x = GlobalAveragePooling2D(name='avg_pool')(x)\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.","17":"Similar lines in 2 files\n==inception_resnet_v2:241\n==inception_v3:141\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(\n        input_shape,\n        default_size=299,\n        min_size=139,\n        data_format=K.image_data_format(),","18":"Similar lines in 2 files\n==vgg16:17\n==vgg19:15\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras import backend as K\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.engine.topology import get_source_inputs\n\n","19":"Similar lines in 5 files\n==inception_resnet_v2:342\n==inception_v3:344\n==vgg16:143\n==vgg19:144\n==xception:231\n        x = Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.","20":"Similar lines in 2 files\n==inception_resnet_v2:343\n==mobilenet:472\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n\n    # Create model","21":"Similar lines in 7 files\n==inception_resnet_v2:343\n==inception_v3:345\n==mobilenet:472\n==resnet50:237\n==vgg16:144\n==vgg19:145\n==xception:232\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n","22":"Similar lines in 2 files\n==inception_v3:345\n==mobilenet:472\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.","23":"Similar lines in 2 files\n==inception_resnet_v2:360\n==inception_v3:361\n    if weights == 'imagenet':\n        if K.image_data_format() == 'channels_first':\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~\/.keras\/keras.json.')\n        if include_top:","24":"Similar lines in 3 files\n==vgg16:100\n==vgg19:98\n==xception:132\n                                      data_format=K.image_data_format(),\n                                      include_top=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    # Block 1","25":"Similar lines in 2 files\n==inception_v3:387\n==xception:261\n    return model\n\n\ndef preprocess_input(x):\n    x \/= 255.\n    x -= 0.5\n    x *= 2.\n    return x\n\n\nif __name__ == '__main__':","26":"Similar lines in 4 files\n==resnet50:191\n==vgg16:100\n==vgg19:98\n==xception:132\n                                      data_format=K.image_data_format(),\n                                      include_top=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor","27":"Similar lines in 2 files\n==inception_resnet_v2:241\n==resnet50:178\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape","28":"Similar lines in 2 files\n==resnet50:290\n==vgg16:195\n    img_path = 'elephant.jpg'\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    print('Input image shape:', x.shape)\n\n    preds = model.predict(x)\n    print('Predicted:', decode_predictions(preds))","29":"Similar lines in 6 files\n==inception_resnet_v2:241\n==inception_v3:141\n==resnet50:178\n==vgg16:88\n==vgg19:86\n==xception:101\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n","30":"Similar lines in 5 files\n==inception_resnet_v2:362\n==inception_v3:363\n==resnet50:275\n==vgg16:180\n==vgg19:181\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~\/.keras\/keras.json.')","31":"Similar lines in 2 files\n==inception_resnet_v2:391\n==inception_v3:400\n    img_path = 'elephant.jpg'\n    img = image.load_img(img_path, target_size=(299, 299))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    x = preprocess_input(x)\n\n    preds = model.predict(x)\n    print('Predicted:', decode_predictions(preds))","32":"Similar lines in 3 files\n==resnet50:291\n==vgg16:196\n==vgg19:197\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    print('Input image shape:', x.shape)\n\n    preds = model.predict(x)\n    print('Predicted:', decode_predictions(preds))","33":"Similar lines in 2 files\n==mobilenet:657\n==xception:276\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    print('Input image shape:', x.shape)\n\n    preds = model.predict(x)\n    print(np.argmax(preds))\n    print('Predicted:', decode_predictions(preds, 1))","34":"Similar lines in 2 files\n==mobilenet:513\n==xception:256\n                                    cache_subdir='models')\n        model.load_weights(weights_path)\n\n    if old_data_format:\n        K.set_image_data_format(old_data_format)\n    return model\n\n","35":"Similar lines in 5 files\n==inception_resnet_v2:259\n==mobilenet:428\n==vgg16:103\n==vgg19:101\n==xception:135\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n","36":"Similar lines in 2 files\n==mobilenet:421\n==xception:121\n                      'The model being returned right now will expect inputs '\n                      'to follow the \"channels_last\" data format.')\n        K.set_image_data_format('channels_last')\n        old_data_format = 'channels_first'\n    else:\n        old_data_format = None\n","37":"Similar lines in 3 files\n==inception_v3:390\n==mobilenet:90\n==xception:264\ndef preprocess_input(x):\n    x \/= 255.\n    x -= 0.5\n    x *= 2.\n    return x\n\n","38":"Similar lines in 2 files\n==inception_resnet_v2:15\n==xception:19\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport warnings\nimport numpy as np\n\nfrom keras.preprocessing import image","39":"Similar lines in 3 files\n==inception_resnet_v2:259\n==mobilenet:428\n==resnet50:194\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor","40":"Similar lines in 3 files\n==resnet50:264\n==vgg16:169\n==vgg19:170\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:","41":"Similar lines in 5 files\n==mobilenet:657\n==resnet50:292\n==vgg16:197\n==vgg19:198\n==xception:276\n                x = image.img_to_array(img)\n                x = np.expand_dims(x, axis=0)\n                x = preprocess_input(x)\n                print('Input image shape:', x.shape)\n\n                preds = model.predict(x)","42":"Similar lines in 5 files\n==inception_v3:155\n==resnet50:191\n==vgg16:100\n==vgg19:98\n==xception:132\n        data_format=K.image_data_format(),\n        include_top=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:","43":"Similar lines in 7 files\n==inception_resnet_v2:241\n==inception_v3:141\n==mobilenet:375\n==resnet50:178\n==vgg16:88\n==vgg19:86\n==xception:101\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and include_top and classes != 1000:"},"number":{"0":"R1732","1":"R1710","2":"W0201","3":"W0201","4":"W0201","5":"W0201","6":"W0201","7":"R0801","8":"R0801","9":"R0801","10":"R0801","11":"R0801","12":"R0801","13":"R0801","14":"R0801","15":"R0801","16":"R0801","17":"R0801","18":"R0801","19":"R0801","20":"R0801","21":"R0801","22":"R0801","23":"R0801","24":"R0801","25":"R0801","26":"R0801","27":"R0801","28":"R0801","29":"R0801","30":"R0801","31":"R0801","32":"R0801","33":"R0801","34":"R0801","35":"R0801","36":"R0801","37":"R0801","38":"R0801","39":"R0801","40":"R0801","41":"R0801","42":"R0801","43":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint","36":"pylint","37":"pylint","38":"pylint","39":"pylint","40":"pylint","41":"pylint","42":"pylint","43":"pylint"},"lines_amount":{"0":49,"1":668,"2":668,"3":668,"4":668,"5":668,"6":668,"7":285,"8":285,"9":285,"10":285,"11":285,"12":285,"13":285,"14":285,"15":285,"16":285,"17":285,"18":285,"19":285,"20":285,"21":285,"22":285,"23":285,"24":285,"25":285,"26":285,"27":285,"28":285,"29":285,"30":285,"31":285,"32":285,"33":285,"34":285,"35":285,"36":285,"37":285,"38":285,"39":285,"40":285,"41":285,"42":285,"43":285},"commit":{"0":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","1":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","2":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","3":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","4":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","5":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","6":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","7":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","8":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","9":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","10":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","11":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","12":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","13":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","14":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","15":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","16":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","17":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","18":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","19":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","20":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","21":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","22":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","23":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","24":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","25":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","26":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","27":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","28":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","29":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","30":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","31":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","32":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","33":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","34":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","35":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","36":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","37":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","38":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","39":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","40":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","41":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","42":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14","43":"ccd0eb24996b4cbff4231b90cd44b057c0b20f14"},"repo":{"0":"fchollet\/deep-learning-models","1":"fchollet\/deep-learning-models","2":"fchollet\/deep-learning-models","3":"fchollet\/deep-learning-models","4":"fchollet\/deep-learning-models","5":"fchollet\/deep-learning-models","6":"fchollet\/deep-learning-models","7":"fchollet\/deep-learning-models","8":"fchollet\/deep-learning-models","9":"fchollet\/deep-learning-models","10":"fchollet\/deep-learning-models","11":"fchollet\/deep-learning-models","12":"fchollet\/deep-learning-models","13":"fchollet\/deep-learning-models","14":"fchollet\/deep-learning-models","15":"fchollet\/deep-learning-models","16":"fchollet\/deep-learning-models","17":"fchollet\/deep-learning-models","18":"fchollet\/deep-learning-models","19":"fchollet\/deep-learning-models","20":"fchollet\/deep-learning-models","21":"fchollet\/deep-learning-models","22":"fchollet\/deep-learning-models","23":"fchollet\/deep-learning-models","24":"fchollet\/deep-learning-models","25":"fchollet\/deep-learning-models","26":"fchollet\/deep-learning-models","27":"fchollet\/deep-learning-models","28":"fchollet\/deep-learning-models","29":"fchollet\/deep-learning-models","30":"fchollet\/deep-learning-models","31":"fchollet\/deep-learning-models","32":"fchollet\/deep-learning-models","33":"fchollet\/deep-learning-models","34":"fchollet\/deep-learning-models","35":"fchollet\/deep-learning-models","36":"fchollet\/deep-learning-models","37":"fchollet\/deep-learning-models","38":"fchollet\/deep-learning-models","39":"fchollet\/deep-learning-models","40":"fchollet\/deep-learning-models","41":"fchollet\/deep-learning-models","42":"fchollet\/deep-learning-models","43":"fchollet\/deep-learning-models"},"stargazers":{"0":6959,"1":6959,"2":6959,"3":6959,"4":6959,"5":6959,"6":6959,"7":6959,"8":6959,"9":6959,"10":6959,"11":6959,"12":6959,"13":6959,"14":6959,"15":6959,"16":6959,"17":6959,"18":6959,"19":6959,"20":6959,"21":6959,"22":6959,"23":6959,"24":6959,"25":6959,"26":6959,"27":6959,"28":6959,"29":6959,"30":6959,"31":6959,"32":6959,"33":6959,"34":6959,"35":6959,"36":6959,"37":6959,"38":6959,"39":6959,"40":6959,"41":6959,"42":6959,"43":6959}}
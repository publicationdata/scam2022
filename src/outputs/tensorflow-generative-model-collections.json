{"type":{"0":"W","1":"W","2":"R","3":"W","4":"W","5":"W","6":"W","7":"W","8":"W","9":"W","10":"W","11":"W","12":"W","13":"W","14":"W","15":"W","16":"W","17":"W","18":"W","19":"W","20":"W","21":"W","22":"R","23":"W","24":"W","25":"W","26":"W","27":"W","28":"W","29":"W","30":"W","31":"W","32":"W","33":"W","34":"W","35":"W","36":"W","37":"W","38":"W","39":"W","40":"W","41":"R","42":"W","43":"W","44":"W","45":"W","46":"W","47":"W","48":"W","49":"W","50":"W","51":"W","52":"W","53":"W","54":"W","55":"W","56":"W","57":"W","58":"R","59":"W","60":"W","61":"W","62":"W","63":"W","64":"W","65":"W","66":"W","67":"W","68":"W","69":"W","70":"W","71":"W","72":"W","73":"W","74":"W","75":"R","76":"W","77":"W","78":"W","79":"W","80":"W","81":"W","82":"W","83":"W","84":"W","85":"W","86":"W","87":"W","88":"W","89":"W","90":"W","91":"R","92":"W","93":"W","94":"W","95":"W","96":"W","97":"W","98":"W","99":"W","100":"W","101":"W","102":"W","103":"W","104":"W","105":"W","106":"R","107":"W","108":"W","109":"W","110":"W","111":"W","112":"W","113":"W","114":"W","115":"W","116":"W","117":"W","118":"W","119":"W","120":"W","121":"R","122":"W","123":"W","124":"W","125":"W","126":"W","127":"W","128":"W","129":"W","130":"W","131":"W","132":"W","133":"W","134":"W","135":"W","136":"W","137":"R","138":"W","139":"W","140":"W","141":"W","142":"W","143":"W","144":"W","145":"W","146":"W","147":"W","148":"W","149":"W","150":"W","151":"W","152":"W","153":"W","154":"R","155":"W","156":"W","157":"W","158":"W","159":"W","160":"W","161":"W","162":"W","163":"W","164":"W","165":"W","166":"W","167":"W","168":"W","169":"W","170":"R","171":"W","172":"W","173":"W","174":"W","175":"W","176":"W","177":"W","178":"W","179":"W","180":"W","181":"W","182":"W","183":"W","184":"W","185":"R","186":"C","187":"W","188":"W","189":"W","190":"W","191":"W","192":"W","193":"W","194":"W","195":"W","196":"W","197":"W","198":"W","199":"W","200":"W","201":"W","202":"W","203":"W","204":"W","205":"W","206":"W","207":"R","208":"R","209":"R","210":"R","211":"R","212":"R","213":"R","214":"R","215":"R","216":"R","217":"R","218":"R","219":"R","220":"R","221":"R","222":"R","223":"R","224":"R","225":"R","226":"R","227":"R","228":"R","229":"R","230":"R","231":"R","232":"R","233":"R","234":"R","235":"R","236":"R","237":"R","238":"R","239":"R","240":"R","241":"R","242":"R","243":"R","244":"R","245":"R","246":"R","247":"R","248":"R","249":"R","250":"R","251":"R","252":"R","253":"R","254":"R","255":"R","256":"R","257":"R","258":"R","259":"R","260":"R","261":"R","262":"R","263":"R","264":"R","265":"R","266":"R","267":"R","268":"R","269":"R","270":"R","271":"R","272":"R","273":"R","274":"R","275":"R","276":"R","277":"R","278":"R","279":"R","280":"R","281":"R","282":"R","283":"R","284":"R","285":"R","286":"R","287":"R","288":"R","289":"R","290":"R","291":"R","292":"R","293":"R","294":"R","295":"R","296":"R","297":"R","298":"R","299":"R","300":"R","301":"R","302":"R","303":"R","304":"R","305":"R"},"module":{"0":"ACGAN","1":"ACGAN","2":"ACGAN","3":"ACGAN","4":"ACGAN","5":"ACGAN","6":"ACGAN","7":"ACGAN","8":"ACGAN","9":"ACGAN","10":"ACGAN","11":"ACGAN","12":"ACGAN","13":"ACGAN","14":"ACGAN","15":"ACGAN","16":"ACGAN","17":"ACGAN","18":"ACGAN","19":"ACGAN","20":"BEGAN","21":"BEGAN","22":"BEGAN","23":"BEGAN","24":"BEGAN","25":"BEGAN","26":"BEGAN","27":"BEGAN","28":"BEGAN","29":"BEGAN","30":"BEGAN","31":"BEGAN","32":"BEGAN","33":"BEGAN","34":"BEGAN","35":"BEGAN","36":"BEGAN","37":"BEGAN","38":"BEGAN","39":"CGAN","40":"CGAN","41":"CGAN","42":"CGAN","43":"CGAN","44":"CGAN","45":"CGAN","46":"CGAN","47":"CGAN","48":"CGAN","49":"CGAN","50":"CGAN","51":"CGAN","52":"CGAN","53":"CGAN","54":"CGAN","55":"CGAN","56":"CVAE","57":"CVAE","58":"CVAE","59":"CVAE","60":"CVAE","61":"CVAE","62":"CVAE","63":"CVAE","64":"CVAE","65":"CVAE","66":"CVAE","67":"CVAE","68":"CVAE","69":"CVAE","70":"CVAE","71":"CVAE","72":"CVAE","73":"DRAGAN","74":"DRAGAN","75":"DRAGAN","76":"DRAGAN","77":"DRAGAN","78":"DRAGAN","79":"DRAGAN","80":"DRAGAN","81":"DRAGAN","82":"DRAGAN","83":"DRAGAN","84":"DRAGAN","85":"DRAGAN","86":"DRAGAN","87":"DRAGAN","88":"DRAGAN","89":"EBGAN","90":"EBGAN","91":"EBGAN","92":"EBGAN","93":"EBGAN","94":"EBGAN","95":"EBGAN","96":"EBGAN","97":"EBGAN","98":"EBGAN","99":"EBGAN","100":"EBGAN","101":"EBGAN","102":"EBGAN","103":"EBGAN","104":"GAN","105":"GAN","106":"GAN","107":"GAN","108":"GAN","109":"GAN","110":"GAN","111":"GAN","112":"GAN","113":"GAN","114":"GAN","115":"GAN","116":"GAN","117":"GAN","118":"GAN","119":"LSGAN","120":"LSGAN","121":"LSGAN","122":"LSGAN","123":"LSGAN","124":"LSGAN","125":"LSGAN","126":"LSGAN","127":"LSGAN","128":"LSGAN","129":"LSGAN","130":"LSGAN","131":"LSGAN","132":"LSGAN","133":"LSGAN","134":"LSGAN","135":"VAE","136":"VAE","137":"VAE","138":"VAE","139":"VAE","140":"VAE","141":"VAE","142":"VAE","143":"VAE","144":"VAE","145":"VAE","146":"VAE","147":"VAE","148":"VAE","149":"VAE","150":"VAE","151":"VAE","152":"WGAN","153":"WGAN","154":"WGAN","155":"WGAN","156":"WGAN","157":"WGAN","158":"WGAN","159":"WGAN","160":"WGAN","161":"WGAN","162":"WGAN","163":"WGAN","164":"WGAN","165":"WGAN","166":"WGAN","167":"WGAN","168":"WGAN_GP","169":"WGAN_GP","170":"WGAN_GP","171":"WGAN_GP","172":"WGAN_GP","173":"WGAN_GP","174":"WGAN_GP","175":"WGAN_GP","176":"WGAN_GP","177":"WGAN_GP","178":"WGAN_GP","179":"WGAN_GP","180":"WGAN_GP","181":"WGAN_GP","182":"WGAN_GP","183":"infoGAN","184":"infoGAN","185":"infoGAN","186":"infoGAN","187":"infoGAN","188":"infoGAN","189":"infoGAN","190":"infoGAN","191":"infoGAN","192":"infoGAN","193":"infoGAN","194":"infoGAN","195":"infoGAN","196":"infoGAN","197":"infoGAN","198":"infoGAN","199":"infoGAN","200":"infoGAN","201":"infoGAN","202":"infoGAN","203":"infoGAN","204":"infoGAN","205":"ops","206":"utils","207":"utils","208":"utils","209":"utils","210":"utils","211":"utils","212":"utils","213":"utils","214":"utils","215":"utils","216":"utils","217":"utils","218":"utils","219":"utils","220":"utils","221":"utils","222":"utils","223":"utils","224":"utils","225":"utils","226":"utils","227":"utils","228":"utils","229":"utils","230":"utils","231":"utils","232":"utils","233":"utils","234":"utils","235":"utils","236":"utils","237":"utils","238":"utils","239":"utils","240":"utils","241":"utils","242":"utils","243":"utils","244":"utils","245":"utils","246":"utils","247":"utils","248":"utils","249":"utils","250":"utils","251":"utils","252":"utils","253":"utils","254":"utils","255":"utils","256":"utils","257":"utils","258":"utils","259":"utils","260":"utils","261":"utils","262":"utils","263":"utils","264":"utils","265":"utils","266":"utils","267":"utils","268":"utils","269":"utils","270":"utils","271":"utils","272":"utils","273":"utils","274":"utils","275":"utils","276":"utils","277":"utils","278":"utils","279":"utils","280":"utils","281":"utils","282":"utils","283":"utils","284":"utils","285":"utils","286":"utils","287":"utils","288":"utils","289":"utils","290":"utils","291":"utils","292":"utils","293":"utils","294":"utils","295":"utils","296":"utils","297":"utils","298":"utils","299":"utils","300":"utils","301":"utils","302":"utils","303":"utils","304":"utils","305":"utils"},"obj":{"0":"","1":"","2":"ACGAN.__init__","3":"ACGAN.build_model","4":"ACGAN.build_model","5":"ACGAN.build_model","6":"ACGAN.build_model","7":"ACGAN.build_model","8":"ACGAN.build_model","9":"ACGAN.build_model","10":"ACGAN.build_model","11":"ACGAN.build_model","12":"ACGAN.build_model","13":"ACGAN.build_model","14":"ACGAN.build_model","15":"ACGAN.build_model","16":"ACGAN.train","17":"ACGAN.train","18":"ACGAN.train","19":"ACGAN.train","20":"","21":"","22":"BEGAN.__init__","23":"BEGAN.build_model","24":"BEGAN.build_model","25":"BEGAN.build_model","26":"BEGAN.build_model","27":"BEGAN.build_model","28":"BEGAN.build_model","29":"BEGAN.build_model","30":"BEGAN.build_model","31":"BEGAN.build_model","32":"BEGAN.build_model","33":"BEGAN.build_model","34":"BEGAN.build_model","35":"BEGAN.build_model","36":"BEGAN.train","37":"BEGAN.train","38":"BEGAN.train","39":"","40":"","41":"CGAN.__init__","42":"CGAN.build_model","43":"CGAN.build_model","44":"CGAN.build_model","45":"CGAN.build_model","46":"CGAN.build_model","47":"CGAN.build_model","48":"CGAN.build_model","49":"CGAN.build_model","50":"CGAN.build_model","51":"CGAN.build_model","52":"CGAN.train","53":"CGAN.train","54":"CGAN.train","55":"CGAN.train","56":"","57":"","58":"CVAE.__init__","59":"CVAE.build_model","60":"CVAE.build_model","61":"CVAE.build_model","62":"CVAE.build_model","63":"CVAE.build_model","64":"CVAE.build_model","65":"CVAE.build_model","66":"CVAE.build_model","67":"CVAE.build_model","68":"CVAE.build_model","69":"CVAE.train","70":"CVAE.train","71":"CVAE.train","72":"CVAE.train","73":"","74":"","75":"DRAGAN.__init__","76":"DRAGAN.build_model","77":"DRAGAN.build_model","78":"DRAGAN.build_model","79":"DRAGAN.build_model","80":"DRAGAN.build_model","81":"DRAGAN.build_model","82":"DRAGAN.build_model","83":"DRAGAN.build_model","84":"DRAGAN.build_model","85":"DRAGAN.build_model","86":"DRAGAN.train","87":"DRAGAN.train","88":"DRAGAN.train","89":"","90":"","91":"EBGAN.__init__","92":"EBGAN.build_model","93":"EBGAN.build_model","94":"EBGAN.build_model","95":"EBGAN.build_model","96":"EBGAN.build_model","97":"EBGAN.build_model","98":"EBGAN.build_model","99":"EBGAN.build_model","100":"EBGAN.build_model","101":"EBGAN.train","102":"EBGAN.train","103":"EBGAN.train","104":"","105":"","106":"GAN.__init__","107":"GAN.build_model","108":"GAN.build_model","109":"GAN.build_model","110":"GAN.build_model","111":"GAN.build_model","112":"GAN.build_model","113":"GAN.build_model","114":"GAN.build_model","115":"GAN.build_model","116":"GAN.train","117":"GAN.train","118":"GAN.train","119":"","120":"","121":"LSGAN.__init__","122":"LSGAN.build_model","123":"LSGAN.build_model","124":"LSGAN.build_model","125":"LSGAN.build_model","126":"LSGAN.build_model","127":"LSGAN.build_model","128":"LSGAN.build_model","129":"LSGAN.build_model","130":"LSGAN.build_model","131":"LSGAN.build_model","132":"LSGAN.train","133":"LSGAN.train","134":"LSGAN.train","135":"","136":"","137":"VAE.__init__","138":"VAE.visualize_results","139":"VAE.build_model","140":"VAE.build_model","141":"VAE.build_model","142":"VAE.build_model","143":"VAE.build_model","144":"VAE.build_model","145":"VAE.build_model","146":"VAE.build_model","147":"VAE.build_model","148":"VAE.build_model","149":"VAE.train","150":"VAE.train","151":"VAE.train","152":"","153":"","154":"WGAN.__init__","155":"WGAN.build_model","156":"WGAN.build_model","157":"WGAN.build_model","158":"WGAN.build_model","159":"WGAN.build_model","160":"WGAN.build_model","161":"WGAN.build_model","162":"WGAN.build_model","163":"WGAN.build_model","164":"WGAN.build_model","165":"WGAN.train","166":"WGAN.train","167":"WGAN.train","168":"","169":"","170":"WGAN_GP.__init__","171":"WGAN_GP.build_model","172":"WGAN_GP.build_model","173":"WGAN_GP.build_model","174":"WGAN_GP.build_model","175":"WGAN_GP.build_model","176":"WGAN_GP.build_model","177":"WGAN_GP.build_model","178":"WGAN_GP.build_model","179":"WGAN_GP.build_model","180":"WGAN_GP.train","181":"WGAN_GP.train","182":"WGAN_GP.train","183":"","184":"","185":"infoGAN.__init__","186":"infoGAN.train","187":"infoGAN.build_model","188":"infoGAN.build_model","189":"infoGAN.build_model","190":"infoGAN.build_model","191":"infoGAN.build_model","192":"infoGAN.build_model","193":"infoGAN.build_model","194":"infoGAN.build_model","195":"infoGAN.build_model","196":"infoGAN.build_model","197":"infoGAN.build_model","198":"infoGAN.build_model","199":"infoGAN.build_model","200":"infoGAN.train","201":"infoGAN.train","202":"infoGAN.train","203":"infoGAN.train","204":"infoGAN.train","205":"","206":"save_scattered_image","207":"","208":"","209":"","210":"","211":"","212":"","213":"","214":"","215":"","216":"","217":"","218":"","219":"","220":"","221":"","222":"","223":"","224":"","225":"","226":"","227":"","228":"","229":"","230":"","231":"","232":"","233":"","234":"","235":"","236":"","237":"","238":"","239":"","240":"","241":"","242":"","243":"","244":"","245":"","246":"","247":"","248":"","249":"","250":"","251":"","252":"","253":"","254":"","255":"","256":"","257":"","258":"","259":"","260":"","261":"","262":"","263":"","264":"","265":"","266":"","267":"","268":"","269":"","270":"","271":"","272":"","273":"","274":"","275":"","276":"","277":"","278":"","279":"","280":"","281":"","282":"","283":"","284":"","285":"","286":"","287":"","288":"","289":"","290":"","291":"","292":"","293":"","294":"","295":"","296":"","297":"","298":"","299":"","300":"","301":"","302":"","303":"","304":"","305":""},"lnum":{"0":8,"1":9,"2":23,"3":105,"4":108,"5":111,"6":128,"7":131,"8":145,"9":156,"10":158,"11":160,"12":165,"13":178,"14":179,"15":180,"16":188,"17":189,"18":192,"19":195,"20":8,"21":9,"22":23,"23":89,"24":93,"25":96,"26":108,"27":111,"28":114,"29":117,"30":128,"31":130,"32":135,"33":146,"34":147,"35":148,"36":156,"37":159,"38":162,"39":8,"40":9,"41":23,"42":94,"43":97,"44":100,"45":117,"46":120,"47":131,"48":133,"49":138,"50":147,"51":148,"52":156,"53":157,"54":160,"55":163,"56":8,"57":9,"58":25,"59":102,"60":105,"61":108,"62":119,"63":125,"64":126,"65":130,"66":136,"67":141,"68":149,"69":157,"70":158,"71":161,"72":164,"73":8,"74":9,"75":23,"76":90,"77":91,"78":94,"79":111,"80":114,"81":136,"82":138,"83":143,"84":152,"85":153,"86":161,"87":164,"88":167,"89":8,"90":9,"91":23,"92":106,"93":109,"94":121,"95":124,"96":134,"97":136,"98":141,"99":150,"100":151,"101":159,"102":162,"103":165,"104":8,"105":9,"106":23,"107":84,"108":87,"109":104,"110":107,"111":118,"112":120,"113":125,"114":134,"115":135,"116":143,"117":146,"118":149,"119":8,"120":9,"121":23,"122":88,"123":91,"124":106,"125":109,"126":119,"127":121,"128":125,"129":129,"130":138,"131":139,"132":147,"133":150,"134":153,"135":8,"136":9,"137":25,"138":232,"139":92,"140":95,"141":99,"142":106,"143":113,"144":114,"145":118,"146":124,"147":129,"148":137,"149":145,"150":148,"151":151,"152":8,"153":9,"154":23,"155":87,"156":90,"157":105,"158":108,"159":118,"160":120,"161":124,"162":128,"163":137,"164":138,"165":146,"166":149,"167":152,"168":8,"169":9,"170":23,"171":88,"172":91,"173":106,"174":109,"175":130,"176":132,"177":137,"178":146,"179":147,"180":155,"181":158,"182":161,"183":8,"184":9,"185":23,"186":227,"187":108,"188":111,"189":114,"190":131,"191":134,"192":151,"193":162,"194":164,"195":166,"196":171,"197":184,"198":185,"199":186,"200":194,"201":195,"202":196,"203":200,"204":203,"205":10,"206":127,"207":1,"208":1,"209":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1,"216":1,"217":1,"218":1,"219":1,"220":1,"221":1,"222":1,"223":1,"224":1,"225":1,"226":1,"227":1,"228":1,"229":1,"230":1,"231":1,"232":1,"233":1,"234":1,"235":1,"236":1,"237":1,"238":1,"239":1,"240":1,"241":1,"242":1,"243":1,"244":1,"245":1,"246":1,"247":1,"248":1,"249":1,"250":1,"251":1,"252":1,"253":1,"254":1,"255":1,"256":1,"257":1,"258":1,"259":1,"260":1,"261":1,"262":1,"263":1,"264":1,"265":1,"266":1,"267":1,"268":1,"269":1,"270":1,"271":1,"272":1,"273":1,"274":1,"275":1,"276":1,"277":1,"278":1,"279":1,"280":1,"281":1,"282":1,"283":1,"284":1,"285":1,"286":1,"287":1,"288":1,"289":1,"290":1,"291":1,"292":1,"293":1,"294":1,"295":1,"296":1,"297":1,"298":1,"299":1,"300":1,"301":1,"302":1,"303":1,"304":1,"305":1},"col":{"0":0,"1":0,"2":11,"3":8,"4":8,"5":8,"6":8,"7":8,"8":8,"9":12,"10":12,"11":12,"12":8,"13":8,"14":8,"15":8,"16":8,"17":8,"18":8,"19":8,"20":0,"21":0,"22":11,"23":8,"24":8,"25":8,"26":8,"27":8,"28":8,"29":8,"30":12,"31":12,"32":8,"33":8,"34":8,"35":8,"36":8,"37":8,"38":8,"39":0,"40":0,"41":11,"42":8,"43":8,"44":8,"45":8,"46":8,"47":12,"48":12,"49":8,"50":8,"51":8,"52":8,"53":8,"54":8,"55":8,"56":0,"57":0,"58":11,"59":8,"60":8,"61":8,"62":8,"63":8,"64":8,"65":8,"66":12,"67":8,"68":8,"69":8,"70":8,"71":8,"72":8,"73":0,"74":0,"75":11,"76":8,"77":8,"78":8,"79":8,"80":8,"81":12,"82":12,"83":8,"84":8,"85":8,"86":8,"87":8,"88":8,"89":0,"90":0,"91":11,"92":8,"93":8,"94":8,"95":8,"96":12,"97":12,"98":8,"99":8,"100":8,"101":8,"102":8,"103":8,"104":0,"105":0,"106":11,"107":8,"108":8,"109":8,"110":8,"111":12,"112":12,"113":8,"114":8,"115":8,"116":8,"117":8,"118":8,"119":0,"120":0,"121":11,"122":8,"123":8,"124":8,"125":8,"126":12,"127":12,"128":8,"129":8,"130":8,"131":8,"132":8,"133":8,"134":8,"135":0,"136":0,"137":11,"138":16,"139":8,"140":8,"141":8,"142":8,"143":8,"144":8,"145":8,"146":12,"147":8,"148":8,"149":8,"150":8,"151":8,"152":0,"153":0,"154":11,"155":8,"156":8,"157":8,"158":8,"159":12,"160":12,"161":8,"162":8,"163":8,"164":8,"165":8,"166":8,"167":8,"168":0,"169":0,"170":11,"171":8,"172":8,"173":8,"174":8,"175":12,"176":12,"177":8,"178":8,"179":8,"180":8,"181":8,"182":8,"183":0,"184":0,"185":11,"186":19,"187":8,"188":8,"189":8,"190":8,"191":8,"192":8,"193":12,"194":12,"195":12,"196":8,"197":8,"198":8,"199":8,"200":8,"201":8,"202":8,"203":8,"204":8,"205":0,"206":28,"207":0,"208":0,"209":0,"210":0,"211":0,"212":0,"213":0,"214":0,"215":0,"216":0,"217":0,"218":0,"219":0,"220":0,"221":0,"222":0,"223":0,"224":0,"225":0,"226":0,"227":0,"228":0,"229":0,"230":0,"231":0,"232":0,"233":0,"234":0,"235":0,"236":0,"237":0,"238":0,"239":0,"240":0,"241":0,"242":0,"243":0,"244":0,"245":0,"246":0,"247":0,"248":0,"249":0,"250":0,"251":0,"252":0,"253":0,"254":0,"255":0,"256":0,"257":0,"258":0,"259":0,"260":0,"261":0,"262":0,"263":0,"264":0,"265":0,"266":0,"267":0,"268":0,"269":0,"270":0,"271":0,"272":0,"273":0,"274":0,"275":0,"276":0,"277":0,"278":0,"279":0,"280":0,"281":0,"282":0,"283":0,"284":0,"285":0,"286":0,"287":0,"288":0,"289":0,"290":0,"291":0,"292":0,"293":0,"294":0,"295":0,"296":0,"297":0,"298":0,"299":0,"300":0,"301":0,"302":0,"303":0,"304":0,"305":0},"filename":{"0":"ACGAN.py","1":"ACGAN.py","2":"ACGAN.py","3":"ACGAN.py","4":"ACGAN.py","5":"ACGAN.py","6":"ACGAN.py","7":"ACGAN.py","8":"ACGAN.py","9":"ACGAN.py","10":"ACGAN.py","11":"ACGAN.py","12":"ACGAN.py","13":"ACGAN.py","14":"ACGAN.py","15":"ACGAN.py","16":"ACGAN.py","17":"ACGAN.py","18":"ACGAN.py","19":"ACGAN.py","20":"BEGAN.py","21":"BEGAN.py","22":"BEGAN.py","23":"BEGAN.py","24":"BEGAN.py","25":"BEGAN.py","26":"BEGAN.py","27":"BEGAN.py","28":"BEGAN.py","29":"BEGAN.py","30":"BEGAN.py","31":"BEGAN.py","32":"BEGAN.py","33":"BEGAN.py","34":"BEGAN.py","35":"BEGAN.py","36":"BEGAN.py","37":"BEGAN.py","38":"BEGAN.py","39":"CGAN.py","40":"CGAN.py","41":"CGAN.py","42":"CGAN.py","43":"CGAN.py","44":"CGAN.py","45":"CGAN.py","46":"CGAN.py","47":"CGAN.py","48":"CGAN.py","49":"CGAN.py","50":"CGAN.py","51":"CGAN.py","52":"CGAN.py","53":"CGAN.py","54":"CGAN.py","55":"CGAN.py","56":"CVAE.py","57":"CVAE.py","58":"CVAE.py","59":"CVAE.py","60":"CVAE.py","61":"CVAE.py","62":"CVAE.py","63":"CVAE.py","64":"CVAE.py","65":"CVAE.py","66":"CVAE.py","67":"CVAE.py","68":"CVAE.py","69":"CVAE.py","70":"CVAE.py","71":"CVAE.py","72":"CVAE.py","73":"DRAGAN.py","74":"DRAGAN.py","75":"DRAGAN.py","76":"DRAGAN.py","77":"DRAGAN.py","78":"DRAGAN.py","79":"DRAGAN.py","80":"DRAGAN.py","81":"DRAGAN.py","82":"DRAGAN.py","83":"DRAGAN.py","84":"DRAGAN.py","85":"DRAGAN.py","86":"DRAGAN.py","87":"DRAGAN.py","88":"DRAGAN.py","89":"EBGAN.py","90":"EBGAN.py","91":"EBGAN.py","92":"EBGAN.py","93":"EBGAN.py","94":"EBGAN.py","95":"EBGAN.py","96":"EBGAN.py","97":"EBGAN.py","98":"EBGAN.py","99":"EBGAN.py","100":"EBGAN.py","101":"EBGAN.py","102":"EBGAN.py","103":"EBGAN.py","104":"GAN.py","105":"GAN.py","106":"GAN.py","107":"GAN.py","108":"GAN.py","109":"GAN.py","110":"GAN.py","111":"GAN.py","112":"GAN.py","113":"GAN.py","114":"GAN.py","115":"GAN.py","116":"GAN.py","117":"GAN.py","118":"GAN.py","119":"LSGAN.py","120":"LSGAN.py","121":"LSGAN.py","122":"LSGAN.py","123":"LSGAN.py","124":"LSGAN.py","125":"LSGAN.py","126":"LSGAN.py","127":"LSGAN.py","128":"LSGAN.py","129":"LSGAN.py","130":"LSGAN.py","131":"LSGAN.py","132":"LSGAN.py","133":"LSGAN.py","134":"LSGAN.py","135":"VAE.py","136":"VAE.py","137":"VAE.py","138":"VAE.py","139":"VAE.py","140":"VAE.py","141":"VAE.py","142":"VAE.py","143":"VAE.py","144":"VAE.py","145":"VAE.py","146":"VAE.py","147":"VAE.py","148":"VAE.py","149":"VAE.py","150":"VAE.py","151":"VAE.py","152":"WGAN.py","153":"WGAN.py","154":"WGAN.py","155":"WGAN.py","156":"WGAN.py","157":"WGAN.py","158":"WGAN.py","159":"WGAN.py","160":"WGAN.py","161":"WGAN.py","162":"WGAN.py","163":"WGAN.py","164":"WGAN.py","165":"WGAN.py","166":"WGAN.py","167":"WGAN.py","168":"WGAN_GP.py","169":"WGAN_GP.py","170":"WGAN_GP.py","171":"WGAN_GP.py","172":"WGAN_GP.py","173":"WGAN_GP.py","174":"WGAN_GP.py","175":"WGAN_GP.py","176":"WGAN_GP.py","177":"WGAN_GP.py","178":"WGAN_GP.py","179":"WGAN_GP.py","180":"WGAN_GP.py","181":"WGAN_GP.py","182":"WGAN_GP.py","183":"infoGAN.py","184":"infoGAN.py","185":"infoGAN.py","186":"infoGAN.py","187":"infoGAN.py","188":"infoGAN.py","189":"infoGAN.py","190":"infoGAN.py","191":"infoGAN.py","192":"infoGAN.py","193":"infoGAN.py","194":"infoGAN.py","195":"infoGAN.py","196":"infoGAN.py","197":"infoGAN.py","198":"infoGAN.py","199":"infoGAN.py","200":"infoGAN.py","201":"infoGAN.py","202":"infoGAN.py","203":"infoGAN.py","204":"infoGAN.py","205":"ops.py","206":"utils.py","207":"utils.py","208":"utils.py","209":"utils.py","210":"utils.py","211":"utils.py","212":"utils.py","213":"utils.py","214":"utils.py","215":"utils.py","216":"utils.py","217":"utils.py","218":"utils.py","219":"utils.py","220":"utils.py","221":"utils.py","222":"utils.py","223":"utils.py","224":"utils.py","225":"utils.py","226":"utils.py","227":"utils.py","228":"utils.py","229":"utils.py","230":"utils.py","231":"utils.py","232":"utils.py","233":"utils.py","234":"utils.py","235":"utils.py","236":"utils.py","237":"utils.py","238":"utils.py","239":"utils.py","240":"utils.py","241":"utils.py","242":"utils.py","243":"utils.py","244":"utils.py","245":"utils.py","246":"utils.py","247":"utils.py","248":"utils.py","249":"utils.py","250":"utils.py","251":"utils.py","252":"utils.py","253":"utils.py","254":"utils.py","255":"utils.py","256":"utils.py","257":"utils.py","258":"utils.py","259":"utils.py","260":"utils.py","261":"utils.py","262":"utils.py","263":"utils.py","264":"utils.py","265":"utils.py","266":"utils.py","267":"utils.py","268":"utils.py","269":"utils.py","270":"utils.py","271":"utils.py","272":"utils.py","273":"utils.py","274":"utils.py","275":"utils.py","276":"utils.py","277":"utils.py","278":"utils.py","279":"utils.py","280":"utils.py","281":"utils.py","282":"utils.py","283":"utils.py","284":"utils.py","285":"utils.py","286":"utils.py","287":"utils.py","288":"utils.py","289":"utils.py","290":"utils.py","291":"utils.py","292":"utils.py","293":"utils.py","294":"utils.py","295":"utils.py","296":"utils.py","297":"utils.py","298":"utils.py","299":"utils.py","300":"utils.py","301":"utils.py","302":"utils.py","303":"utils.py","304":"utils.py","305":"utils.py"},"symbol":{"0":"wildcard-import","1":"wildcard-import","2":"consider-using-in","3":"attribute-defined-outside-init","4":"attribute-defined-outside-init","5":"attribute-defined-outside-init","6":"attribute-defined-outside-init","7":"attribute-defined-outside-init","8":"attribute-defined-outside-init","9":"attribute-defined-outside-init","10":"attribute-defined-outside-init","11":"attribute-defined-outside-init","12":"attribute-defined-outside-init","13":"attribute-defined-outside-init","14":"attribute-defined-outside-init","15":"attribute-defined-outside-init","16":"attribute-defined-outside-init","17":"attribute-defined-outside-init","18":"attribute-defined-outside-init","19":"attribute-defined-outside-init","20":"wildcard-import","21":"wildcard-import","22":"consider-using-in","23":"attribute-defined-outside-init","24":"attribute-defined-outside-init","25":"attribute-defined-outside-init","26":"attribute-defined-outside-init","27":"attribute-defined-outside-init","28":"attribute-defined-outside-init","29":"attribute-defined-outside-init","30":"attribute-defined-outside-init","31":"attribute-defined-outside-init","32":"attribute-defined-outside-init","33":"attribute-defined-outside-init","34":"attribute-defined-outside-init","35":"attribute-defined-outside-init","36":"attribute-defined-outside-init","37":"attribute-defined-outside-init","38":"attribute-defined-outside-init","39":"wildcard-import","40":"wildcard-import","41":"consider-using-in","42":"attribute-defined-outside-init","43":"attribute-defined-outside-init","44":"attribute-defined-outside-init","45":"attribute-defined-outside-init","46":"attribute-defined-outside-init","47":"attribute-defined-outside-init","48":"attribute-defined-outside-init","49":"attribute-defined-outside-init","50":"attribute-defined-outside-init","51":"attribute-defined-outside-init","52":"attribute-defined-outside-init","53":"attribute-defined-outside-init","54":"attribute-defined-outside-init","55":"attribute-defined-outside-init","56":"wildcard-import","57":"wildcard-import","58":"consider-using-in","59":"attribute-defined-outside-init","60":"attribute-defined-outside-init","61":"attribute-defined-outside-init","62":"attribute-defined-outside-init","63":"attribute-defined-outside-init","64":"attribute-defined-outside-init","65":"attribute-defined-outside-init","66":"attribute-defined-outside-init","67":"attribute-defined-outside-init","68":"attribute-defined-outside-init","69":"attribute-defined-outside-init","70":"attribute-defined-outside-init","71":"attribute-defined-outside-init","72":"attribute-defined-outside-init","73":"wildcard-import","74":"wildcard-import","75":"consider-using-in","76":"attribute-defined-outside-init","77":"attribute-defined-outside-init","78":"attribute-defined-outside-init","79":"attribute-defined-outside-init","80":"attribute-defined-outside-init","81":"attribute-defined-outside-init","82":"attribute-defined-outside-init","83":"attribute-defined-outside-init","84":"attribute-defined-outside-init","85":"attribute-defined-outside-init","86":"attribute-defined-outside-init","87":"attribute-defined-outside-init","88":"attribute-defined-outside-init","89":"wildcard-import","90":"wildcard-import","91":"consider-using-in","92":"attribute-defined-outside-init","93":"attribute-defined-outside-init","94":"attribute-defined-outside-init","95":"attribute-defined-outside-init","96":"attribute-defined-outside-init","97":"attribute-defined-outside-init","98":"attribute-defined-outside-init","99":"attribute-defined-outside-init","100":"attribute-defined-outside-init","101":"attribute-defined-outside-init","102":"attribute-defined-outside-init","103":"attribute-defined-outside-init","104":"wildcard-import","105":"wildcard-import","106":"consider-using-in","107":"attribute-defined-outside-init","108":"attribute-defined-outside-init","109":"attribute-defined-outside-init","110":"attribute-defined-outside-init","111":"attribute-defined-outside-init","112":"attribute-defined-outside-init","113":"attribute-defined-outside-init","114":"attribute-defined-outside-init","115":"attribute-defined-outside-init","116":"attribute-defined-outside-init","117":"attribute-defined-outside-init","118":"attribute-defined-outside-init","119":"wildcard-import","120":"wildcard-import","121":"consider-using-in","122":"attribute-defined-outside-init","123":"attribute-defined-outside-init","124":"attribute-defined-outside-init","125":"attribute-defined-outside-init","126":"attribute-defined-outside-init","127":"attribute-defined-outside-init","128":"attribute-defined-outside-init","129":"attribute-defined-outside-init","130":"attribute-defined-outside-init","131":"attribute-defined-outside-init","132":"attribute-defined-outside-init","133":"attribute-defined-outside-init","134":"attribute-defined-outside-init","135":"wildcard-import","136":"wildcard-import","137":"consider-using-in","138":"redefined-builtin","139":"attribute-defined-outside-init","140":"attribute-defined-outside-init","141":"attribute-defined-outside-init","142":"attribute-defined-outside-init","143":"attribute-defined-outside-init","144":"attribute-defined-outside-init","145":"attribute-defined-outside-init","146":"attribute-defined-outside-init","147":"attribute-defined-outside-init","148":"attribute-defined-outside-init","149":"attribute-defined-outside-init","150":"attribute-defined-outside-init","151":"attribute-defined-outside-init","152":"wildcard-import","153":"wildcard-import","154":"consider-using-in","155":"attribute-defined-outside-init","156":"attribute-defined-outside-init","157":"attribute-defined-outside-init","158":"attribute-defined-outside-init","159":"attribute-defined-outside-init","160":"attribute-defined-outside-init","161":"attribute-defined-outside-init","162":"attribute-defined-outside-init","163":"attribute-defined-outside-init","164":"attribute-defined-outside-init","165":"attribute-defined-outside-init","166":"attribute-defined-outside-init","167":"attribute-defined-outside-init","168":"wildcard-import","169":"wildcard-import","170":"consider-using-in","171":"attribute-defined-outside-init","172":"attribute-defined-outside-init","173":"attribute-defined-outside-init","174":"attribute-defined-outside-init","175":"attribute-defined-outside-init","176":"attribute-defined-outside-init","177":"attribute-defined-outside-init","178":"attribute-defined-outside-init","179":"attribute-defined-outside-init","180":"attribute-defined-outside-init","181":"attribute-defined-outside-init","182":"attribute-defined-outside-init","183":"wildcard-import","184":"wildcard-import","185":"consider-using-in","186":"singleton-comparison","187":"attribute-defined-outside-init","188":"attribute-defined-outside-init","189":"attribute-defined-outside-init","190":"attribute-defined-outside-init","191":"attribute-defined-outside-init","192":"attribute-defined-outside-init","193":"attribute-defined-outside-init","194":"attribute-defined-outside-init","195":"attribute-defined-outside-init","196":"attribute-defined-outside-init","197":"attribute-defined-outside-init","198":"attribute-defined-outside-init","199":"attribute-defined-outside-init","200":"attribute-defined-outside-init","201":"attribute-defined-outside-init","202":"attribute-defined-outside-init","203":"attribute-defined-outside-init","204":"attribute-defined-outside-init","205":"wildcard-import","206":"redefined-builtin","207":"duplicate-code","208":"duplicate-code","209":"duplicate-code","210":"duplicate-code","211":"duplicate-code","212":"duplicate-code","213":"duplicate-code","214":"duplicate-code","215":"duplicate-code","216":"duplicate-code","217":"duplicate-code","218":"duplicate-code","219":"duplicate-code","220":"duplicate-code","221":"duplicate-code","222":"duplicate-code","223":"duplicate-code","224":"duplicate-code","225":"duplicate-code","226":"duplicate-code","227":"duplicate-code","228":"duplicate-code","229":"duplicate-code","230":"duplicate-code","231":"duplicate-code","232":"duplicate-code","233":"duplicate-code","234":"duplicate-code","235":"duplicate-code","236":"duplicate-code","237":"duplicate-code","238":"duplicate-code","239":"duplicate-code","240":"duplicate-code","241":"duplicate-code","242":"duplicate-code","243":"duplicate-code","244":"duplicate-code","245":"duplicate-code","246":"duplicate-code","247":"duplicate-code","248":"duplicate-code","249":"duplicate-code","250":"duplicate-code","251":"duplicate-code","252":"duplicate-code","253":"duplicate-code","254":"duplicate-code","255":"duplicate-code","256":"duplicate-code","257":"duplicate-code","258":"duplicate-code","259":"duplicate-code","260":"duplicate-code","261":"duplicate-code","262":"duplicate-code","263":"duplicate-code","264":"duplicate-code","265":"duplicate-code","266":"duplicate-code","267":"duplicate-code","268":"duplicate-code","269":"duplicate-code","270":"duplicate-code","271":"duplicate-code","272":"duplicate-code","273":"duplicate-code","274":"duplicate-code","275":"duplicate-code","276":"duplicate-code","277":"duplicate-code","278":"duplicate-code","279":"duplicate-code","280":"duplicate-code","281":"duplicate-code","282":"duplicate-code","283":"duplicate-code","284":"duplicate-code","285":"duplicate-code","286":"duplicate-code","287":"duplicate-code","288":"duplicate-code","289":"duplicate-code","290":"duplicate-code","291":"duplicate-code","292":"duplicate-code","293":"duplicate-code","294":"duplicate-code","295":"duplicate-code","296":"duplicate-code","297":"duplicate-code","298":"duplicate-code","299":"duplicate-code","300":"duplicate-code","301":"duplicate-code","302":"duplicate-code","303":"duplicate-code","304":"duplicate-code","305":"duplicate-code"},"text":{"0":"Wildcard import ops","1":"Wildcard import utils","2":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","3":"Attribute 'inputs' defined outside __init__","4":"Attribute 'y' defined outside __init__","5":"Attribute 'z' defined outside __init__","6":"Attribute 'd_loss' defined outside __init__","7":"Attribute 'g_loss' defined outside __init__","8":"Attribute 'q_loss' defined outside __init__","9":"Attribute 'd_optim' defined outside __init__","10":"Attribute 'g_optim' defined outside __init__","11":"Attribute 'q_optim' defined outside __init__","12":"Attribute 'fake_images' defined outside __init__","13":"Attribute 'g_sum' defined outside __init__","14":"Attribute 'd_sum' defined outside __init__","15":"Attribute 'q_sum' defined outside __init__","16":"Attribute 'sample_z' defined outside __init__","17":"Attribute 'test_codes' defined outside __init__","18":"Attribute 'saver' defined outside __init__","19":"Attribute 'writer' defined outside __init__","20":"Wildcard import ops","21":"Wildcard import utils","22":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","23":"Attribute 'k' defined outside __init__","24":"Attribute 'inputs' defined outside __init__","25":"Attribute 'z' defined outside __init__","26":"Attribute 'd_loss' defined outside __init__","27":"Attribute 'g_loss' defined outside __init__","28":"Attribute 'M' defined outside __init__","29":"Attribute 'update_k' defined outside __init__","30":"Attribute 'd_optim' defined outside __init__","31":"Attribute 'g_optim' defined outside __init__","32":"Attribute 'fake_images' defined outside __init__","33":"Attribute 'g_sum' defined outside __init__","34":"Attribute 'd_sum' defined outside __init__","35":"Attribute 'p_sum' defined outside __init__","36":"Attribute 'sample_z' defined outside __init__","37":"Attribute 'saver' defined outside __init__","38":"Attribute 'writer' defined outside __init__","39":"Wildcard import ops","40":"Wildcard import utils","41":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","42":"Attribute 'inputs' defined outside __init__","43":"Attribute 'y' defined outside __init__","44":"Attribute 'z' defined outside __init__","45":"Attribute 'd_loss' defined outside __init__","46":"Attribute 'g_loss' defined outside __init__","47":"Attribute 'd_optim' defined outside __init__","48":"Attribute 'g_optim' defined outside __init__","49":"Attribute 'fake_images' defined outside __init__","50":"Attribute 'g_sum' defined outside __init__","51":"Attribute 'd_sum' defined outside __init__","52":"Attribute 'sample_z' defined outside __init__","53":"Attribute 'test_labels' defined outside __init__","54":"Attribute 'saver' defined outside __init__","55":"Attribute 'writer' defined outside __init__","56":"Wildcard import ops","57":"Wildcard import utils","58":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","59":"Attribute 'inputs' defined outside __init__","60":"Attribute 'y' defined outside __init__","61":"Attribute 'z' defined outside __init__","62":"Attribute 'out' defined outside __init__","63":"Attribute 'neg_loglikelihood' defined outside __init__","64":"Attribute 'KL_divergence' defined outside __init__","65":"Attribute 'loss' defined outside __init__","66":"Attribute 'optim' defined outside __init__","67":"Attribute 'fake_images' defined outside __init__","68":"Attribute 'merged_summary_op' defined outside __init__","69":"Attribute 'sample_z' defined outside __init__","70":"Attribute 'test_labels' defined outside __init__","71":"Attribute 'saver' defined outside __init__","72":"Attribute 'writer' defined outside __init__","73":"Wildcard import ops","74":"Wildcard import utils","75":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","76":"Attribute 'inputs' defined outside __init__","77":"Attribute 'inputs_p' defined outside __init__","78":"Attribute 'z' defined outside __init__","79":"Attribute 'd_loss' defined outside __init__","80":"Attribute 'g_loss' defined outside __init__","81":"Attribute 'd_optim' defined outside __init__","82":"Attribute 'g_optim' defined outside __init__","83":"Attribute 'fake_images' defined outside __init__","84":"Attribute 'g_sum' defined outside __init__","85":"Attribute 'd_sum' defined outside __init__","86":"Attribute 'sample_z' defined outside __init__","87":"Attribute 'saver' defined outside __init__","88":"Attribute 'writer' defined outside __init__","89":"Wildcard import ops","90":"Wildcard import utils","91":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","92":"Attribute 'inputs' defined outside __init__","93":"Attribute 'z' defined outside __init__","94":"Attribute 'd_loss' defined outside __init__","95":"Attribute 'g_loss' defined outside __init__","96":"Attribute 'd_optim' defined outside __init__","97":"Attribute 'g_optim' defined outside __init__","98":"Attribute 'fake_images' defined outside __init__","99":"Attribute 'g_sum' defined outside __init__","100":"Attribute 'd_sum' defined outside __init__","101":"Attribute 'sample_z' defined outside __init__","102":"Attribute 'saver' defined outside __init__","103":"Attribute 'writer' defined outside __init__","104":"Wildcard import ops","105":"Wildcard import utils","106":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","107":"Attribute 'inputs' defined outside __init__","108":"Attribute 'z' defined outside __init__","109":"Attribute 'd_loss' defined outside __init__","110":"Attribute 'g_loss' defined outside __init__","111":"Attribute 'd_optim' defined outside __init__","112":"Attribute 'g_optim' defined outside __init__","113":"Attribute 'fake_images' defined outside __init__","114":"Attribute 'g_sum' defined outside __init__","115":"Attribute 'd_sum' defined outside __init__","116":"Attribute 'sample_z' defined outside __init__","117":"Attribute 'saver' defined outside __init__","118":"Attribute 'writer' defined outside __init__","119":"Wildcard import ops","120":"Wildcard import utils","121":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","122":"Attribute 'inputs' defined outside __init__","123":"Attribute 'z' defined outside __init__","124":"Attribute 'd_loss' defined outside __init__","125":"Attribute 'g_loss' defined outside __init__","126":"Attribute 'd_optim' defined outside __init__","127":"Attribute 'g_optim' defined outside __init__","128":"Attribute 'clip_D' defined outside __init__","129":"Attribute 'fake_images' defined outside __init__","130":"Attribute 'g_sum' defined outside __init__","131":"Attribute 'd_sum' defined outside __init__","132":"Attribute 'sample_z' defined outside __init__","133":"Attribute 'saver' defined outside __init__","134":"Attribute 'writer' defined outside __init__","135":"Wildcard import ops","136":"Wildcard import utils","137":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","138":"Redefining built-in 'id'","139":"Attribute 'inputs' defined outside __init__","140":"Attribute 'z' defined outside __init__","141":"Attribute 'mu' defined outside __init__","142":"Attribute 'out' defined outside __init__","143":"Attribute 'neg_loglikelihood' defined outside __init__","144":"Attribute 'KL_divergence' defined outside __init__","145":"Attribute 'loss' defined outside __init__","146":"Attribute 'optim' defined outside __init__","147":"Attribute 'fake_images' defined outside __init__","148":"Attribute 'merged_summary_op' defined outside __init__","149":"Attribute 'sample_z' defined outside __init__","150":"Attribute 'saver' defined outside __init__","151":"Attribute 'writer' defined outside __init__","152":"Wildcard import ops","153":"Wildcard import utils","154":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","155":"Attribute 'inputs' defined outside __init__","156":"Attribute 'z' defined outside __init__","157":"Attribute 'd_loss' defined outside __init__","158":"Attribute 'g_loss' defined outside __init__","159":"Attribute 'd_optim' defined outside __init__","160":"Attribute 'g_optim' defined outside __init__","161":"Attribute 'clip_D' defined outside __init__","162":"Attribute 'fake_images' defined outside __init__","163":"Attribute 'g_sum' defined outside __init__","164":"Attribute 'd_sum' defined outside __init__","165":"Attribute 'sample_z' defined outside __init__","166":"Attribute 'saver' defined outside __init__","167":"Attribute 'writer' defined outside __init__","168":"Wildcard import ops","169":"Wildcard import utils","170":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","171":"Attribute 'inputs' defined outside __init__","172":"Attribute 'z' defined outside __init__","173":"Attribute 'd_loss' defined outside __init__","174":"Attribute 'g_loss' defined outside __init__","175":"Attribute 'd_optim' defined outside __init__","176":"Attribute 'g_optim' defined outside __init__","177":"Attribute 'fake_images' defined outside __init__","178":"Attribute 'g_sum' defined outside __init__","179":"Attribute 'd_sum' defined outside __init__","180":"Attribute 'sample_z' defined outside __init__","181":"Attribute 'saver' defined outside __init__","182":"Attribute 'writer' defined outside __init__","183":"Wildcard import ops","184":"Wildcard import utils","185":"Consider merging these comparisons with \"in\" to \"dataset_name in ('mnist', 'fashion-mnist')\"","186":"Comparison 'self.SUPERVISED == True' should be 'self.SUPERVISED is True' if checking for the singleton value True, or 'self.SUPERVISED' if testing for truthiness","187":"Attribute 'inputs' defined outside __init__","188":"Attribute 'y' defined outside __init__","189":"Attribute 'z' defined outside __init__","190":"Attribute 'd_loss' defined outside __init__","191":"Attribute 'g_loss' defined outside __init__","192":"Attribute 'q_loss' defined outside __init__","193":"Attribute 'd_optim' defined outside __init__","194":"Attribute 'g_optim' defined outside __init__","195":"Attribute 'q_optim' defined outside __init__","196":"Attribute 'fake_images' defined outside __init__","197":"Attribute 'g_sum' defined outside __init__","198":"Attribute 'd_sum' defined outside __init__","199":"Attribute 'q_sum' defined outside __init__","200":"Attribute 'sample_z' defined outside __init__","201":"Attribute 'test_labels' defined outside __init__","202":"Attribute 'test_codes' defined outside __init__","203":"Attribute 'saver' defined outside __init__","204":"Attribute 'writer' defined outside __init__","205":"Wildcard import utils","206":"Redefining built-in 'id'","207":"Similar lines in 2 files\n==WGAN:33\n==WGAN_GP:34\n            self.disc_iters = 1     # The number of critic iterations for one-step of generator\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = - tf.reduce_mean(D_real_logits)\n        d_loss_fake = tf.reduce_mean(D_fake_logits)\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = - d_loss_fake\n\n        \"\"\" Training \"\"\"\n        # divide trainable variables into a group for D and a group for G","208":"Similar lines in 2 files\n==EBGAN:190\n==LSGAN:178\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","209":"Similar lines in 3 files\n==DRAGAN:194\n==EBGAN:191\n==LSGAN:179\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","210":"Similar lines in 4 files\n==DRAGAN:197\n==EBGAN:194\n==LSGAN:182\n==WGAN:182\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","211":"Similar lines in 2 files\n==LSGAN:112\n==WGAN:111\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        # weight clipping\n        self.clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in d_vars]\n\n        \"\"\"\" Testing \"\"\"\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, _, summary_str, d_loss = self.sess.run([self.d_optim, self.clip_D, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network","212":"Similar lines in 5 files\n==DRAGAN:202\n==EBGAN:199\n==LSGAN:187\n==WGAN:187\n==WGAN_GP:198\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","213":"Similar lines in 2 files\n==GAN:111\n==WGAN_GP:123\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network","214":"Similar lines in 3 files\n==GAN:33\n==WGAN:36\n==WGAN_GP:37\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator","215":"Similar lines in 2 files\n==CGAN:238\n==CVAE:233\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n        \"\"\" specified condition, random noise \"\"\"\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n\n        for l in range(self.y_dim):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n            save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                        check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_class_%d.png' % l)\n\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        \"\"\" save merged images to check style-consistency \"\"\"\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):\n            for c in range(self.y_dim):\n                canvas[s * self.y_dim + c, :, :, :] = all_samples[c * n_styles + s, :, :, :]\n\n        save_images(canvas, [n_styles, self.y_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes_style_by_style.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","216":"Similar lines in 2 files\n==BEGAN:204\n==GAN:187\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images, feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","217":"Similar lines in 2 files\n==GAN:13\n==LSGAN:13\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n","218":"Similar lines in 7 files\n==BEGAN:206\n==DRAGAN:209\n==EBGAN:206\n==GAN:189\n==LSGAN:194\n==WGAN:194\n==WGAN_GP:205\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","219":"Similar lines in 2 files\n==EBGAN:145\n==GAN:129\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:","220":"Similar lines in 2 files\n==ACGAN:59\n==infoGAN:62\n            out_logit = linear(net, self.y_dim, scope='c_fc2')\n            out = tf.nn.softmax(out_logit)\n\n            return out, out_logit\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n\n            # merge noise and code\n            z = concat([z, y], 1)\n\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name='y')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n        ## 1. GAN Loss\n        # output of D for real images","221":"Similar lines in 3 files\n==DRAGAN:136\n==GAN:118\n==WGAN_GP:130\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]","222":"Similar lines in 4 files\n==GAN:124\n==LSGAN:128\n==WGAN:127\n==WGAN_GP:136\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network","223":"Similar lines in 2 files\n==EBGAN:145\n==WGAN_GP:141\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network","224":"Similar lines in 3 files\n==DRAGAN:142\n==LSGAN:128\n==WGAN:127\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]","225":"Similar lines in 3 files\n==BEGAN:149\n==EBGAN:152\n==GAN:136\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update k","226":"Similar lines in 3 files\n==ACGAN:69\n==CGAN:58\n==infoGAN:72\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n\n            # merge noise and code\n            z = concat([z, y], 1)\n\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name='y')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n        ## 1. GAN Loss\n        # output of D for real images","227":"Similar lines in 3 files\n==EBGAN:145\n==LSGAN:133\n==WGAN:132\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network","228":"Similar lines in 5 files\n==DRAGAN:36\n==GAN:33\n==LSGAN:33\n==WGAN:36\n==WGAN_GP:37\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n","229":"Similar lines in 2 files\n==BEGAN:149\n==WGAN_GP:148\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network","230":"Similar lines in 2 files\n==DRAGAN:147\n==EBGAN:145\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]","231":"Similar lines in 3 files\n==BEGAN:149\n==LSGAN:140\n==WGAN:139\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network","232":"Similar lines in 2 files\n==CGAN:13\n==CVAE:15\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.y_dim = 10         # dimension of condition-vector (label)\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    # Gaussian Encoder","233":"Similar lines in 3 files\n==GAN:13\n==LSGAN:13\n==VAE:15\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n","234":"Similar lines in 2 files\n==BEGAN:149\n==DRAGAN:154\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]","235":"Similar lines in 2 files\n==CGAN:204\n==CVAE:199\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z, self.y: self.test_labels})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n        y = np.random.choice(self.y_dim, self.batch_size)\n        y_one_hot = np.zeros((self.batch_size, self.y_dim))\n        y_one_hot[np.arange(self.batch_size), y] = 1\n","236":"Similar lines in 2 files\n==CGAN:156\n==CVAE:157\n        self.test_labels = self.data_y[0:self.batch_size]\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_labels = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network","237":"Similar lines in 3 files\n==ACGAN:306\n==CGAN:272\n==CVAE:267\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes_style_by_style.png')\n\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","238":"Similar lines in 4 files\n==EBGAN:83\n==GAN:61\n==WGAN:64\n==WGAN_GP:65\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images","239":"Similar lines in 2 files\n==BEGAN:59\n==EBGAN:75\n            net = tf.nn.relu(bn(linear(code, 64 * 14 * 14, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            net = tf.reshape(net, [self.batch_size, 14, 14, 64])\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='d_dc5'))\n\n            # recon loss\n            recon_error = tf.sqrt(2 * tf.nn.l2_loss(out - x)) \/ self.batch_size\n            return out, recon_error, code\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" BEGAN variable \"\"\"","240":"Similar lines in 12 files\n==ACGAN:308\n==BEGAN:239\n==CGAN:274\n==CVAE:269\n==DRAGAN:242\n==EBGAN:239\n==GAN:222\n==LSGAN:227\n==VAE:247\n==WGAN:227\n==WGAN_GP:238\n==infoGAN:355\n    @property\n    def model_dir(self):\n        return \"{}_{}_{}_{}\".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print(\" [*] Reading checkpoints...\")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n            print(\" [*] Success to read {}\".format(ckpt_name))\n            return True, counter\n        else:\n            print(\" [*] Failed to find a checkpoint\")\n            return False, 0","241":"Similar lines in 3 files\n==ACGAN:13\n==CGAN:13\n==CVAE:15\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.y_dim = 10         # dimension of condition-vector (label)\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist","242":"Similar lines in 2 files\n==CGAN:111\n==GAN:98\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        \"\"\" Training \"\"\"\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test","243":"Similar lines in 8 files\n==BEGAN:206\n==DRAGAN:209\n==EBGAN:206\n==GAN:189\n==LSGAN:194\n==VAE:189\n==WGAN:194\n==WGAN_GP:205\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"\n","244":"Similar lines in 2 files\n==DRAGAN:93\n==GAN:86\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        \"\"\" DRAGAN Loss (Gradient penalty) \"\"\"\n        # This is borrowed from https:\/\/github.com\/kodalinaveen3\/DRAGAN\/blob\/master\/DRAGAN.ipynb","245":"Similar lines in 11 files\n==BEGAN:206\n==CGAN:207\n==CVAE:202\n==DRAGAN:209\n==EBGAN:206\n==GAN:189\n==LSGAN:194\n==VAE:189\n==WGAN:194\n==WGAN_GP:205\n==infoGAN:260\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                '.\/' + check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_train_{:02d}_{:04d}.png'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        \"\"\" random condition, random noise \"\"\"","246":"Similar lines in 2 files\n==ACGAN:148\n==infoGAN:154\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n        q_vars = [var for var in t_vars if ('d_' in var.name) or ('c_' in var.name) or ('g_' in var.name)]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate * 5, beta1=self.beta1) \\\n                .minimize(self.g_loss, var_list=g_vars)\n            self.q_optim = tf.train.AdamOptimizer(self.learning_rate * 5, beta1=self.beta1) \\\n                .minimize(self.q_loss, var_list=q_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test\n        self.fake_images = self.generator(self.z, self.y, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        q_loss_sum = tf.summary.scalar(\"g_loss\", self.q_loss)","247":"Similar lines in 12 files\n==ACGAN:191\n==BEGAN:158\n==CGAN:159\n==CVAE:160\n==DRAGAN:163\n==EBGAN:161\n==GAN:145\n==LSGAN:149\n==VAE:147\n==WGAN:148\n==WGAN_GP:157\n==infoGAN:199\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + '\/' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter \/ self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print(\" [*] Load SUCCESS\")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print(\" [!] Load failed...\")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]","248":"Similar lines in 4 files\n==GAN:76\n==LSGAN:80\n==WGAN:79\n==WGAN_GP:80\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator","249":"Similar lines in 2 files\n==ACGAN:34\n==infoGAN:36\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # code\n            self.len_discrete_code = 10  # categorical distribution (i.e. label)\n            self.len_continuous_code = 2  # gaussian distribution (e.g. rotation, thickness)\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    def classifier(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)5c2s-(128)5c2s_BL-FC1024_BL-FC128_BL-FC12S\u2019\n        # All layers except the last two layers are shared by discriminator","250":"Similar lines in 2 files\n==DRAGAN:13\n==WGAN_GP:13\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # DRAGAN parameter\n            self.lambd = 0.25       # The higher value, the more stable, but the slower convergence","251":"Similar lines in 4 files\n==BEGAN:67\n==GAN:61\n==WGAN:64\n==WGAN_GP:65\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"","252":"Similar lines in 7 files\n==ACGAN:86\n==CGAN:75\n==EBGAN:87\n==GAN:65\n==WGAN:68\n==WGAN_GP:69\n==infoGAN:89\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises","253":"Similar lines in 2 files\n==BEGAN:121\n==EBGAN:127\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_error_real\", D_real_err)\n        d_loss_fake_sum = tf.summary.scalar(\"d_error_fake\", D_fake_err)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)","254":"Similar lines in 8 files\n==BEGAN:13\n==DRAGAN:13\n==EBGAN:13\n==GAN:13\n==LSGAN:13\n==VAE:15\n==WGAN:13\n==WGAN_GP:13\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # train","255":"Similar lines in 6 files\n==BEGAN:37\n==DRAGAN:36\n==GAN:33\n==LSGAN:33\n==WGAN:36\n==WGAN_GP:37\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n","256":"Similar lines in 4 files\n==ACGAN:95\n==CGAN:84\n==CVAE:92\n==infoGAN:98\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name='y')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n        ## 1. GAN Loss","257":"Similar lines in 3 files\n==CGAN:31\n==CVAE:33\n==VAE:32\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n","258":"Similar lines in 12 files\n==ACGAN:247\n==BEGAN:211\n==CGAN:212\n==CVAE:207\n==DRAGAN:214\n==EBGAN:211\n==GAN:194\n==LSGAN:199\n==VAE:194\n==WGAN:199\n==WGAN_GP:210\n==infoGAN:265\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))","259":"Similar lines in 4 files\n==CGAN:31\n==CVAE:33\n==GAN:30\n==LSGAN:30\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n","260":"Similar lines in 2 files\n==ACGAN:118\n==infoGAN:121\n        G = self.generator(self.z, self.y, is_training=True, reuse=False)\n        D_fake, D_fake_logits, input4classifier_fake = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        ## 2. Information Loss\n        code_fake, code_logit_fake = self.classifier(input4classifier_fake, is_training=True, reuse=False)","261":"Similar lines in 4 files\n==ACGAN:86\n==BEGAN:71\n==CGAN:75\n==infoGAN:89\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" BEGAN variable \"\"\"","262":"Similar lines in 11 files\n==ACGAN:13\n==BEGAN:13\n==CGAN:13\n==CVAE:15\n==DRAGAN:13\n==EBGAN:13\n==GAN:13\n==LSGAN:13\n==VAE:15\n==WGAN:13\n==WGAN_GP:13\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector","263":"Similar lines in 5 files\n==EBGAN:96\n==GAN:74\n==VAE:82\n==WGAN:77\n==WGAN_GP:78\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n","264":"Similar lines in 2 files\n==CVAE:124\n==VAE:112\n        self.neg_loglikelihood = -tf.reduce_mean(marginal_likelihood)\n        self.KL_divergence = tf.reduce_mean(KL_divergence)\n\n        ELBO = -self.neg_loglikelihood - self.KL_divergence\n\n        self.loss = -ELBO\n\n        \"\"\" Training \"\"\"\n        # optimizers\n        t_vars = tf.trainable_variables()\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.loss, var_list=t_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test","265":"Similar lines in 2 files\n==CGAN:233\n==infoGAN:286\n        y_one_hot = np.zeros((self.batch_size, self.y_dim))\n        y_one_hot[np.arange(self.batch_size), y] = 1\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n        \"\"\" specified condition, random noise \"\"\"\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n","266":"Similar lines in 6 files\n==CGAN:140\n==DRAGAN:145\n==GAN:127\n==LSGAN:131\n==WGAN:130\n==WGAN_GP:139\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))","267":"Similar lines in 4 files\n==BEGAN:121\n==EBGAN:127\n==GAN:111\n==WGAN_GP:123\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"","268":"Similar lines in 2 files\n==ACGAN:292\n==infoGAN:311\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        \"\"\" save merged images to check style-consistency \"\"\"\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):\n            for c in range(self.len_discrete_code):\n                canvas[s * self.len_discrete_code + c, :, :, :] = all_samples[c * n_styles + s, :, :, :]\n\n        save_images(canvas, [n_styles, self.len_discrete_code],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes_style_by_style.png')\n","269":"Similar lines in 12 files\n==ACGAN:14\n==BEGAN:14\n==CGAN:14\n==CVAE:16\n==DRAGAN:14\n==EBGAN:14\n==GAN:14\n==LSGAN:14\n==VAE:16\n==WGAN:14\n==WGAN_GP:14\n==infoGAN:14\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == 'mnist' or dataset_name == 'fashion-mnist':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector","270":"Similar lines in 2 files\n==EBGAN:98\n==LSGAN:80\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images","271":"Similar lines in 2 files\n==DRAGAN:120\n==WGAN_GP:114\n        interpolates = self.inputs + (alpha * differences)\n        _,D_inter,_=self.discriminator(interpolates, is_training=True, reuse=True)\n        gradients = tf.gradients(D_inter, [interpolates])[0]\n        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n        gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n        self.d_loss += self.lambd * gradient_penalty\n\n        \"\"\" Training \"\"\"\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):","272":"Similar lines in 2 files\n==CVAE:60\n==VAE:55\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='en_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='en_conv2'), is_training=is_training, scope='en_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='en_fc3'), is_training=is_training, scope='en_bn3'))\n            gaussian_params = linear(net, 2 * self.z_dim, scope='en_fc4')\n\n            # The mean parameter is unconstrained\n            mean = gaussian_params[:, :self.z_dim]\n            # The standard deviation must be positive. Parametrize with a softplus and\n            # add a small epsilon for numerical stability\n            stddev = 1e-6 + tf.nn.softplus(gaussian_params[:, self.z_dim:])\n\n        return mean, stddev\n\n    # Bernoulli decoder","273":"Similar lines in 4 files\n==CGAN:34\n==CVAE:36\n==EBGAN:38\n==VAE:35\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n\n    # borrowed from https:\/\/github.com\/shekkizh\/EBGAN.tensorflow\/blob\/master\/EBGAN\/Faces_EBGAN.py","274":"Similar lines in 2 files\n==BEGAN:92\n==EBGAN:105\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n\n        # output of D for real images\n        D_real_img, D_real_err, D_real_code = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake_img, D_fake_err, D_fake_code = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator","275":"Similar lines in 4 files\n==BEGAN:67\n==DRAGAN:64\n==EBGAN:83\n==LSGAN:61\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(\"generator\", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n","276":"Similar lines in 2 files\n==ACGAN:230\n==infoGAN:248\n                self.writer.add_summary(summary_str_g, counter)\n                self.writer.add_summary(summary_str_q, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z, self.y: self.test_codes})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))","277":"Similar lines in 2 files\n==LSGAN:80\n==VAE:84\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name='z')\n\n        \"\"\" Loss Function \"\"\"\n","278":"Similar lines in 2 files\n==GAN:174\n==LSGAN:178\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:","279":"Similar lines in 2 files\n==CVAE:143\n==VAE:131\n        nll_sum = tf.summary.scalar(\"nll\", self.neg_loglikelihood)\n        kl_sum = tf.summary.scalar(\"kl\", self.KL_divergence)\n        loss_sum = tf.summary.scalar(\"loss\", self.loss)\n\n        # final summary operations\n        self.merged_summary_op = tf.summary.merge_all()\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = prior.gaussian(self.batch_size, self.z_dim)","280":"Similar lines in 2 files\n==CGAN:142\n==EBGAN:145\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))","281":"Similar lines in 10 files\n==BEGAN:37\n==CGAN:34\n==CVAE:36\n==DRAGAN:36\n==EBGAN:38\n==GAN:33\n==LSGAN:33\n==VAE:35\n==WGAN:36\n==WGAN_GP:37\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) \/\/ self.batch_size\n        else:\n            raise NotImplementedError\n","282":"Similar lines in 2 files\n==ACGAN:275\n==infoGAN:294\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n        \"\"\" specified condition, random noise \"\"\"\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n\n        for l in range(self.len_discrete_code):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})","283":"Similar lines in 7 files\n==ACGAN:64\n==DRAGAN:50\n==GAN:47\n==LSGAN:47\n==WGAN:50\n==WGAN_GP:51\n==infoGAN:67\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https:\/\/arxiv.org\/abs\/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(\"discriminator\", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n","284":"Similar lines in 2 files\n==DRAGAN:194\n==GAN:175\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:","285":"Similar lines in 2 files\n==CGAN:111\n==DRAGAN:105\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        \"\"\" DRAGAN Loss (Gradient penalty) \"\"\"\n        # This is borrowed from https:\/\/github.com\/kodalinaveen3\/DRAGAN\/blob\/master\/DRAGAN.ipynb","286":"Similar lines in 4 files\n==BEGAN:121\n==CGAN:124\n==EBGAN:127\n==WGAN_GP:123\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"\n        # for test","287":"Similar lines in 3 files\n==CVAE:92\n==EBGAN:96\n==GAN:74\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # labels","288":"Similar lines in 7 files\n==BEGAN:121\n==CGAN:124\n==EBGAN:127\n==GAN:111\n==LSGAN:112\n==WGAN:111\n==WGAN_GP:123\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if 'd_' in var.name]\n        g_vars = [var for var in t_vars if 'g_' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        \"\"\"\" Testing \"\"\"","289":"Similar lines in 7 files\n==ACGAN:95\n==CGAN:84\n==CVAE:92\n==VAE:82\n==WGAN:77\n==WGAN_GP:78\n==infoGAN:98\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        \"\"\" Graph Input \"\"\"\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name='real_images')\n\n        # noises","290":"Similar lines in 3 files\n==ACGAN:290\n==CGAN:256\n==CVAE:251\n                        check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_class_%d.png' % l)\n\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        \"\"\" save merged images to check style-consistency \"\"\"\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):","291":"Similar lines in 5 files\n==ACGAN:122\n==CGAN:111\n==DRAGAN:105\n==GAN:98\n==infoGAN:125\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        \"\"\" DRAGAN Loss (Gradient penalty) \"\"\"","292":"Similar lines in 2 files\n==CVAE:233\n==infoGAN:291\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + '\/' + self.model_dir) + '\/' + self.model_name + '_epoch%03d' % epoch + '_test_all_classes.png')\n\n        \"\"\" specified condition, random noise \"\"\"\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n","293":"Similar lines in 2 files\n==CVAE:1\n==VAE:1\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nimport prior_factory as prior\n","294":"Similar lines in 2 files\n==ACGAN:218\n==infoGAN:236\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                                       feed_dict={self.inputs: batch_images, self.y: batch_codes,\n                                                                  self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G & Q network\n                _, summary_str_g, g_loss, _, summary_str_q, q_loss = self.sess.run(\n                    [self.g_optim, self.g_sum, self.g_loss, self.q_optim, self.q_sum, self.q_loss],","295":"Similar lines in 5 files\n==ACGAN:86\n==CGAN:75\n==DRAGAN:68\n==LSGAN:65\n==infoGAN:89\n            net = tf.nn.relu(bn(linear(z, 1024, scope='g_fc1'), is_training=is_training, scope='g_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='g_fc2'), is_training=is_training, scope='g_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='g_dc3'), is_training=is_training,\n                   scope='g_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='g_dc4'))\n\n            return out\n","296":"Similar lines in 2 files\n==GAN:178\n==WGAN:182\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:","297":"Similar lines in 2 files\n==CVAE:191\n==VAE:177\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, loss: %.8f, nll: %.8f, kl: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, loss, nll_loss, kl_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,","298":"Similar lines in 3 files\n==CGAN:258\n==CVAE:253\n==infoGAN:311\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        \"\"\" save merged images to check style-consistency \"\"\"\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):","299":"Similar lines in 5 files\n==CGAN:196\n==DRAGAN:198\n==EBGAN:195\n==LSGAN:183\n==WGAN:183\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,","300":"Similar lines in 2 files\n==CGAN:196\n==GAN:179\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:","301":"Similar lines in 6 files\n==CGAN:58\n==DRAGAN:55\n==GAN:52\n==LSGAN:52\n==WGAN:55\n==WGAN_GP:56\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n            out_logit = linear(net, 1, scope='d_fc4')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n","302":"Similar lines in 12 files\n==ACGAN:1\n==BEGAN:1\n==CGAN:1\n==CVAE:1\n==DRAGAN:1\n==EBGAN:1\n==GAN:1\n==LSGAN:1\n==VAE:1\n==WGAN:1\n==WGAN_GP:1\n==infoGAN:1\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n","303":"Similar lines in 2 files\n==CVAE:83\n==VAE:74\n            net = tf.nn.relu(bn(linear(z, 1024, scope='de_fc1'), is_training=is_training, scope='de_bn1'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope='de_fc2'), is_training=is_training, scope='de_bn2'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name='de_dc3'), is_training=is_training,\n                   scope='de_bn3'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name='de_dc4'))","304":"Similar lines in 3 files\n==ACGAN:164\n==CGAN:137\n==infoGAN:170\n        self.fake_images = self.generator(self.z, self.y, is_training=False, reuse=True)\n\n        \"\"\" Summary \"\"\"\n        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n","305":"Similar lines in 7 files\n==ACGAN:234\n==CGAN:199\n==DRAGAN:201\n==EBGAN:198\n==LSGAN:186\n==WGAN:186\n==infoGAN:252\n                counter += 1\n                print(\"Epoch: [%2d] [%4d\/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,"},"number":{"0":"W0401","1":"W0401","2":"R1714","3":"W0201","4":"W0201","5":"W0201","6":"W0201","7":"W0201","8":"W0201","9":"W0201","10":"W0201","11":"W0201","12":"W0201","13":"W0201","14":"W0201","15":"W0201","16":"W0201","17":"W0201","18":"W0201","19":"W0201","20":"W0401","21":"W0401","22":"R1714","23":"W0201","24":"W0201","25":"W0201","26":"W0201","27":"W0201","28":"W0201","29":"W0201","30":"W0201","31":"W0201","32":"W0201","33":"W0201","34":"W0201","35":"W0201","36":"W0201","37":"W0201","38":"W0201","39":"W0401","40":"W0401","41":"R1714","42":"W0201","43":"W0201","44":"W0201","45":"W0201","46":"W0201","47":"W0201","48":"W0201","49":"W0201","50":"W0201","51":"W0201","52":"W0201","53":"W0201","54":"W0201","55":"W0201","56":"W0401","57":"W0401","58":"R1714","59":"W0201","60":"W0201","61":"W0201","62":"W0201","63":"W0201","64":"W0201","65":"W0201","66":"W0201","67":"W0201","68":"W0201","69":"W0201","70":"W0201","71":"W0201","72":"W0201","73":"W0401","74":"W0401","75":"R1714","76":"W0201","77":"W0201","78":"W0201","79":"W0201","80":"W0201","81":"W0201","82":"W0201","83":"W0201","84":"W0201","85":"W0201","86":"W0201","87":"W0201","88":"W0201","89":"W0401","90":"W0401","91":"R1714","92":"W0201","93":"W0201","94":"W0201","95":"W0201","96":"W0201","97":"W0201","98":"W0201","99":"W0201","100":"W0201","101":"W0201","102":"W0201","103":"W0201","104":"W0401","105":"W0401","106":"R1714","107":"W0201","108":"W0201","109":"W0201","110":"W0201","111":"W0201","112":"W0201","113":"W0201","114":"W0201","115":"W0201","116":"W0201","117":"W0201","118":"W0201","119":"W0401","120":"W0401","121":"R1714","122":"W0201","123":"W0201","124":"W0201","125":"W0201","126":"W0201","127":"W0201","128":"W0201","129":"W0201","130":"W0201","131":"W0201","132":"W0201","133":"W0201","134":"W0201","135":"W0401","136":"W0401","137":"R1714","138":"W0622","139":"W0201","140":"W0201","141":"W0201","142":"W0201","143":"W0201","144":"W0201","145":"W0201","146":"W0201","147":"W0201","148":"W0201","149":"W0201","150":"W0201","151":"W0201","152":"W0401","153":"W0401","154":"R1714","155":"W0201","156":"W0201","157":"W0201","158":"W0201","159":"W0201","160":"W0201","161":"W0201","162":"W0201","163":"W0201","164":"W0201","165":"W0201","166":"W0201","167":"W0201","168":"W0401","169":"W0401","170":"R1714","171":"W0201","172":"W0201","173":"W0201","174":"W0201","175":"W0201","176":"W0201","177":"W0201","178":"W0201","179":"W0201","180":"W0201","181":"W0201","182":"W0201","183":"W0401","184":"W0401","185":"R1714","186":"C0121","187":"W0201","188":"W0201","189":"W0201","190":"W0201","191":"W0201","192":"W0201","193":"W0201","194":"W0201","195":"W0201","196":"W0201","197":"W0201","198":"W0201","199":"W0201","200":"W0201","201":"W0201","202":"W0201","203":"W0201","204":"W0201","205":"W0401","206":"W0622","207":"R0801","208":"R0801","209":"R0801","210":"R0801","211":"R0801","212":"R0801","213":"R0801","214":"R0801","215":"R0801","216":"R0801","217":"R0801","218":"R0801","219":"R0801","220":"R0801","221":"R0801","222":"R0801","223":"R0801","224":"R0801","225":"R0801","226":"R0801","227":"R0801","228":"R0801","229":"R0801","230":"R0801","231":"R0801","232":"R0801","233":"R0801","234":"R0801","235":"R0801","236":"R0801","237":"R0801","238":"R0801","239":"R0801","240":"R0801","241":"R0801","242":"R0801","243":"R0801","244":"R0801","245":"R0801","246":"R0801","247":"R0801","248":"R0801","249":"R0801","250":"R0801","251":"R0801","252":"R0801","253":"R0801","254":"R0801","255":"R0801","256":"R0801","257":"R0801","258":"R0801","259":"R0801","260":"R0801","261":"R0801","262":"R0801","263":"R0801","264":"R0801","265":"R0801","266":"R0801","267":"R0801","268":"R0801","269":"R0801","270":"R0801","271":"R0801","272":"R0801","273":"R0801","274":"R0801","275":"R0801","276":"R0801","277":"R0801","278":"R0801","279":"R0801","280":"R0801","281":"R0801","282":"R0801","283":"R0801","284":"R0801","285":"R0801","286":"R0801","287":"R0801","288":"R0801","289":"R0801","290":"R0801","291":"R0801","292":"R0801","293":"R0801","294":"R0801","295":"R0801","296":"R0801","297":"R0801","298":"R0801","299":"R0801","300":"R0801","301":"R0801","302":"R0801","303":"R0801","304":"R0801","305":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint","36":"pylint","37":"pylint","38":"pylint","39":"pylint","40":"pylint","41":"pylint","42":"pylint","43":"pylint","44":"pylint","45":"pylint","46":"pylint","47":"pylint","48":"pylint","49":"pylint","50":"pylint","51":"pylint","52":"pylint","53":"pylint","54":"pylint","55":"pylint","56":"pylint","57":"pylint","58":"pylint","59":"pylint","60":"pylint","61":"pylint","62":"pylint","63":"pylint","64":"pylint","65":"pylint","66":"pylint","67":"pylint","68":"pylint","69":"pylint","70":"pylint","71":"pylint","72":"pylint","73":"pylint","74":"pylint","75":"pylint","76":"pylint","77":"pylint","78":"pylint","79":"pylint","80":"pylint","81":"pylint","82":"pylint","83":"pylint","84":"pylint","85":"pylint","86":"pylint","87":"pylint","88":"pylint","89":"pylint","90":"pylint","91":"pylint","92":"pylint","93":"pylint","94":"pylint","95":"pylint","96":"pylint","97":"pylint","98":"pylint","99":"pylint","100":"pylint","101":"pylint","102":"pylint","103":"pylint","104":"pylint","105":"pylint","106":"pylint","107":"pylint","108":"pylint","109":"pylint","110":"pylint","111":"pylint","112":"pylint","113":"pylint","114":"pylint","115":"pylint","116":"pylint","117":"pylint","118":"pylint","119":"pylint","120":"pylint","121":"pylint","122":"pylint","123":"pylint","124":"pylint","125":"pylint","126":"pylint","127":"pylint","128":"pylint","129":"pylint","130":"pylint","131":"pylint","132":"pylint","133":"pylint","134":"pylint","135":"pylint","136":"pylint","137":"pylint","138":"pylint","139":"pylint","140":"pylint","141":"pylint","142":"pylint","143":"pylint","144":"pylint","145":"pylint","146":"pylint","147":"pylint","148":"pylint","149":"pylint","150":"pylint","151":"pylint","152":"pylint","153":"pylint","154":"pylint","155":"pylint","156":"pylint","157":"pylint","158":"pylint","159":"pylint","160":"pylint","161":"pylint","162":"pylint","163":"pylint","164":"pylint","165":"pylint","166":"pylint","167":"pylint","168":"pylint","169":"pylint","170":"pylint","171":"pylint","172":"pylint","173":"pylint","174":"pylint","175":"pylint","176":"pylint","177":"pylint","178":"pylint","179":"pylint","180":"pylint","181":"pylint","182":"pylint","183":"pylint","184":"pylint","185":"pylint","186":"pylint","187":"pylint","188":"pylint","189":"pylint","190":"pylint","191":"pylint","192":"pylint","193":"pylint","194":"pylint","195":"pylint","196":"pylint","197":"pylint","198":"pylint","199":"pylint","200":"pylint","201":"pylint","202":"pylint","203":"pylint","204":"pylint","205":"pylint","206":"pylint","207":"pylint","208":"pylint","209":"pylint","210":"pylint","211":"pylint","212":"pylint","213":"pylint","214":"pylint","215":"pylint","216":"pylint","217":"pylint","218":"pylint","219":"pylint","220":"pylint","221":"pylint","222":"pylint","223":"pylint","224":"pylint","225":"pylint","226":"pylint","227":"pylint","228":"pylint","229":"pylint","230":"pylint","231":"pylint","232":"pylint","233":"pylint","234":"pylint","235":"pylint","236":"pylint","237":"pylint","238":"pylint","239":"pylint","240":"pylint","241":"pylint","242":"pylint","243":"pylint","244":"pylint","245":"pylint","246":"pylint","247":"pylint","248":"pylint","249":"pylint","250":"pylint","251":"pylint","252":"pylint","253":"pylint","254":"pylint","255":"pylint","256":"pylint","257":"pylint","258":"pylint","259":"pylint","260":"pylint","261":"pylint","262":"pylint","263":"pylint","264":"pylint","265":"pylint","266":"pylint","267":"pylint","268":"pylint","269":"pylint","270":"pylint","271":"pylint","272":"pylint","273":"pylint","274":"pylint","275":"pylint","276":"pylint","277":"pylint","278":"pylint","279":"pylint","280":"pylint","281":"pylint","282":"pylint","283":"pylint","284":"pylint","285":"pylint","286":"pylint","287":"pylint","288":"pylint","289":"pylint","290":"pylint","291":"pylint","292":"pylint","293":"pylint","294":"pylint","295":"pylint","296":"pylint","297":"pylint","298":"pylint","299":"pylint","300":"pylint","301":"pylint","302":"pylint","303":"pylint","304":"pylint","305":"pylint"},"lines_amount":{"0":337,"1":337,"2":337,"3":337,"4":337,"5":337,"6":337,"7":337,"8":337,"9":337,"10":337,"11":337,"12":337,"13":337,"14":337,"15":337,"16":337,"17":337,"18":337,"19":337,"20":269,"21":269,"22":269,"23":269,"24":269,"25":269,"26":269,"27":269,"28":269,"29":269,"30":269,"31":269,"32":269,"33":269,"34":269,"35":269,"36":269,"37":269,"38":269,"39":304,"40":304,"41":304,"42":304,"43":304,"44":304,"45":304,"46":304,"47":304,"48":304,"49":304,"50":304,"51":304,"52":304,"53":304,"54":304,"55":304,"56":298,"57":298,"58":298,"59":298,"60":298,"61":298,"62":298,"63":298,"64":298,"65":298,"66":298,"67":298,"68":298,"69":298,"70":298,"71":298,"72":298,"73":271,"74":271,"75":271,"76":271,"77":271,"78":271,"79":271,"80":271,"81":271,"82":271,"83":271,"84":271,"85":271,"86":271,"87":271,"88":271,"89":268,"90":268,"91":268,"92":268,"93":268,"94":268,"95":268,"96":268,"97":268,"98":268,"99":268,"100":268,"101":268,"102":268,"103":268,"104":252,"105":252,"106":252,"107":252,"108":252,"109":252,"110":252,"111":252,"112":252,"113":252,"114":252,"115":252,"116":252,"117":252,"118":252,"119":256,"120":256,"121":256,"122":256,"123":256,"124":256,"125":256,"126":256,"127":256,"128":256,"129":256,"130":256,"131":256,"132":256,"133":256,"134":256,"135":276,"136":276,"137":276,"138":276,"139":276,"140":276,"141":276,"142":276,"143":276,"144":276,"145":276,"146":276,"147":276,"148":276,"149":276,"150":276,"151":276,"152":256,"153":256,"154":256,"155":256,"156":256,"157":256,"158":256,"159":256,"160":256,"161":256,"162":256,"163":256,"164":256,"165":256,"166":256,"167":256,"168":267,"169":267,"170":267,"171":267,"172":267,"173":267,"174":267,"175":267,"176":267,"177":267,"178":267,"179":267,"180":267,"181":267,"182":267,"183":385,"184":385,"185":385,"186":385,"187":385,"188":385,"189":385,"190":385,"191":385,"192":385,"193":385,"194":385,"195":385,"196":385,"197":385,"198":385,"199":385,"200":385,"201":385,"202":385,"203":385,"204":385,"205":84,"206":149,"207":149,"208":149,"209":149,"210":149,"211":149,"212":149,"213":149,"214":149,"215":149,"216":149,"217":149,"218":149,"219":149,"220":149,"221":149,"222":149,"223":149,"224":149,"225":149,"226":149,"227":149,"228":149,"229":149,"230":149,"231":149,"232":149,"233":149,"234":149,"235":149,"236":149,"237":149,"238":149,"239":149,"240":149,"241":149,"242":149,"243":149,"244":149,"245":149,"246":149,"247":149,"248":149,"249":149,"250":149,"251":149,"252":149,"253":149,"254":149,"255":149,"256":149,"257":149,"258":149,"259":149,"260":149,"261":149,"262":149,"263":149,"264":149,"265":149,"266":149,"267":149,"268":149,"269":149,"270":149,"271":149,"272":149,"273":149,"274":149,"275":149,"276":149,"277":149,"278":149,"279":149,"280":149,"281":149,"282":149,"283":149,"284":149,"285":149,"286":149,"287":149,"288":149,"289":149,"290":149,"291":149,"292":149,"293":149,"294":149,"295":149,"296":149,"297":149,"298":149,"299":149,"300":149,"301":149,"302":149,"303":149,"304":149,"305":149},"commit":{"0":"3abde8a9bcfe31815da50347d14641ec95096f62","1":"3abde8a9bcfe31815da50347d14641ec95096f62","2":"3abde8a9bcfe31815da50347d14641ec95096f62","3":"3abde8a9bcfe31815da50347d14641ec95096f62","4":"3abde8a9bcfe31815da50347d14641ec95096f62","5":"3abde8a9bcfe31815da50347d14641ec95096f62","6":"3abde8a9bcfe31815da50347d14641ec95096f62","7":"3abde8a9bcfe31815da50347d14641ec95096f62","8":"3abde8a9bcfe31815da50347d14641ec95096f62","9":"3abde8a9bcfe31815da50347d14641ec95096f62","10":"3abde8a9bcfe31815da50347d14641ec95096f62","11":"3abde8a9bcfe31815da50347d14641ec95096f62","12":"3abde8a9bcfe31815da50347d14641ec95096f62","13":"3abde8a9bcfe31815da50347d14641ec95096f62","14":"3abde8a9bcfe31815da50347d14641ec95096f62","15":"3abde8a9bcfe31815da50347d14641ec95096f62","16":"3abde8a9bcfe31815da50347d14641ec95096f62","17":"3abde8a9bcfe31815da50347d14641ec95096f62","18":"3abde8a9bcfe31815da50347d14641ec95096f62","19":"3abde8a9bcfe31815da50347d14641ec95096f62","20":"3abde8a9bcfe31815da50347d14641ec95096f62","21":"3abde8a9bcfe31815da50347d14641ec95096f62","22":"3abde8a9bcfe31815da50347d14641ec95096f62","23":"3abde8a9bcfe31815da50347d14641ec95096f62","24":"3abde8a9bcfe31815da50347d14641ec95096f62","25":"3abde8a9bcfe31815da50347d14641ec95096f62","26":"3abde8a9bcfe31815da50347d14641ec95096f62","27":"3abde8a9bcfe31815da50347d14641ec95096f62","28":"3abde8a9bcfe31815da50347d14641ec95096f62","29":"3abde8a9bcfe31815da50347d14641ec95096f62","30":"3abde8a9bcfe31815da50347d14641ec95096f62","31":"3abde8a9bcfe31815da50347d14641ec95096f62","32":"3abde8a9bcfe31815da50347d14641ec95096f62","33":"3abde8a9bcfe31815da50347d14641ec95096f62","34":"3abde8a9bcfe31815da50347d14641ec95096f62","35":"3abde8a9bcfe31815da50347d14641ec95096f62","36":"3abde8a9bcfe31815da50347d14641ec95096f62","37":"3abde8a9bcfe31815da50347d14641ec95096f62","38":"3abde8a9bcfe31815da50347d14641ec95096f62","39":"3abde8a9bcfe31815da50347d14641ec95096f62","40":"3abde8a9bcfe31815da50347d14641ec95096f62","41":"3abde8a9bcfe31815da50347d14641ec95096f62","42":"3abde8a9bcfe31815da50347d14641ec95096f62","43":"3abde8a9bcfe31815da50347d14641ec95096f62","44":"3abde8a9bcfe31815da50347d14641ec95096f62","45":"3abde8a9bcfe31815da50347d14641ec95096f62","46":"3abde8a9bcfe31815da50347d14641ec95096f62","47":"3abde8a9bcfe31815da50347d14641ec95096f62","48":"3abde8a9bcfe31815da50347d14641ec95096f62","49":"3abde8a9bcfe31815da50347d14641ec95096f62","50":"3abde8a9bcfe31815da50347d14641ec95096f62","51":"3abde8a9bcfe31815da50347d14641ec95096f62","52":"3abde8a9bcfe31815da50347d14641ec95096f62","53":"3abde8a9bcfe31815da50347d14641ec95096f62","54":"3abde8a9bcfe31815da50347d14641ec95096f62","55":"3abde8a9bcfe31815da50347d14641ec95096f62","56":"3abde8a9bcfe31815da50347d14641ec95096f62","57":"3abde8a9bcfe31815da50347d14641ec95096f62","58":"3abde8a9bcfe31815da50347d14641ec95096f62","59":"3abde8a9bcfe31815da50347d14641ec95096f62","60":"3abde8a9bcfe31815da50347d14641ec95096f62","61":"3abde8a9bcfe31815da50347d14641ec95096f62","62":"3abde8a9bcfe31815da50347d14641ec95096f62","63":"3abde8a9bcfe31815da50347d14641ec95096f62","64":"3abde8a9bcfe31815da50347d14641ec95096f62","65":"3abde8a9bcfe31815da50347d14641ec95096f62","66":"3abde8a9bcfe31815da50347d14641ec95096f62","67":"3abde8a9bcfe31815da50347d14641ec95096f62","68":"3abde8a9bcfe31815da50347d14641ec95096f62","69":"3abde8a9bcfe31815da50347d14641ec95096f62","70":"3abde8a9bcfe31815da50347d14641ec95096f62","71":"3abde8a9bcfe31815da50347d14641ec95096f62","72":"3abde8a9bcfe31815da50347d14641ec95096f62","73":"3abde8a9bcfe31815da50347d14641ec95096f62","74":"3abde8a9bcfe31815da50347d14641ec95096f62","75":"3abde8a9bcfe31815da50347d14641ec95096f62","76":"3abde8a9bcfe31815da50347d14641ec95096f62","77":"3abde8a9bcfe31815da50347d14641ec95096f62","78":"3abde8a9bcfe31815da50347d14641ec95096f62","79":"3abde8a9bcfe31815da50347d14641ec95096f62","80":"3abde8a9bcfe31815da50347d14641ec95096f62","81":"3abde8a9bcfe31815da50347d14641ec95096f62","82":"3abde8a9bcfe31815da50347d14641ec95096f62","83":"3abde8a9bcfe31815da50347d14641ec95096f62","84":"3abde8a9bcfe31815da50347d14641ec95096f62","85":"3abde8a9bcfe31815da50347d14641ec95096f62","86":"3abde8a9bcfe31815da50347d14641ec95096f62","87":"3abde8a9bcfe31815da50347d14641ec95096f62","88":"3abde8a9bcfe31815da50347d14641ec95096f62","89":"3abde8a9bcfe31815da50347d14641ec95096f62","90":"3abde8a9bcfe31815da50347d14641ec95096f62","91":"3abde8a9bcfe31815da50347d14641ec95096f62","92":"3abde8a9bcfe31815da50347d14641ec95096f62","93":"3abde8a9bcfe31815da50347d14641ec95096f62","94":"3abde8a9bcfe31815da50347d14641ec95096f62","95":"3abde8a9bcfe31815da50347d14641ec95096f62","96":"3abde8a9bcfe31815da50347d14641ec95096f62","97":"3abde8a9bcfe31815da50347d14641ec95096f62","98":"3abde8a9bcfe31815da50347d14641ec95096f62","99":"3abde8a9bcfe31815da50347d14641ec95096f62","100":"3abde8a9bcfe31815da50347d14641ec95096f62","101":"3abde8a9bcfe31815da50347d14641ec95096f62","102":"3abde8a9bcfe31815da50347d14641ec95096f62","103":"3abde8a9bcfe31815da50347d14641ec95096f62","104":"3abde8a9bcfe31815da50347d14641ec95096f62","105":"3abde8a9bcfe31815da50347d14641ec95096f62","106":"3abde8a9bcfe31815da50347d14641ec95096f62","107":"3abde8a9bcfe31815da50347d14641ec95096f62","108":"3abde8a9bcfe31815da50347d14641ec95096f62","109":"3abde8a9bcfe31815da50347d14641ec95096f62","110":"3abde8a9bcfe31815da50347d14641ec95096f62","111":"3abde8a9bcfe31815da50347d14641ec95096f62","112":"3abde8a9bcfe31815da50347d14641ec95096f62","113":"3abde8a9bcfe31815da50347d14641ec95096f62","114":"3abde8a9bcfe31815da50347d14641ec95096f62","115":"3abde8a9bcfe31815da50347d14641ec95096f62","116":"3abde8a9bcfe31815da50347d14641ec95096f62","117":"3abde8a9bcfe31815da50347d14641ec95096f62","118":"3abde8a9bcfe31815da50347d14641ec95096f62","119":"3abde8a9bcfe31815da50347d14641ec95096f62","120":"3abde8a9bcfe31815da50347d14641ec95096f62","121":"3abde8a9bcfe31815da50347d14641ec95096f62","122":"3abde8a9bcfe31815da50347d14641ec95096f62","123":"3abde8a9bcfe31815da50347d14641ec95096f62","124":"3abde8a9bcfe31815da50347d14641ec95096f62","125":"3abde8a9bcfe31815da50347d14641ec95096f62","126":"3abde8a9bcfe31815da50347d14641ec95096f62","127":"3abde8a9bcfe31815da50347d14641ec95096f62","128":"3abde8a9bcfe31815da50347d14641ec95096f62","129":"3abde8a9bcfe31815da50347d14641ec95096f62","130":"3abde8a9bcfe31815da50347d14641ec95096f62","131":"3abde8a9bcfe31815da50347d14641ec95096f62","132":"3abde8a9bcfe31815da50347d14641ec95096f62","133":"3abde8a9bcfe31815da50347d14641ec95096f62","134":"3abde8a9bcfe31815da50347d14641ec95096f62","135":"3abde8a9bcfe31815da50347d14641ec95096f62","136":"3abde8a9bcfe31815da50347d14641ec95096f62","137":"3abde8a9bcfe31815da50347d14641ec95096f62","138":"3abde8a9bcfe31815da50347d14641ec95096f62","139":"3abde8a9bcfe31815da50347d14641ec95096f62","140":"3abde8a9bcfe31815da50347d14641ec95096f62","141":"3abde8a9bcfe31815da50347d14641ec95096f62","142":"3abde8a9bcfe31815da50347d14641ec95096f62","143":"3abde8a9bcfe31815da50347d14641ec95096f62","144":"3abde8a9bcfe31815da50347d14641ec95096f62","145":"3abde8a9bcfe31815da50347d14641ec95096f62","146":"3abde8a9bcfe31815da50347d14641ec95096f62","147":"3abde8a9bcfe31815da50347d14641ec95096f62","148":"3abde8a9bcfe31815da50347d14641ec95096f62","149":"3abde8a9bcfe31815da50347d14641ec95096f62","150":"3abde8a9bcfe31815da50347d14641ec95096f62","151":"3abde8a9bcfe31815da50347d14641ec95096f62","152":"3abde8a9bcfe31815da50347d14641ec95096f62","153":"3abde8a9bcfe31815da50347d14641ec95096f62","154":"3abde8a9bcfe31815da50347d14641ec95096f62","155":"3abde8a9bcfe31815da50347d14641ec95096f62","156":"3abde8a9bcfe31815da50347d14641ec95096f62","157":"3abde8a9bcfe31815da50347d14641ec95096f62","158":"3abde8a9bcfe31815da50347d14641ec95096f62","159":"3abde8a9bcfe31815da50347d14641ec95096f62","160":"3abde8a9bcfe31815da50347d14641ec95096f62","161":"3abde8a9bcfe31815da50347d14641ec95096f62","162":"3abde8a9bcfe31815da50347d14641ec95096f62","163":"3abde8a9bcfe31815da50347d14641ec95096f62","164":"3abde8a9bcfe31815da50347d14641ec95096f62","165":"3abde8a9bcfe31815da50347d14641ec95096f62","166":"3abde8a9bcfe31815da50347d14641ec95096f62","167":"3abde8a9bcfe31815da50347d14641ec95096f62","168":"3abde8a9bcfe31815da50347d14641ec95096f62","169":"3abde8a9bcfe31815da50347d14641ec95096f62","170":"3abde8a9bcfe31815da50347d14641ec95096f62","171":"3abde8a9bcfe31815da50347d14641ec95096f62","172":"3abde8a9bcfe31815da50347d14641ec95096f62","173":"3abde8a9bcfe31815da50347d14641ec95096f62","174":"3abde8a9bcfe31815da50347d14641ec95096f62","175":"3abde8a9bcfe31815da50347d14641ec95096f62","176":"3abde8a9bcfe31815da50347d14641ec95096f62","177":"3abde8a9bcfe31815da50347d14641ec95096f62","178":"3abde8a9bcfe31815da50347d14641ec95096f62","179":"3abde8a9bcfe31815da50347d14641ec95096f62","180":"3abde8a9bcfe31815da50347d14641ec95096f62","181":"3abde8a9bcfe31815da50347d14641ec95096f62","182":"3abde8a9bcfe31815da50347d14641ec95096f62","183":"3abde8a9bcfe31815da50347d14641ec95096f62","184":"3abde8a9bcfe31815da50347d14641ec95096f62","185":"3abde8a9bcfe31815da50347d14641ec95096f62","186":"3abde8a9bcfe31815da50347d14641ec95096f62","187":"3abde8a9bcfe31815da50347d14641ec95096f62","188":"3abde8a9bcfe31815da50347d14641ec95096f62","189":"3abde8a9bcfe31815da50347d14641ec95096f62","190":"3abde8a9bcfe31815da50347d14641ec95096f62","191":"3abde8a9bcfe31815da50347d14641ec95096f62","192":"3abde8a9bcfe31815da50347d14641ec95096f62","193":"3abde8a9bcfe31815da50347d14641ec95096f62","194":"3abde8a9bcfe31815da50347d14641ec95096f62","195":"3abde8a9bcfe31815da50347d14641ec95096f62","196":"3abde8a9bcfe31815da50347d14641ec95096f62","197":"3abde8a9bcfe31815da50347d14641ec95096f62","198":"3abde8a9bcfe31815da50347d14641ec95096f62","199":"3abde8a9bcfe31815da50347d14641ec95096f62","200":"3abde8a9bcfe31815da50347d14641ec95096f62","201":"3abde8a9bcfe31815da50347d14641ec95096f62","202":"3abde8a9bcfe31815da50347d14641ec95096f62","203":"3abde8a9bcfe31815da50347d14641ec95096f62","204":"3abde8a9bcfe31815da50347d14641ec95096f62","205":"3abde8a9bcfe31815da50347d14641ec95096f62","206":"3abde8a9bcfe31815da50347d14641ec95096f62","207":"3abde8a9bcfe31815da50347d14641ec95096f62","208":"3abde8a9bcfe31815da50347d14641ec95096f62","209":"3abde8a9bcfe31815da50347d14641ec95096f62","210":"3abde8a9bcfe31815da50347d14641ec95096f62","211":"3abde8a9bcfe31815da50347d14641ec95096f62","212":"3abde8a9bcfe31815da50347d14641ec95096f62","213":"3abde8a9bcfe31815da50347d14641ec95096f62","214":"3abde8a9bcfe31815da50347d14641ec95096f62","215":"3abde8a9bcfe31815da50347d14641ec95096f62","216":"3abde8a9bcfe31815da50347d14641ec95096f62","217":"3abde8a9bcfe31815da50347d14641ec95096f62","218":"3abde8a9bcfe31815da50347d14641ec95096f62","219":"3abde8a9bcfe31815da50347d14641ec95096f62","220":"3abde8a9bcfe31815da50347d14641ec95096f62","221":"3abde8a9bcfe31815da50347d14641ec95096f62","222":"3abde8a9bcfe31815da50347d14641ec95096f62","223":"3abde8a9bcfe31815da50347d14641ec95096f62","224":"3abde8a9bcfe31815da50347d14641ec95096f62","225":"3abde8a9bcfe31815da50347d14641ec95096f62","226":"3abde8a9bcfe31815da50347d14641ec95096f62","227":"3abde8a9bcfe31815da50347d14641ec95096f62","228":"3abde8a9bcfe31815da50347d14641ec95096f62","229":"3abde8a9bcfe31815da50347d14641ec95096f62","230":"3abde8a9bcfe31815da50347d14641ec95096f62","231":"3abde8a9bcfe31815da50347d14641ec95096f62","232":"3abde8a9bcfe31815da50347d14641ec95096f62","233":"3abde8a9bcfe31815da50347d14641ec95096f62","234":"3abde8a9bcfe31815da50347d14641ec95096f62","235":"3abde8a9bcfe31815da50347d14641ec95096f62","236":"3abde8a9bcfe31815da50347d14641ec95096f62","237":"3abde8a9bcfe31815da50347d14641ec95096f62","238":"3abde8a9bcfe31815da50347d14641ec95096f62","239":"3abde8a9bcfe31815da50347d14641ec95096f62","240":"3abde8a9bcfe31815da50347d14641ec95096f62","241":"3abde8a9bcfe31815da50347d14641ec95096f62","242":"3abde8a9bcfe31815da50347d14641ec95096f62","243":"3abde8a9bcfe31815da50347d14641ec95096f62","244":"3abde8a9bcfe31815da50347d14641ec95096f62","245":"3abde8a9bcfe31815da50347d14641ec95096f62","246":"3abde8a9bcfe31815da50347d14641ec95096f62","247":"3abde8a9bcfe31815da50347d14641ec95096f62","248":"3abde8a9bcfe31815da50347d14641ec95096f62","249":"3abde8a9bcfe31815da50347d14641ec95096f62","250":"3abde8a9bcfe31815da50347d14641ec95096f62","251":"3abde8a9bcfe31815da50347d14641ec95096f62","252":"3abde8a9bcfe31815da50347d14641ec95096f62","253":"3abde8a9bcfe31815da50347d14641ec95096f62","254":"3abde8a9bcfe31815da50347d14641ec95096f62","255":"3abde8a9bcfe31815da50347d14641ec95096f62","256":"3abde8a9bcfe31815da50347d14641ec95096f62","257":"3abde8a9bcfe31815da50347d14641ec95096f62","258":"3abde8a9bcfe31815da50347d14641ec95096f62","259":"3abde8a9bcfe31815da50347d14641ec95096f62","260":"3abde8a9bcfe31815da50347d14641ec95096f62","261":"3abde8a9bcfe31815da50347d14641ec95096f62","262":"3abde8a9bcfe31815da50347d14641ec95096f62","263":"3abde8a9bcfe31815da50347d14641ec95096f62","264":"3abde8a9bcfe31815da50347d14641ec95096f62","265":"3abde8a9bcfe31815da50347d14641ec95096f62","266":"3abde8a9bcfe31815da50347d14641ec95096f62","267":"3abde8a9bcfe31815da50347d14641ec95096f62","268":"3abde8a9bcfe31815da50347d14641ec95096f62","269":"3abde8a9bcfe31815da50347d14641ec95096f62","270":"3abde8a9bcfe31815da50347d14641ec95096f62","271":"3abde8a9bcfe31815da50347d14641ec95096f62","272":"3abde8a9bcfe31815da50347d14641ec95096f62","273":"3abde8a9bcfe31815da50347d14641ec95096f62","274":"3abde8a9bcfe31815da50347d14641ec95096f62","275":"3abde8a9bcfe31815da50347d14641ec95096f62","276":"3abde8a9bcfe31815da50347d14641ec95096f62","277":"3abde8a9bcfe31815da50347d14641ec95096f62","278":"3abde8a9bcfe31815da50347d14641ec95096f62","279":"3abde8a9bcfe31815da50347d14641ec95096f62","280":"3abde8a9bcfe31815da50347d14641ec95096f62","281":"3abde8a9bcfe31815da50347d14641ec95096f62","282":"3abde8a9bcfe31815da50347d14641ec95096f62","283":"3abde8a9bcfe31815da50347d14641ec95096f62","284":"3abde8a9bcfe31815da50347d14641ec95096f62","285":"3abde8a9bcfe31815da50347d14641ec95096f62","286":"3abde8a9bcfe31815da50347d14641ec95096f62","287":"3abde8a9bcfe31815da50347d14641ec95096f62","288":"3abde8a9bcfe31815da50347d14641ec95096f62","289":"3abde8a9bcfe31815da50347d14641ec95096f62","290":"3abde8a9bcfe31815da50347d14641ec95096f62","291":"3abde8a9bcfe31815da50347d14641ec95096f62","292":"3abde8a9bcfe31815da50347d14641ec95096f62","293":"3abde8a9bcfe31815da50347d14641ec95096f62","294":"3abde8a9bcfe31815da50347d14641ec95096f62","295":"3abde8a9bcfe31815da50347d14641ec95096f62","296":"3abde8a9bcfe31815da50347d14641ec95096f62","297":"3abde8a9bcfe31815da50347d14641ec95096f62","298":"3abde8a9bcfe31815da50347d14641ec95096f62","299":"3abde8a9bcfe31815da50347d14641ec95096f62","300":"3abde8a9bcfe31815da50347d14641ec95096f62","301":"3abde8a9bcfe31815da50347d14641ec95096f62","302":"3abde8a9bcfe31815da50347d14641ec95096f62","303":"3abde8a9bcfe31815da50347d14641ec95096f62","304":"3abde8a9bcfe31815da50347d14641ec95096f62","305":"3abde8a9bcfe31815da50347d14641ec95096f62"},"repo":{"0":"hwalsuklee\/tensorflow-generative-model-collections","1":"hwalsuklee\/tensorflow-generative-model-collections","2":"hwalsuklee\/tensorflow-generative-model-collections","3":"hwalsuklee\/tensorflow-generative-model-collections","4":"hwalsuklee\/tensorflow-generative-model-collections","5":"hwalsuklee\/tensorflow-generative-model-collections","6":"hwalsuklee\/tensorflow-generative-model-collections","7":"hwalsuklee\/tensorflow-generative-model-collections","8":"hwalsuklee\/tensorflow-generative-model-collections","9":"hwalsuklee\/tensorflow-generative-model-collections","10":"hwalsuklee\/tensorflow-generative-model-collections","11":"hwalsuklee\/tensorflow-generative-model-collections","12":"hwalsuklee\/tensorflow-generative-model-collections","13":"hwalsuklee\/tensorflow-generative-model-collections","14":"hwalsuklee\/tensorflow-generative-model-collections","15":"hwalsuklee\/tensorflow-generative-model-collections","16":"hwalsuklee\/tensorflow-generative-model-collections","17":"hwalsuklee\/tensorflow-generative-model-collections","18":"hwalsuklee\/tensorflow-generative-model-collections","19":"hwalsuklee\/tensorflow-generative-model-collections","20":"hwalsuklee\/tensorflow-generative-model-collections","21":"hwalsuklee\/tensorflow-generative-model-collections","22":"hwalsuklee\/tensorflow-generative-model-collections","23":"hwalsuklee\/tensorflow-generative-model-collections","24":"hwalsuklee\/tensorflow-generative-model-collections","25":"hwalsuklee\/tensorflow-generative-model-collections","26":"hwalsuklee\/tensorflow-generative-model-collections","27":"hwalsuklee\/tensorflow-generative-model-collections","28":"hwalsuklee\/tensorflow-generative-model-collections","29":"hwalsuklee\/tensorflow-generative-model-collections","30":"hwalsuklee\/tensorflow-generative-model-collections","31":"hwalsuklee\/tensorflow-generative-model-collections","32":"hwalsuklee\/tensorflow-generative-model-collections","33":"hwalsuklee\/tensorflow-generative-model-collections","34":"hwalsuklee\/tensorflow-generative-model-collections","35":"hwalsuklee\/tensorflow-generative-model-collections","36":"hwalsuklee\/tensorflow-generative-model-collections","37":"hwalsuklee\/tensorflow-generative-model-collections","38":"hwalsuklee\/tensorflow-generative-model-collections","39":"hwalsuklee\/tensorflow-generative-model-collections","40":"hwalsuklee\/tensorflow-generative-model-collections","41":"hwalsuklee\/tensorflow-generative-model-collections","42":"hwalsuklee\/tensorflow-generative-model-collections","43":"hwalsuklee\/tensorflow-generative-model-collections","44":"hwalsuklee\/tensorflow-generative-model-collections","45":"hwalsuklee\/tensorflow-generative-model-collections","46":"hwalsuklee\/tensorflow-generative-model-collections","47":"hwalsuklee\/tensorflow-generative-model-collections","48":"hwalsuklee\/tensorflow-generative-model-collections","49":"hwalsuklee\/tensorflow-generative-model-collections","50":"hwalsuklee\/tensorflow-generative-model-collections","51":"hwalsuklee\/tensorflow-generative-model-collections","52":"hwalsuklee\/tensorflow-generative-model-collections","53":"hwalsuklee\/tensorflow-generative-model-collections","54":"hwalsuklee\/tensorflow-generative-model-collections","55":"hwalsuklee\/tensorflow-generative-model-collections","56":"hwalsuklee\/tensorflow-generative-model-collections","57":"hwalsuklee\/tensorflow-generative-model-collections","58":"hwalsuklee\/tensorflow-generative-model-collections","59":"hwalsuklee\/tensorflow-generative-model-collections","60":"hwalsuklee\/tensorflow-generative-model-collections","61":"hwalsuklee\/tensorflow-generative-model-collections","62":"hwalsuklee\/tensorflow-generative-model-collections","63":"hwalsuklee\/tensorflow-generative-model-collections","64":"hwalsuklee\/tensorflow-generative-model-collections","65":"hwalsuklee\/tensorflow-generative-model-collections","66":"hwalsuklee\/tensorflow-generative-model-collections","67":"hwalsuklee\/tensorflow-generative-model-collections","68":"hwalsuklee\/tensorflow-generative-model-collections","69":"hwalsuklee\/tensorflow-generative-model-collections","70":"hwalsuklee\/tensorflow-generative-model-collections","71":"hwalsuklee\/tensorflow-generative-model-collections","72":"hwalsuklee\/tensorflow-generative-model-collections","73":"hwalsuklee\/tensorflow-generative-model-collections","74":"hwalsuklee\/tensorflow-generative-model-collections","75":"hwalsuklee\/tensorflow-generative-model-collections","76":"hwalsuklee\/tensorflow-generative-model-collections","77":"hwalsuklee\/tensorflow-generative-model-collections","78":"hwalsuklee\/tensorflow-generative-model-collections","79":"hwalsuklee\/tensorflow-generative-model-collections","80":"hwalsuklee\/tensorflow-generative-model-collections","81":"hwalsuklee\/tensorflow-generative-model-collections","82":"hwalsuklee\/tensorflow-generative-model-collections","83":"hwalsuklee\/tensorflow-generative-model-collections","84":"hwalsuklee\/tensorflow-generative-model-collections","85":"hwalsuklee\/tensorflow-generative-model-collections","86":"hwalsuklee\/tensorflow-generative-model-collections","87":"hwalsuklee\/tensorflow-generative-model-collections","88":"hwalsuklee\/tensorflow-generative-model-collections","89":"hwalsuklee\/tensorflow-generative-model-collections","90":"hwalsuklee\/tensorflow-generative-model-collections","91":"hwalsuklee\/tensorflow-generative-model-collections","92":"hwalsuklee\/tensorflow-generative-model-collections","93":"hwalsuklee\/tensorflow-generative-model-collections","94":"hwalsuklee\/tensorflow-generative-model-collections","95":"hwalsuklee\/tensorflow-generative-model-collections","96":"hwalsuklee\/tensorflow-generative-model-collections","97":"hwalsuklee\/tensorflow-generative-model-collections","98":"hwalsuklee\/tensorflow-generative-model-collections","99":"hwalsuklee\/tensorflow-generative-model-collections","100":"hwalsuklee\/tensorflow-generative-model-collections","101":"hwalsuklee\/tensorflow-generative-model-collections","102":"hwalsuklee\/tensorflow-generative-model-collections","103":"hwalsuklee\/tensorflow-generative-model-collections","104":"hwalsuklee\/tensorflow-generative-model-collections","105":"hwalsuklee\/tensorflow-generative-model-collections","106":"hwalsuklee\/tensorflow-generative-model-collections","107":"hwalsuklee\/tensorflow-generative-model-collections","108":"hwalsuklee\/tensorflow-generative-model-collections","109":"hwalsuklee\/tensorflow-generative-model-collections","110":"hwalsuklee\/tensorflow-generative-model-collections","111":"hwalsuklee\/tensorflow-generative-model-collections","112":"hwalsuklee\/tensorflow-generative-model-collections","113":"hwalsuklee\/tensorflow-generative-model-collections","114":"hwalsuklee\/tensorflow-generative-model-collections","115":"hwalsuklee\/tensorflow-generative-model-collections","116":"hwalsuklee\/tensorflow-generative-model-collections","117":"hwalsuklee\/tensorflow-generative-model-collections","118":"hwalsuklee\/tensorflow-generative-model-collections","119":"hwalsuklee\/tensorflow-generative-model-collections","120":"hwalsuklee\/tensorflow-generative-model-collections","121":"hwalsuklee\/tensorflow-generative-model-collections","122":"hwalsuklee\/tensorflow-generative-model-collections","123":"hwalsuklee\/tensorflow-generative-model-collections","124":"hwalsuklee\/tensorflow-generative-model-collections","125":"hwalsuklee\/tensorflow-generative-model-collections","126":"hwalsuklee\/tensorflow-generative-model-collections","127":"hwalsuklee\/tensorflow-generative-model-collections","128":"hwalsuklee\/tensorflow-generative-model-collections","129":"hwalsuklee\/tensorflow-generative-model-collections","130":"hwalsuklee\/tensorflow-generative-model-collections","131":"hwalsuklee\/tensorflow-generative-model-collections","132":"hwalsuklee\/tensorflow-generative-model-collections","133":"hwalsuklee\/tensorflow-generative-model-collections","134":"hwalsuklee\/tensorflow-generative-model-collections","135":"hwalsuklee\/tensorflow-generative-model-collections","136":"hwalsuklee\/tensorflow-generative-model-collections","137":"hwalsuklee\/tensorflow-generative-model-collections","138":"hwalsuklee\/tensorflow-generative-model-collections","139":"hwalsuklee\/tensorflow-generative-model-collections","140":"hwalsuklee\/tensorflow-generative-model-collections","141":"hwalsuklee\/tensorflow-generative-model-collections","142":"hwalsuklee\/tensorflow-generative-model-collections","143":"hwalsuklee\/tensorflow-generative-model-collections","144":"hwalsuklee\/tensorflow-generative-model-collections","145":"hwalsuklee\/tensorflow-generative-model-collections","146":"hwalsuklee\/tensorflow-generative-model-collections","147":"hwalsuklee\/tensorflow-generative-model-collections","148":"hwalsuklee\/tensorflow-generative-model-collections","149":"hwalsuklee\/tensorflow-generative-model-collections","150":"hwalsuklee\/tensorflow-generative-model-collections","151":"hwalsuklee\/tensorflow-generative-model-collections","152":"hwalsuklee\/tensorflow-generative-model-collections","153":"hwalsuklee\/tensorflow-generative-model-collections","154":"hwalsuklee\/tensorflow-generative-model-collections","155":"hwalsuklee\/tensorflow-generative-model-collections","156":"hwalsuklee\/tensorflow-generative-model-collections","157":"hwalsuklee\/tensorflow-generative-model-collections","158":"hwalsuklee\/tensorflow-generative-model-collections","159":"hwalsuklee\/tensorflow-generative-model-collections","160":"hwalsuklee\/tensorflow-generative-model-collections","161":"hwalsuklee\/tensorflow-generative-model-collections","162":"hwalsuklee\/tensorflow-generative-model-collections","163":"hwalsuklee\/tensorflow-generative-model-collections","164":"hwalsuklee\/tensorflow-generative-model-collections","165":"hwalsuklee\/tensorflow-generative-model-collections","166":"hwalsuklee\/tensorflow-generative-model-collections","167":"hwalsuklee\/tensorflow-generative-model-collections","168":"hwalsuklee\/tensorflow-generative-model-collections","169":"hwalsuklee\/tensorflow-generative-model-collections","170":"hwalsuklee\/tensorflow-generative-model-collections","171":"hwalsuklee\/tensorflow-generative-model-collections","172":"hwalsuklee\/tensorflow-generative-model-collections","173":"hwalsuklee\/tensorflow-generative-model-collections","174":"hwalsuklee\/tensorflow-generative-model-collections","175":"hwalsuklee\/tensorflow-generative-model-collections","176":"hwalsuklee\/tensorflow-generative-model-collections","177":"hwalsuklee\/tensorflow-generative-model-collections","178":"hwalsuklee\/tensorflow-generative-model-collections","179":"hwalsuklee\/tensorflow-generative-model-collections","180":"hwalsuklee\/tensorflow-generative-model-collections","181":"hwalsuklee\/tensorflow-generative-model-collections","182":"hwalsuklee\/tensorflow-generative-model-collections","183":"hwalsuklee\/tensorflow-generative-model-collections","184":"hwalsuklee\/tensorflow-generative-model-collections","185":"hwalsuklee\/tensorflow-generative-model-collections","186":"hwalsuklee\/tensorflow-generative-model-collections","187":"hwalsuklee\/tensorflow-generative-model-collections","188":"hwalsuklee\/tensorflow-generative-model-collections","189":"hwalsuklee\/tensorflow-generative-model-collections","190":"hwalsuklee\/tensorflow-generative-model-collections","191":"hwalsuklee\/tensorflow-generative-model-collections","192":"hwalsuklee\/tensorflow-generative-model-collections","193":"hwalsuklee\/tensorflow-generative-model-collections","194":"hwalsuklee\/tensorflow-generative-model-collections","195":"hwalsuklee\/tensorflow-generative-model-collections","196":"hwalsuklee\/tensorflow-generative-model-collections","197":"hwalsuklee\/tensorflow-generative-model-collections","198":"hwalsuklee\/tensorflow-generative-model-collections","199":"hwalsuklee\/tensorflow-generative-model-collections","200":"hwalsuklee\/tensorflow-generative-model-collections","201":"hwalsuklee\/tensorflow-generative-model-collections","202":"hwalsuklee\/tensorflow-generative-model-collections","203":"hwalsuklee\/tensorflow-generative-model-collections","204":"hwalsuklee\/tensorflow-generative-model-collections","205":"hwalsuklee\/tensorflow-generative-model-collections","206":"hwalsuklee\/tensorflow-generative-model-collections","207":"hwalsuklee\/tensorflow-generative-model-collections","208":"hwalsuklee\/tensorflow-generative-model-collections","209":"hwalsuklee\/tensorflow-generative-model-collections","210":"hwalsuklee\/tensorflow-generative-model-collections","211":"hwalsuklee\/tensorflow-generative-model-collections","212":"hwalsuklee\/tensorflow-generative-model-collections","213":"hwalsuklee\/tensorflow-generative-model-collections","214":"hwalsuklee\/tensorflow-generative-model-collections","215":"hwalsuklee\/tensorflow-generative-model-collections","216":"hwalsuklee\/tensorflow-generative-model-collections","217":"hwalsuklee\/tensorflow-generative-model-collections","218":"hwalsuklee\/tensorflow-generative-model-collections","219":"hwalsuklee\/tensorflow-generative-model-collections","220":"hwalsuklee\/tensorflow-generative-model-collections","221":"hwalsuklee\/tensorflow-generative-model-collections","222":"hwalsuklee\/tensorflow-generative-model-collections","223":"hwalsuklee\/tensorflow-generative-model-collections","224":"hwalsuklee\/tensorflow-generative-model-collections","225":"hwalsuklee\/tensorflow-generative-model-collections","226":"hwalsuklee\/tensorflow-generative-model-collections","227":"hwalsuklee\/tensorflow-generative-model-collections","228":"hwalsuklee\/tensorflow-generative-model-collections","229":"hwalsuklee\/tensorflow-generative-model-collections","230":"hwalsuklee\/tensorflow-generative-model-collections","231":"hwalsuklee\/tensorflow-generative-model-collections","232":"hwalsuklee\/tensorflow-generative-model-collections","233":"hwalsuklee\/tensorflow-generative-model-collections","234":"hwalsuklee\/tensorflow-generative-model-collections","235":"hwalsuklee\/tensorflow-generative-model-collections","236":"hwalsuklee\/tensorflow-generative-model-collections","237":"hwalsuklee\/tensorflow-generative-model-collections","238":"hwalsuklee\/tensorflow-generative-model-collections","239":"hwalsuklee\/tensorflow-generative-model-collections","240":"hwalsuklee\/tensorflow-generative-model-collections","241":"hwalsuklee\/tensorflow-generative-model-collections","242":"hwalsuklee\/tensorflow-generative-model-collections","243":"hwalsuklee\/tensorflow-generative-model-collections","244":"hwalsuklee\/tensorflow-generative-model-collections","245":"hwalsuklee\/tensorflow-generative-model-collections","246":"hwalsuklee\/tensorflow-generative-model-collections","247":"hwalsuklee\/tensorflow-generative-model-collections","248":"hwalsuklee\/tensorflow-generative-model-collections","249":"hwalsuklee\/tensorflow-generative-model-collections","250":"hwalsuklee\/tensorflow-generative-model-collections","251":"hwalsuklee\/tensorflow-generative-model-collections","252":"hwalsuklee\/tensorflow-generative-model-collections","253":"hwalsuklee\/tensorflow-generative-model-collections","254":"hwalsuklee\/tensorflow-generative-model-collections","255":"hwalsuklee\/tensorflow-generative-model-collections","256":"hwalsuklee\/tensorflow-generative-model-collections","257":"hwalsuklee\/tensorflow-generative-model-collections","258":"hwalsuklee\/tensorflow-generative-model-collections","259":"hwalsuklee\/tensorflow-generative-model-collections","260":"hwalsuklee\/tensorflow-generative-model-collections","261":"hwalsuklee\/tensorflow-generative-model-collections","262":"hwalsuklee\/tensorflow-generative-model-collections","263":"hwalsuklee\/tensorflow-generative-model-collections","264":"hwalsuklee\/tensorflow-generative-model-collections","265":"hwalsuklee\/tensorflow-generative-model-collections","266":"hwalsuklee\/tensorflow-generative-model-collections","267":"hwalsuklee\/tensorflow-generative-model-collections","268":"hwalsuklee\/tensorflow-generative-model-collections","269":"hwalsuklee\/tensorflow-generative-model-collections","270":"hwalsuklee\/tensorflow-generative-model-collections","271":"hwalsuklee\/tensorflow-generative-model-collections","272":"hwalsuklee\/tensorflow-generative-model-collections","273":"hwalsuklee\/tensorflow-generative-model-collections","274":"hwalsuklee\/tensorflow-generative-model-collections","275":"hwalsuklee\/tensorflow-generative-model-collections","276":"hwalsuklee\/tensorflow-generative-model-collections","277":"hwalsuklee\/tensorflow-generative-model-collections","278":"hwalsuklee\/tensorflow-generative-model-collections","279":"hwalsuklee\/tensorflow-generative-model-collections","280":"hwalsuklee\/tensorflow-generative-model-collections","281":"hwalsuklee\/tensorflow-generative-model-collections","282":"hwalsuklee\/tensorflow-generative-model-collections","283":"hwalsuklee\/tensorflow-generative-model-collections","284":"hwalsuklee\/tensorflow-generative-model-collections","285":"hwalsuklee\/tensorflow-generative-model-collections","286":"hwalsuklee\/tensorflow-generative-model-collections","287":"hwalsuklee\/tensorflow-generative-model-collections","288":"hwalsuklee\/tensorflow-generative-model-collections","289":"hwalsuklee\/tensorflow-generative-model-collections","290":"hwalsuklee\/tensorflow-generative-model-collections","291":"hwalsuklee\/tensorflow-generative-model-collections","292":"hwalsuklee\/tensorflow-generative-model-collections","293":"hwalsuklee\/tensorflow-generative-model-collections","294":"hwalsuklee\/tensorflow-generative-model-collections","295":"hwalsuklee\/tensorflow-generative-model-collections","296":"hwalsuklee\/tensorflow-generative-model-collections","297":"hwalsuklee\/tensorflow-generative-model-collections","298":"hwalsuklee\/tensorflow-generative-model-collections","299":"hwalsuklee\/tensorflow-generative-model-collections","300":"hwalsuklee\/tensorflow-generative-model-collections","301":"hwalsuklee\/tensorflow-generative-model-collections","302":"hwalsuklee\/tensorflow-generative-model-collections","303":"hwalsuklee\/tensorflow-generative-model-collections","304":"hwalsuklee\/tensorflow-generative-model-collections","305":"hwalsuklee\/tensorflow-generative-model-collections"},"stargazers":{"0":3775,"1":3775,"2":3775,"3":3775,"4":3775,"5":3775,"6":3775,"7":3775,"8":3775,"9":3775,"10":3775,"11":3775,"12":3775,"13":3775,"14":3775,"15":3775,"16":3775,"17":3775,"18":3775,"19":3775,"20":3775,"21":3775,"22":3775,"23":3775,"24":3775,"25":3775,"26":3775,"27":3775,"28":3775,"29":3775,"30":3775,"31":3775,"32":3775,"33":3775,"34":3775,"35":3775,"36":3775,"37":3775,"38":3775,"39":3775,"40":3775,"41":3775,"42":3775,"43":3775,"44":3775,"45":3775,"46":3775,"47":3775,"48":3775,"49":3775,"50":3775,"51":3775,"52":3775,"53":3775,"54":3775,"55":3775,"56":3775,"57":3775,"58":3775,"59":3775,"60":3775,"61":3775,"62":3775,"63":3775,"64":3775,"65":3775,"66":3775,"67":3775,"68":3775,"69":3775,"70":3775,"71":3775,"72":3775,"73":3775,"74":3775,"75":3775,"76":3775,"77":3775,"78":3775,"79":3775,"80":3775,"81":3775,"82":3775,"83":3775,"84":3775,"85":3775,"86":3775,"87":3775,"88":3775,"89":3775,"90":3775,"91":3775,"92":3775,"93":3775,"94":3775,"95":3775,"96":3775,"97":3775,"98":3775,"99":3775,"100":3775,"101":3775,"102":3775,"103":3775,"104":3775,"105":3775,"106":3775,"107":3775,"108":3775,"109":3775,"110":3775,"111":3775,"112":3775,"113":3775,"114":3775,"115":3775,"116":3775,"117":3775,"118":3775,"119":3775,"120":3775,"121":3775,"122":3775,"123":3775,"124":3775,"125":3775,"126":3775,"127":3775,"128":3775,"129":3775,"130":3775,"131":3775,"132":3775,"133":3775,"134":3775,"135":3775,"136":3775,"137":3775,"138":3775,"139":3775,"140":3775,"141":3775,"142":3775,"143":3775,"144":3775,"145":3775,"146":3775,"147":3775,"148":3775,"149":3775,"150":3775,"151":3775,"152":3775,"153":3775,"154":3775,"155":3775,"156":3775,"157":3775,"158":3775,"159":3775,"160":3775,"161":3775,"162":3775,"163":3775,"164":3775,"165":3775,"166":3775,"167":3775,"168":3775,"169":3775,"170":3775,"171":3775,"172":3775,"173":3775,"174":3775,"175":3775,"176":3775,"177":3775,"178":3775,"179":3775,"180":3775,"181":3775,"182":3775,"183":3775,"184":3775,"185":3775,"186":3775,"187":3775,"188":3775,"189":3775,"190":3775,"191":3775,"192":3775,"193":3775,"194":3775,"195":3775,"196":3775,"197":3775,"198":3775,"199":3775,"200":3775,"201":3775,"202":3775,"203":3775,"204":3775,"205":3775,"206":3775,"207":3775,"208":3775,"209":3775,"210":3775,"211":3775,"212":3775,"213":3775,"214":3775,"215":3775,"216":3775,"217":3775,"218":3775,"219":3775,"220":3775,"221":3775,"222":3775,"223":3775,"224":3775,"225":3775,"226":3775,"227":3775,"228":3775,"229":3775,"230":3775,"231":3775,"232":3775,"233":3775,"234":3775,"235":3775,"236":3775,"237":3775,"238":3775,"239":3775,"240":3775,"241":3775,"242":3775,"243":3775,"244":3775,"245":3775,"246":3775,"247":3775,"248":3775,"249":3775,"250":3775,"251":3775,"252":3775,"253":3775,"254":3775,"255":3775,"256":3775,"257":3775,"258":3775,"259":3775,"260":3775,"261":3775,"262":3775,"263":3775,"264":3775,"265":3775,"266":3775,"267":3775,"268":3775,"269":3775,"270":3775,"271":3775,"272":3775,"273":3775,"274":3775,"275":3775,"276":3775,"277":3775,"278":3775,"279":3775,"280":3775,"281":3775,"282":3775,"283":3775,"284":3775,"285":3775,"286":3775,"287":3775,"288":3775,"289":3775,"290":3775,"291":3775,"292":3775,"293":3775,"294":3775,"295":3775,"296":3775,"297":3775,"298":3775,"299":3775,"300":3775,"301":3775,"302":3775,"303":3775,"304":3775,"305":3775}}
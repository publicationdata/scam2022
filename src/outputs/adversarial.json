{"type":{"0":"W","1":"W","2":"W","3":"W","4":"W","5":"W","6":"W","7":"W","8":"W","9":"W","10":"W","11":"W","12":"W","13":"W","14":"W","15":"W","16":"W","17":"W","18":"W","19":"W","20":"W","21":"W","22":"W","23":"W","24":"W","25":"W","26":"W","27":"W","28":"W","29":"W","30":"W","31":"W","32":"W","33":"R","34":"R","35":"R","36":"R","37":"R","38":"R","39":"R","40":"R","41":"R","42":"R","43":"R","44":"R","45":"R","46":"R","47":"R","48":"R","49":"R"},"module":{"0":"sgd","1":"sgd","2":"sgd","3":"sgd","4":"sgd","5":"sgd","6":"sgd","7":"sgd","8":"sgd","9":"sgd","10":"sgd","11":"sgd","12":"sgd","13":"sgd","14":"sgd","15":"sgd","16":"sgd","17":"sgd_alt","18":"sgd_alt","19":"sgd_alt","20":"sgd_alt","21":"sgd_alt","22":"sgd_alt","23":"sgd_alt","24":"sgd_alt","25":"sgd_alt","26":"sgd_alt","27":"sgd_alt","28":"sgd_alt","29":"sgd_alt","30":"sgd_alt","31":"sgd_alt","32":"test_deconv","33":"test_deconv","34":"test_deconv","35":"test_deconv","36":"test_deconv","37":"test_deconv","38":"test_deconv","39":"test_deconv","40":"test_deconv","41":"test_deconv","42":"test_deconv","43":"test_deconv","44":"test_deconv","45":"test_deconv","46":"test_deconv","47":"test_deconv","48":"test_deconv","49":"test_deconv"},"obj":{"0":"SGD.__init__","1":"SGD.setup","2":"SGD.train","3":"SGD.setup","4":"SGD.setup","5":"SGD.setup","6":"SGD.setup","7":"SGD.setup","8":"SGD.setup","9":"AnnealedLearningRate.__call__","10":"ExponentialDecay.__call__","11":"LinearDecay.__call__","12":"LinearDecay.__call__","13":"OneOverEpoch.on_monitor","14":"LinearDecayOverEpoch.on_monitor","15":"LinearDecayOverEpoch.on_monitor","16":"PolyakAveraging.on_monitor","17":"SGD.__init__","18":"SGD.setup","19":"SGD.setup","20":"SGD.setup","21":"SGD.setup","22":"SGD.setup","23":"SGD.setup","24":"AnnealedLearningRate.__call__","25":"ExponentialDecay.__call__","26":"LinearDecay.__call__","27":"LinearDecay.__call__","28":"OneOverEpoch.on_monitor","29":"LinearDecayOverEpoch.on_monitor","30":"LinearDecayOverEpoch.on_monitor","31":"PolyakAveraging.on_monitor","32":"","33":"","34":"","35":"","36":"","37":"","38":"","39":"","40":"","41":"","42":"","43":"","44":"","45":"","46":"","47":"","48":"","49":""},"lnum":{"0":158,"1":219,"2":481,"3":232,"4":236,"5":272,"6":315,"7":407,"8":408,"9":762,"10":811,"11":869,"12":870,"13":941,"14":1000,"15":1001,"16":1122,"17":159,"18":234,"19":238,"20":274,"21":317,"22":416,"23":417,"24":774,"25":823,"26":881,"27":882,"28":953,"29":1012,"30":1013,"31":1134,"32":44,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1},"col":{"0":4,"1":8,"2":8,"3":8,"4":8,"5":8,"6":8,"7":8,"8":8,"9":12,"10":12,"11":12,"12":12,"13":12,"14":12,"15":12,"16":12,"17":4,"18":8,"19":8,"20":8,"21":8,"22":8,"23":8,"24":12,"25":12,"26":12,"27":12,"28":12,"29":12,"30":12,"31":12,"32":0,"33":0,"34":0,"35":0,"36":0,"37":0,"38":0,"39":0,"40":0,"41":0,"42":0,"43":0,"44":0,"45":0,"46":0,"47":0,"48":0,"49":0},"filename":{"0":"sgd.py","1":"sgd.py","2":"sgd.py","3":"sgd.py","4":"sgd.py","5":"sgd.py","6":"sgd.py","7":"sgd.py","8":"sgd.py","9":"sgd.py","10":"sgd.py","11":"sgd.py","12":"sgd.py","13":"sgd.py","14":"sgd.py","15":"sgd.py","16":"sgd.py","17":"sgd_alt.py","18":"sgd_alt.py","19":"sgd_alt.py","20":"sgd_alt.py","21":"sgd_alt.py","22":"sgd_alt.py","23":"sgd_alt.py","24":"sgd_alt.py","25":"sgd_alt.py","26":"sgd_alt.py","27":"sgd_alt.py","28":"sgd_alt.py","29":"sgd_alt.py","30":"sgd_alt.py","31":"sgd_alt.py","32":"test_deconv.py","33":"test_deconv.py","34":"test_deconv.py","35":"test_deconv.py","36":"test_deconv.py","37":"test_deconv.py","38":"test_deconv.py","39":"test_deconv.py","40":"test_deconv.py","41":"test_deconv.py","42":"test_deconv.py","43":"test_deconv.py","44":"test_deconv.py","45":"test_deconv.py","46":"test_deconv.py","47":"test_deconv.py","48":"test_deconv.py","49":"test_deconv.py"},"symbol":{"0":"dangerous-default-value","1":"attribute-defined-outside-init","2":"attribute-defined-outside-init","3":"attribute-defined-outside-init","4":"attribute-defined-outside-init","5":"attribute-defined-outside-init","6":"attribute-defined-outside-init","7":"attribute-defined-outside-init","8":"attribute-defined-outside-init","9":"attribute-defined-outside-init","10":"attribute-defined-outside-init","11":"attribute-defined-outside-init","12":"attribute-defined-outside-init","13":"attribute-defined-outside-init","14":"attribute-defined-outside-init","15":"attribute-defined-outside-init","16":"attribute-defined-outside-init","17":"dangerous-default-value","18":"attribute-defined-outside-init","19":"attribute-defined-outside-init","20":"attribute-defined-outside-init","21":"attribute-defined-outside-init","22":"attribute-defined-outside-init","23":"attribute-defined-outside-init","24":"attribute-defined-outside-init","25":"attribute-defined-outside-init","26":"attribute-defined-outside-init","27":"attribute-defined-outside-init","28":"attribute-defined-outside-init","29":"attribute-defined-outside-init","30":"attribute-defined-outside-init","31":"attribute-defined-outside-init","32":"redefined-builtin","33":"duplicate-code","34":"duplicate-code","35":"duplicate-code","36":"duplicate-code","37":"duplicate-code","38":"duplicate-code","39":"duplicate-code","40":"duplicate-code","41":"duplicate-code","42":"duplicate-code","43":"duplicate-code","44":"duplicate-code","45":"duplicate-code","46":"duplicate-code","47":"duplicate-code","48":"duplicate-code","49":"duplicate-code"},"text":{"0":"Dangerous default value [] as argument","1":"Attribute 'i' defined outside __init__","2":"Attribute 'i' defined outside __init__","3":"Attribute 'model' defined outside __init__","4":"Attribute 'monitor' defined outside __init__","5":"Attribute 'on_load_batch' defined outside __init__","6":"Attribute 'params' defined outside __init__","7":"Attribute 'd_func' defined outside __init__","8":"Attribute 'g_func' defined outside __init__","9":"Attribute '_base' defined outside __init__","10":"Attribute '_base_lr' defined outside __init__","11":"Attribute '_base_lr' defined outside __init__","12":"Attribute '_step' defined outside __init__","13":"Attribute '_init_lr' defined outside __init__","14":"Attribute '_init_lr' defined outside __init__","15":"Attribute '_step' defined outside __init__","16":"Attribute '_worker' defined outside __init__","17":"Dangerous default value [] as argument","18":"Attribute 'model' defined outside __init__","19":"Attribute 'monitor' defined outside __init__","20":"Attribute 'on_load_batch' defined outside __init__","21":"Attribute 'params' defined outside __init__","22":"Attribute 'd_func' defined outside __init__","23":"Attribute 'g_func' defined outside __init__","24":"Attribute '_base' defined outside __init__","25":"Attribute '_base_lr' defined outside __init__","26":"Attribute '_base_lr' defined outside __init__","27":"Attribute '_step' defined outside __init__","28":"Attribute '_init_lr' defined outside __init__","29":"Attribute '_init_lr' defined outside __init__","30":"Attribute '_step' defined outside __init__","31":"Attribute '_worker' defined outside __init__","32":"Redefining built-in 'iter'","33":"Similar lines in 2 files\n==sgd:482\n==sgd_alt:494\n    def continue_learning(self, model):\n        \"\"\"\n        Returns True if the algorithm should continue running, or False\n        if it has reached convergence \/ started overfitting and should\n        stop.\n\n        Parameters\n        ----------\n        model : a Model instance\n        \"\"\"\n        if self.termination_criterion is None:\n            return True\n        else:\n            return self.termination_criterion.continue_learning(self.model)\n\nclass MonitorBasedLRAdjuster(TrainExtension):\n    \"\"\"\n    A TrainExtension that uses the on_monitor callback to adjust\n    the learning rate on each epoch. It pulls out a channel\n    from the model's monitor and adjusts the learning rate\n    based on what happened to the monitoring channel on the last\n    epoch. If the channel is greater than high_trigger times\n    its previous value, the learning rate will be scaled by\n    shrink_amt (which should be < 1 for this scheme to make\n    sense). The idea is that in this case the learning algorithm\n    is overshooting the bottom of the objective function.\n\n    If the objective is less than high_trigger but\n    greater than low_trigger times its previous value, the\n    learning rate will be scaled by grow_amt (which should be > 1\n    for this scheme to make sense). The idea is that the learning\n    algorithm is making progress but at too slow of a rate.\n\n    Parameters\n    ----------\n    high_trigger : float, optional\n        See class-level docstring\n    low_trigger : float, optional\n        See class-level docstring\n    grow_amt : float, optional\n        See class-level docstring\n    min_lr : float, optional\n        All updates to the learning rate are clipped to be at least\n        this value.\n    max_lr : float, optional\n        All updates to the learning rate are clipped to be at most\n        this value.\n    dataset_name : str, optional\n        If specified, use dataset_name + \"_objective\" as the channel\n        to guide the learning rate adaptation.\n    channel_name : str, optional\n        If specified, use channel_name as the channel to guide the\n        learning rate adaptation. Conflicts with dataset_name.\n        If neither dataset_name nor channel_name is specified, uses\n        \"objective\"\n    \"\"\"\n\n    def __init__(self, high_trigger=1., shrink_amt=.99,\n                 low_trigger=.99, grow_amt=1.01,\n                 min_lr = 1e-7, max_lr = 1.,\n                 dataset_name=None, channel_name=None):\n        self.high_trigger = high_trigger\n        self.shrink_amt = shrink_amt\n        self.low_trigger = low_trigger\n        self.grow_amt = grow_amt\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.dataset_name = None\n        if channel_name is not None:\n            self.channel_name = channel_name\n        else:\n            if dataset_name is not None:\n                self.channel_name = dataset_name + '_objective'\n                self.dataset_name = dataset_name\n            else:\n                self.channel_name = None\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Adjusts the learning rate based on the contents of model.monitor\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        model = algorithm.model\n        lr = algorithm.learning_rate\n        current_learning_rate = lr.get_value()\n        assert hasattr(model, 'monitor'), (\"no monitor associated with \"\n                + str(model))\n        monitor = model.monitor\n        monitor_channel_specified = True\n\n        if self.channel_name is None:\n            monitor_channel_specified = False\n            channels = [elem for elem in monitor.channels\n                    if elem.endswith(\"objective\")]\n            if len(channels) < 1:\n                raise ValueError(\"There are no monitoring channels that end \"\n                        \"with \\\"objective\\\". Please specify either \"\n                        \"channel_name or dataset_name.\")\n            elif len(channels) > 1:\n                datasets = algorithm.monitoring_dataset.keys()\n                raise ValueError(\"There are multiple monitoring channels that\"\n                        \"end with \\\"_objective\\\". The list of available \"\n                        \"datasets are: \" +\n                                str(datasets) + \" . Please specify either \"\n                                \"channel_name or dataset_name in the \"\n                                \"MonitorBasedLRAdjuster constructor to \"\n                                'disambiguate.')\n            else:\n                self.channel_name = channels[0]\n                warnings.warn('The channel that has been chosen for '\n                        'monitoring is: ' +\n                              str(self.channel_name) + '.')\n\n        try:\n            v = monitor.channels[self.channel_name].val_record\n        except KeyError:\n            err_input = ''\n            if monitor_channel_specified:\n                if self.dataset_name:\n                    err_input = 'The dataset_name \\'' + str(\n                            self.dataset_name) + '\\' is not valid.'\n                else:\n                    err_input = 'The channel_name \\'' + str(\n                            self.channel_name) + '\\' is not valid.'\n            err_message = 'There is no monitoring channel named \\'' + \\\n                    str(self.channel_name) + '\\'. You probably need to ' + \\\n                    'specify a valid monitoring channel by using either ' + \\\n                    'dataset_name or channel_name in the ' + \\\n                    'MonitorBasedLRAdjuster constructor. ' + err_input\n            raise ValueError(err_message)\n\n        if len(v) < 1:\n            if monitor.dataset is None:\n                assert len(v) == 0\n                raise ValueError(\"You're trying to use a monitor-based \"\n                        \"learning rate adjustor but the monitor has no \"\n                        \"entries because you didn't specify a \"\n                        \"monitoring dataset.\")\n\n            raise ValueError(\"For some reason there are no monitor entries\"\n                                 \"yet the MonitorBasedLRAdjuster has been \"\n                                 \"called. This should never happen. The Train\"\n                                 \" object should call the monitor once on \"\n                                 \"initialization, then call the callbacks. \"\n                                 \"It seems you are either calling the \"\n                                 \"callback manually rather than as part of a \"\n                                 \"training algorithm, or there is a problem \"\n                                \"with the Train object.\")\n        if len(v) == 1:\n            #only the initial monitoring has happened\n            #no learning has happened, so we can't adjust the learning rate yet\n            #just do nothing\n            return\n\n        rval = current_learning_rate\n\n        log.info(\"monitoring channel is {0}\".format(self.channel_name))\n\n        if v[-1] > self.high_trigger * v[-2]:\n            rval *= self.shrink_amt\n            log.info(\"shrinking learning rate to %f\" % rval)\n        elif v[-1] > self.low_trigger * v[-2]:\n            rval *= self.grow_amt\n            log.info(\"growing learning rate to %f\" % rval)\n\n        rval = max(self.min_lr, rval)\n        rval = min(self.max_lr, rval)\n\n        lr.set_value(np.cast[lr.dtype](rval))\n\n\nclass PatienceBasedTermCrit(object):\n    \"\"\"\n    A monitor-based termination criterion using a geometrically increasing\n    amount of patience. If the selected channel has decreased by a certain\n    proportion when comparing to the lowest value seen yet, the patience is\n    set to a factor of the number of examples seen, which by default\n    (patience_increase=2.) ensures the model has seen as many examples as the\n    number of examples that lead to the lowest value before concluding a local\n    optima has been reached.\n\n    Note: Technically, the patience corresponds to a number of epochs to be\n    independent of the size of the dataset, so be aware of that when choosing\n    initial_patience.\n\n    Parameters\n    ----------\n    prop_decrease : float\n        The factor X in the (1 - X) * best_value threshold\n    initial_patience : int\n        Minimal number of epochs the model has to run before it can stop\n    patience_increase : float, optional\n        The factor X in the patience = X * n_iter update.\n    channel_name : string, optional\n        Name of the channel to examine. If None and the monitor\n        has only one channel, this channel will be used; otherwise, an\n        error will be raised.\n    \"\"\"\n    def __init__(self, prop_decrease, initial_patience,\n                 patience_increase=2., channel_name=None):\n        self._channel_name = channel_name\n        self.prop_decrease = prop_decrease\n        self.patience = initial_patience\n        self.best_value = np.inf\n        self.patience_increase = patience_increase\n\n    def __call__(self, model):\n        \"\"\"\n        Returns True or False depending on whether the optimization should\n        stop or not. The optimization should stop if it has run for a number\n        of epochs superior to the patience without any improvement.\n\n        Parameters\n        ----------\n        model : Model\n            The model used in the experiment and from which the monitor used\n            in the termination criterion will be extracted.\n\n        Returns\n        -------\n        bool\n            True or False, indicating if the optimization should stop or not.\n        \"\"\"\n        monitor = model.monitor\n        # In the case the monitor has only one channel, the channel_name can\n        # be omitted and the criterion will examine the only channel\n        # available. However, if the monitor has multiple channels, leaving\n        # the channel_name unspecified will raise an error.\n        if self._channel_name is None:\n            if len(monitor.channels) != 1:\n                raise ValueError(\"Only single-channel monitors are supported \"\n                                 \"for channel_name == None\")\n            v = monitor.channels.values()[0].val_record\n        else:\n            v = monitor.channels[self._channel_name].val_record\n        # If the channel value decrease is higher than the threshold, we\n        # update the best value to this value and we update the patience.\n        if v[-1] < self.best_value * (1. - self.prop_decrease):\n            # Using the max between actual patience and updated patience\n            # ensures that the model will run for at least the initial\n            # patience and that it would behave correctly if the user\n            # chooses a dumb value (i.e. less than 1)\n            self.patience = max(self.patience, len(v) * self.patience_increase)\n            self.best_value = v[-1]\n\n        return len(v) < self.patience\n\n\nclass AnnealedLearningRate(object):\n    \"\"\"\n    This is a callback for the SGD algorithm rather than the Train object.\n    This anneals the learning rate to decrease as 1\/t where t is the number\n    of gradient descent updates done so far. Use OneOverEpoch as Train object\n    callback if you would prefer 1\/t where t is epochs.\n\n    Parameters\n    ----------\n    anneal_start : int\n        The epoch on which to begin annealing\n    \"\"\"\n    def __init__(self, anneal_start):\n        self._initialized = False\n        self._count = 0\n        self._anneal_start = anneal_start\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Updates the learning rate according to the annealing schedule.\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        if not self._initialized:\n            self._base = algorithm.learning_rate.get_value()\n        self._count += 1\n        algorithm.learning_rate.set_value(self.current_learning_rate())\n\n    def current_learning_rate(self):\n        \"\"\"\n        Returns the current desired learning rate according to the\n        annealing schedule.\n        \"\"\"\n        return self._base * min(1, self._anneal_start \/ self._count)\n\nclass ExponentialDecay(object):\n    \"\"\"\n    This is a callback for the `SGD` algorithm rather than the `Train` object.\n    This anneals the learning rate by dividing by decay_factor after each\n    gradient descent step. It will not shrink the learning rate beyond\n    `min_lr`.\n\n    Parameters\n    ----------\n    decay_factor : float\n        The learning rate at step t is given by\n        `init_learning_rate \/ (decay_factor ** t)`\n    min_lr : float\n        The learning rate will be clipped to be at least this value\n    \"\"\"\n\n    def __init__(self, decay_factor, min_lr):\n        if isinstance(decay_factor, str):\n            decay_factor = float(decay_factor)\n        if isinstance(min_lr, str):\n            min_lr = float(min_lr)\n        assert isinstance(decay_factor, float)\n        assert isinstance(min_lr, float)\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n        self._min_reached = False\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Updates the learning rate according to the exponential decay schedule.\n\n        Parameters\n        ----------\n        algorithm : SGD\n            The SGD instance whose `learning_rate` field should be modified.\n        \"\"\"\n        if self._count == 0:\n            self._base_lr = algorithm.learning_rate.get_value()\n        self._count += 1\n\n        if not self._min_reached:\n            # If we keep on executing the exponentiation on each mini-batch,\n            # we will eventually get an OverflowError. So make sure we\n            # only do the computation until min_lr is reached.\n            new_lr = self._base_lr \/ (self.decay_factor ** self._count)\n            if new_lr <= self.min_lr:\n                self._min_reached = True\n                new_lr = self.min_lr\n        else:\n            new_lr = self.min_lr\n\n        new_lr = np.cast[config.floatX](new_lr)\n        algorithm.learning_rate.set_value(new_lr)\n\nclass LinearDecay(object):\n    \"\"\"\n    This is a callback for the SGD algorithm rather than the Train object.\n    This anneals the learning rate to decay_factor times of the initial value\n    during time start till saturate.\n\n    Parameters\n    ----------\n    start : int\n        The step at which to start decreasing the learning rate\n    saturate : int\n        The step at which to stop decreating the learning rate\n    decay_factor : float\n        `final learning rate = decay_factor * initial learning rate`\n    \"\"\"\n\n    def __init__(self, start, saturate, decay_factor):\n        if isinstance(decay_factor, str):\n            decay_factor = float(decay_factor)\n        if isinstance(start, str):\n            start = float(start)\n        if isinstance(saturate, str):\n            saturate = float(saturate)\n        assert isinstance(decay_factor, float)\n        assert isinstance(start, (py_integer_types, py_float_types))\n        assert isinstance(saturate, (py_integer_types, py_float_types))\n        assert saturate > start\n        assert start > 0\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Adjusts the learning rate according to the linear decay schedule\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        if self._count == 0:\n            self._base_lr = algorithm.learning_rate.get_value()\n            self._step = ((self._base_lr - self._base_lr * self.decay_factor) \/\n                          (self.saturate - self.start + 1))\n        self._count += 1\n        if self._count >= self.start:\n            if self._count < self.saturate:\n                new_lr = self._base_lr - self._step * (self._count\n                        - self.start + 1)\n            else:\n                new_lr = self._base_lr * self.decay_factor\n        else:\n            new_lr = self._base_lr\n        assert new_lr > 0\n        new_lr = np.cast[config.floatX](new_lr)\n        algorithm.learning_rate.set_value(new_lr)\n\n\ndef MomentumAdjustor(final_momentum, start, saturate):\n    \"\"\"\n    Deprecated class used with the deprecated init_momentum argument.\n    Use learning_rule.MomentumAdjustor instead.\n\n    Parameters\n    ----------\n    final_momentum : WRITEME\n    start : WRITEME\n    saturate : WRITEME\n    \"\"\"\n    warnings.warn(\"sgd.MomentumAdjustor interface is deprecated and will \"\n    \"become officially unsupported as of May 9, 2014. Please use \"\n    \"`learning_rule.MomentumAdjustor` instead.\")\n    return LRMomentumAdjustor(final_momentum, start, saturate)\n\n\nclass OneOverEpoch(TrainExtension):\n    \"\"\"\n    Scales the learning rate like one over # epochs\n\n    Parameters\n    ----------\n    start : int\n        The epoch on which to start shrinking the learning rate\n    half_life : int, optional\n        How many epochs after start it will take for the learning rate to lose\n        half its value for the first time (to lose the next half of its value\n        will take twice as long)\n    min_lr : float, optional\n        The minimum value the learning rate can take on\n    \"\"\"\n    def __init__(self, start, half_life = None, min_lr = 1e-6):\n        self.__dict__.update(locals())\n        del self.self\n        self._initialized = False\n        self._count = 0\n        assert start >= 0\n        if half_life is None:\n            self.half_life = start + 1\n        else:\n            assert half_life > 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Adjusts the learning rate according to the decay schedule.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n\n        if not self._initialized:\n            self._init_lr = algorithm.learning_rate.get_value()\n            if self._init_lr < self.min_lr:\n                raise ValueError(\"The initial learning rate is smaller than \" +\n                                 \"the minimum allowed learning rate.\")\n            self._initialized = True\n        self._count += 1\n        algorithm.learning_rate.set_value(np.cast[config.floatX](\n            self.current_lr()))\n\n    def current_lr(self):\n        \"\"\"\n        Returns the learning rate currently desired by the decay schedule.\n        \"\"\"\n        if self._count < self.start:\n            scale = 1\n        else:\n            scale = float(self.half_life) \/ float(self._count - self.start\n                    + self.half_life)\n        lr = self._init_lr * scale\n        clipped = max(self.min_lr, lr)\n        return clipped\n\nclass LinearDecayOverEpoch(TrainExtension):\n    \"\"\"\n    Scales the learning rate linearly on each epochs\n\n    Parameters\n    ----------\n    start : int\n        The epoch on which to start shrinking the learning rate\n    saturate : int\n        The epoch to saturate the shrinkage\n    decay_factor : float\n        The final value would be initial learning rate times decay_factor\n    \"\"\"\n\n    def __init__(self, start, saturate, decay_factor):\n        self.__dict__.update(locals())\n        del self.self\n        self._initialized = False\n        self._count = 0\n        assert isinstance(decay_factor, float)\n        assert isinstance(start, (py_integer_types, py_float_types))\n        assert isinstance(saturate, (py_integer_types, py_float_types))\n        assert saturate > start\n        assert start >= 0\n        assert saturate >= start\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Updates the learning rate based on the linear decay schedule.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        if not self._initialized:\n            self._init_lr = algorithm.learning_rate.get_value()\n            self._step = ((self._init_lr - self._init_lr * self.decay_factor) \/\n                          (self.saturate - self.start + 1))\n            self._initialized = True\n        self._count += 1\n        algorithm.learning_rate.set_value(np.cast[config.floatX](\n            self.current_lr()))\n\n    def current_lr(self):\n        \"\"\"\n        Returns the learning rate currently desired by the decay schedule.\n        \"\"\"\n        if self._count >= self.start:\n            if self._count < self.saturate:\n                new_lr = self._init_lr - self._step * (self._count\n                        - self.start + 1)\n            else:\n                new_lr = self._init_lr * self.decay_factor\n        else:\n            new_lr = self._init_lr\n        assert new_lr > 0\n        return new_lr\n\nclass _PolyakWorker(object):\n    \"\"\"\n    Only to be used by the PolyakAveraging TrainingCallback below.\n    Do not use directly.\n    A callback for the SGD class.\n\n    Parameters\n    ----------\n    model : a Model\n        The model whose parameters we want to train with Polyak averaging\n    \"\"\"\n\n    def __init__(self, model):\n        avg_updates = OrderedDict()\n        t = sharedX(1.)\n        self.param_to_mean = OrderedDict()\n        for param in model.get_params():\n            mean = sharedX(param.get_value())\n            assert type(mean) == type(param)\n            self.param_to_mean[param] = mean\n            avg_updates[mean] = mean - (mean - param) \/ t\n            avg_updates[t] = t + 1.\n        self.avg = function([], updates = avg_updates)\n\n    def __call__(self, algorithm):\n        \"\"\"\n        To be called after each SGD step.\n        Updates the Polyak averaged-parameters for this model\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        self.avg()\n\nclass PolyakAveraging(TrainExtension):\n    \"\"\"\n    See \"A Tutorial on Stochastic Approximation Algorithms\n        for Training Restricted Boltzmann Machines and\n        Deep Belief Nets\" by Kevin Swersky et al\n\n    This functionality is still a work in progress. Currently,\n    your model needs to implement \"add_polyak_channels\" to\n    use it.\n\n    The problem is that Polyak averaging shouldn't modify\n    the model parameters. It should keep a second copy\n    that it averages in the background. This second copy\n    doesn't get to come back in and affect the learning process\n    though.\n\n    (IG tried having the second copy get pushed back into\n    the model once per epoch, but this turned out to be\n    harmful, at least in limited tests)\n\n    So we need a cleaner interface for monitoring the\n    averaged copy of the parameters, and we need to make\n    sure the saved model at the end uses the averaged\n    parameters, not the parameters used for computing\n    the gradients during training.\n\n    TODO: make use of the new on_save callback instead\n        of duplicating Train's save_freq flag\n\n    Parameters\n    ----------\n    start : int\n        The epoch after which to start averaging (0 = start averaging\n        immediately)\n    save_path : str, optional\n        WRITEME\n    save_freq : int, optional\n        WRITEME\n\n    Notes\n    -----\n    This is usually used with a fixed, rather than annealed learning\n    rate. It may be used in conjunction with momentum.\n    \"\"\"\n\n    def __init__(self, start, save_path=None, save_freq=1):\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n        assert isinstance(start, py_integer_types)\n        assert start >= 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Make sure Polyak-averaged model gets monitored.\n        Save the model if necessary.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        if self._count == self.start:\n            self._worker = _PolyakWorker(model)\n            algorithm.update_callbacks.append(self._worker)\n            #HACK\n            try:\n                model.add_polyak_channels(self._worker.param_to_mean,\n                                          algorithm.monitoring_dataset)\n            except AttributeError:\n                pass\n        elif self.save_path is not None and self._count > self.start and \\\n                self._count % self.save_freq == 0:\n            saved_params = OrderedDict()\n            for param in model.get_params():\n                saved_params[param] = param.get_value()\n                param.set_value(self._worker.param_to_mean[param].get_value())\n            serial.save(self.save_path, model)\n            for param in model.get_params():\n                param.set_value(saved_params[param])\n        self._count += 1","34":"Similar lines in 2 files\n==sgd:6\n==sgd_alt:7\nfrom __future__ import division\n\n__authors__ = \"Ian Goodfellow\"\n__copyright__ = \"Copyright 2010-2012, Universite de Montreal\"\n__credits__ = [\"Ian Goodfellow, David Warde-Farley\"]\n__license__ = \"3-clause BSD\"\n__maintainer__ = \"David Warde-Farley\"\n__email__ = \"pylearn-dev@googlegroups\"\n\nimport logging\nimport warnings\nimport numpy as np\n\nfrom theano import config\nfrom theano import function\nfrom theano.compat.python2x import OrderedDict\nfrom theano.gof.op import get_debug_values\n\nfrom pylearn2.monitor import Monitor\nfrom pylearn2.space import CompositeSpace, NullSpace\nfrom pylearn2.train_extensions import TrainExtension\nfrom pylearn2.training_algorithms.training_algorithm import TrainingAlgorithm\nfrom pylearn2.training_algorithms.learning_rule import Momentum\nfrom pylearn2.training_algorithms.learning_rule import MomentumAdjustor \\\n        as LRMomentumAdjustor\nfrom pylearn2.utils.iteration import is_stochastic, has_uniform_batch_size\nfrom pylearn2.utils import py_integer_types, py_float_types\nfrom pylearn2.utils import safe_zip\nfrom pylearn2.utils import serial\nfrom pylearn2.utils import sharedX\nfrom pylearn2.utils.data_specs import DataSpecsMapping\nfrom pylearn2.utils.timing import log_timing\nfrom pylearn2.utils.rng import make_np_rng\n\n\nlog = logging.getLogger(__name__)\n\n\nclass SGD(TrainingAlgorithm):\n    \"\"\"\n    SGD = (Minibatch) Stochastic Gradient Descent.\n    A TrainingAlgorithm that does stochastic gradient descent on minibatches\n    of training examples.\n\n    For theoretical background on this algorithm, see Yoshua Bengio's machine\n    learning course notes on the subject:\n\n    http:\/\/www.iro.umontreal.ca\/~pift6266\/H10\/notes\/gradient.html\n\n    Parameters\n    ----------\n    learning_rate : float\n        The learning rate to use. Train object callbacks can change the\n        learning rate after each epoch. SGD update_callbacks can change\n        it after each minibatch.\n    cost : pylearn2.costs.cost.Cost, optional\n        Cost object specifying the objective function to be minimized.\n        Optionally, may be None. In this case, SGD will call the model's\n        get_default_cost method to obtain the objective function.\n    batch_size : int, optional\n        The size of the batch to be used.\n        If not specified, the model will be asked for the batch size, so\n        you must have specified the batch size there.\n        (Some models are rigidly defined to only work with one batch size)\n    monitoring_batch_size : int, optional\n        The size of the monitoring batches.\n    monitoring_batches : int, optional\n        At the start of each epoch, we run \"monitoring\", to evaluate\n        quantities such as the validation set error.\n        monitoring_batches, if specified, determines the number of batches\n        to draw from the iterator for each monitoring dataset.\n        Unnecessary if not using monitoring or if `monitor_iteration_mode`\n        is 'sequential' and `batch_size` is specified (number of\n        batches will be calculated based on full dataset size).\n        TODO: make it possible to specify different monitoring_batches\n        for each monitoring dataset. The Monitor itself already supports\n        this.\n    monitoring_dataset : Dataset or dictionary, optional\n        If not specified, no monitoring is used.\n        If specified to be a Dataset, monitor on that Dataset.\n        If specified to be dictionary, the keys should be string names\n        of datasets, and the values should be Datasets. All monitoring\n        channels will be computed for all monitoring Datasets and will\n        have the dataset name and an underscore prepended to them.\n    monitor_iteration_mode : str, optional\n        The iteration mode used to iterate over the examples in all\n        monitoring datasets. If not specified, defaults to 'sequential'.\n        TODO: make it possible to specify different modes for different\n        datasets.\n    termination_criterion : instance of \\\n        pylearn2.termination_criteria.TerminationCriterion, optional\n\n        Used to determine when the algorithm should stop running.\n        If not specified, runs forever--or more realistically, until\n        external factors halt the python process (Kansas 1977).\n    update_callbacks : list, optional\n        If specified, each member of the list should be a callable that\n        accepts an SGD instance as its only argument.\n        All callbacks will be called with this SGD instance after each\n        SGD step.\n    learning_rule : training_algorithms.learning_rule.LearningRule, optional\n        A learning rule computes the new parameter values given old\n        parameters and first-order gradients. If learning_rule is None,\n        sgd.SGD will update parameters according to the standard SGD\n        learning rule:\n\n        .. code-block:: none\n\n            param := param - learning_rate * d cost \/ d param\n\n        This argument allows more sophisticated learning rules, such\n        as SGD with momentum.\n    init_momentum : float, **DEPRECATED** option\n        Use learning_rule instead.\n        If None, does not use momentum otherwise, use momentum and\n        initialize the momentum coefficient to init_momentum. Callbacks\n        can change this over time just like the learning rate. If the\n        gradient is the same on every step, then the update taken by the\n        SGD algorithm is scaled by a factor of 1\/(1-momentum). See\n        section 9 of Geoffrey Hinton's \"A Practical Guide to Training\n        Restricted Boltzmann Machines\" for details.\n    set_batch_size : bool, optional\n        Defaults to False.\n        If True, and batch_size conflicts with model.force_batch_size,\n        will call model.set_batch_size(batch_size) in an attempt to\n        change model.force_batch_size\n    train_iteration_mode : str, optional\n        Defaults to 'shuffled_sequential'.\n        The iteration mode to use for iterating through training examples.\n    batches_per_iter : int, optional\n        The number of batches to draw from the iterator over training\n        examples.\n        If iteration mode is 'sequential' or 'shuffled_sequential', this\n        is unnecessary; when unspecified we will iterate over all examples.\n    theano_function_mode : a valid argument to theano.function's \\\n        'mode' parameter, optional\n\n        The theano mode to compile the updates function with. Note that\n        pylearn2 includes some wraplinker modes that are not bundled with\n        theano. See pylearn2.devtools. These extra modes let you do\n        things like check for NaNs at every step, or record md5 digests\n        of all computations performed by the update function to help\n        isolate problems with nondeterminism.\n    monitoring_costs : list, optional\n        a list of Cost instances. The Monitor will also include all\n        channels defined by these Costs, even though we don't train\n        using them.\n    seed : valid argument to np.random.RandomState, optional\n        The seed used for the random number generate to be passed to the\n        training dataset iterator (if any)\n    \"\"\"\n    def __init__(self, learning_rate, cost=None, batch_size=None,\n                 monitoring_batch_size=None, monitoring_batches=None,\n                 monitoring_dataset=None, monitor_iteration_mode='sequential',\n                 termination_criterion=None, update_callbacks=None,\n                 learning_rule = None, init_momentum = None,\n                 set_batch_size = False,\n                 train_iteration_mode = None, batches_per_iter=None,\n                 theano_function_mode = None, monitoring_costs=None,\n                 seed=[2012, 10, 5], discriminator_steps=1):","35":"Similar lines in 2 files\n==sgd:219\n==sgd_alt:221\n        if self.cost is None:\n            self.cost = model.get_default_cost()\n\n        inf_params = [param for param in model.get_params()\n                      if np.any(np.isinf(param.get_value()))]\n        if len(inf_params) > 0:\n            raise ValueError(\"These params are Inf: \"+str(inf_params))\n        if any([np.any(np.isnan(param.get_value()))\n                for param in model.get_params()]):\n            nan_params = [param for param in model.get_params()\n                          if np.any(np.isnan(param.get_value()))]\n            raise ValueError(\"These params are NaN: \"+str(nan_params))\n        self.model = model\n\n        self._synchronize_batch_size(model)\n        model._test_batch_size = self.batch_size\n        self.monitor = Monitor.get_monitor(model)\n        self.monitor._sanity_check()\n\n        # test if force batch size and batch size\n        if getattr(model, \"force_batch_size\", False) and \\\n           any(dataset.get_design_matrix().shape[0] % self.batch_size != 0 for\n               dataset in self.monitoring_dataset.values()) and \\\n           not has_uniform_batch_size(self.monitor_iteration_mode):\n\n            raise ValueError(\"Dataset size is not a multiple of batch size.\"\n                             \"You should set monitor_iteration_mode to \"\n                             \"even_sequential, even_shuffled_sequential or \"\n                             \"even_batchwise_shuffled_sequential\")\n\n        data_specs = self.cost.get_data_specs(self.model)\n        mapping = DataSpecsMapping(data_specs)\n        space_tuple = mapping.flatten(data_specs[0], return_tuple=True)\n        source_tuple = mapping.flatten(data_specs[1], return_tuple=True)\n\n        # Build a flat tuple of Theano Variables, one for each space.\n        # We want that so that if the same space\/source is specified\n        # more than once in data_specs, only one Theano Variable\n        # is generated for it, and the corresponding value is passed\n        # only once to the compiled Theano function.\n        theano_args = []\n        for space, source in safe_zip(space_tuple, source_tuple):\n            name = '%s[%s]' % (self.__class__.__name__, source)\n            arg = space.make_theano_batch(name=name,\n                                          batch_size=self.batch_size)\n            theano_args.append(arg)\n        theano_args = tuple(theano_args)\n\n        # Methods of `self.cost` need args to be passed in a format compatible\n        # with data_specs\n        nested_args = mapping.nest(theano_args)\n        fixed_var_descr = self.cost.get_fixed_var_descr(model, nested_args)\n        self.on_load_batch = fixed_var_descr.on_load_batch\n\n        cost_value = self.cost.expr(model, nested_args,\n                                    ** fixed_var_descr.fixed_vars)\n\n        if cost_value is not None and cost_value.name is None:\n            # Concatenate the name of all tensors in theano_args !?\n            cost_value.name = 'objective'\n\n        # Set up monitor to model the objective value, learning rate,\n        # momentum (if applicable), and extra channels defined by\n        # the cost\n        learning_rate = self.learning_rate\n        if self.monitoring_dataset is not None:\n            if (self.monitoring_batch_size is None and\n                    self.monitoring_batches is None):\n                self.monitoring_batch_size = self.batch_size\n                self.monitoring_batches = self.batches_per_iter\n            self.monitor.setup(dataset=self.monitoring_dataset,\n                               cost=self.cost,\n                               batch_size=self.monitoring_batch_size,\n                               num_batches=self.monitoring_batches,\n                               extra_costs=self.monitoring_costs,\n                               mode=self.monitor_iteration_mode)\n            dataset_name = self.monitoring_dataset.keys()[0]\n            monitoring_dataset = self.monitoring_dataset[dataset_name]\n            #TODO: have Monitor support non-data-dependent channels\n            self.monitor.add_channel(name='learning_rate',\n                                     ipt=None,\n                                     val=learning_rate,\n                                     data_specs=(NullSpace(), ''),\n                                     dataset=monitoring_dataset)\n\n            if self.learning_rule:\n                self.learning_rule.add_channels_to_monitor(\n                        self.monitor,\n                        monitoring_dataset)\n\n        params = list(model.get_params())\n        assert len(params) > 0\n        for i, param in enumerate(params):\n            if param.name is None:\n                param.name = 'sgd_params[%d]' % i\n        self.params = params\n\n\n        grads, updates = self.cost.get_gradients(model, nested_args,\n                                                 ** fixed_var_descr.fixed_vars)\n        if not isinstance(grads, OrderedDict):\n            raise TypeError(str(type(self.cost)) + \".get_gradients returned \" +\n                            \"something with\" + str(type(grads)) + \"as its \" +\n                            \"first member. Expected OrderedDict.\")\n\n        for param in grads:\n            assert param in params\n        for param in params:\n            assert param in grads\n\n        lr_scalers = model.get_lr_scalers()\n\n        for key in lr_scalers:\n            if key not in params:\n                raise ValueError(\"Tried to scale the learning rate on \" +\\\n                        str(key)+\" which is not an optimization parameter.\")\n\n        assert len(updates.keys()) == 0\n","36":"Similar lines in 2 files\n==sgd:168\n==sgd_alt:171\n        if isinstance(cost, (list, tuple, set)):\n            raise TypeError(\"SGD no longer supports using collections of \" +\n                            \"Costs to represent a sum of Costs. Use \" +\n                            \"pylearn2.costs.cost.SumOfCosts instead.\")\n\n        if init_momentum:\n            warnings.warn(\"init_momentum interface is deprecated and will \"\n            \"become officially unsuported as of May 9, 2014. Please use the \"\n            \"`learning_rule` parameter instead, providing an object of type \"\n            \"`pylearn2.training_algorithms.learning_rule.Momentum` instead\")\n            # Convert to new interface under the hood.\n            self.learning_rule = Momentum(init_momentum)\n        else:\n            self.learning_rule = learning_rule\n\n        self.learning_rate = sharedX(learning_rate, 'learning_rate')\n        self.cost = cost\n        self.batch_size = batch_size\n        self.set_batch_size = set_batch_size\n        self.batches_per_iter = batches_per_iter\n        self._set_monitoring_dataset(monitoring_dataset)\n        self.monitoring_batch_size = monitoring_batch_size\n        self.monitoring_batches = monitoring_batches\n        self.monitor_iteration_mode = monitor_iteration_mode\n        if monitoring_dataset is None:\n            if monitoring_batch_size is not None:\n                raise ValueError(\"Specified a monitoring batch size \" +\n                                 \"but not a monitoring dataset.\")\n            if monitoring_batches is not None:\n                raise ValueError(\"Specified an amount of monitoring batches \" +\n                                 \"but not a monitoring dataset.\")\n        self.termination_criterion = termination_criterion\n        self._register_update_callbacks(update_callbacks)\n        if train_iteration_mode is None:\n            train_iteration_mode = 'shuffled_sequential'\n        self.train_iteration_mode = train_iteration_mode\n        self.first = True\n        self.rng = make_np_rng(seed, which_method=[\"randn\",\"randint\"])\n        self.theano_function_mode = theano_function_mode\n        self.monitoring_costs = monitoring_costs\n\n    def setup(self, model, dataset):\n        \"\"\"\n        Compiles the theano functions needed for the train method.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        \"\"\"","37":"Similar lines in 2 files\n==sgd:417\n==sgd_alt:428\n        if not hasattr(self, 'd_func'):\n            raise Exception(\"train called without first calling setup\")\n\n        # Make sure none of the parameters have bad values\n        for param in self.params:\n            value = param.get_value(borrow=True)\n            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n                raise Exception(\"NaN in \" + param.name)\n\n        self.first = False\n        rng = self.rng\n        if not is_stochastic(self.train_iteration_mode):\n            rng = None\n\n        data_specs = self.cost.get_data_specs(self.model)\n\n        # The iterator should be built from flat data specs, so it returns\n        # flat, non-redundent tuples of data.\n        mapping = DataSpecsMapping(data_specs)\n        space_tuple = mapping.flatten(data_specs[0], return_tuple=True)\n        source_tuple = mapping.flatten(data_specs[1], return_tuple=True)\n        if len(space_tuple) == 0:\n            # No data will be returned by the iterator, and it is impossible\n            # to know the size of the actual batch.\n            # It is not decided yet what the right thing to do should be.\n            raise NotImplementedError(\"Unable to train with SGD, because \"\n                    \"the cost does not actually use data from the data set. \"\n                    \"data_specs: %s\" % str(data_specs))\n        flat_data_specs = (CompositeSpace(space_tuple), source_tuple)\n\n        iterator = dataset.iterator(mode=self.train_iteration_mode,\n                batch_size=self.batch_size,\n                data_specs=flat_data_specs, return_tuple=True,\n                rng = rng, num_batches = self.batches_per_iter)\n","38":"Similar lines in 2 files\n==sgd:349\n==sgd_alt:356\n            cur_grads = OrderedDict()\n            for param in cur_params:\n                cur_grads[param] = grads[param]\n\n            for param in grads:\n                if grads[param].name is None and cost_value is not None:\n                    grads[param].name = ('grad(%(costname)s, %(paramname)s)' %\n                                         {'costname': cost_value.name,\n                                          'paramname': param.name})\n                assert grads[param].dtype == param.dtype\n\n            cur_lr_scalers = OrderedDict()\n            for param in cur_params:\n                if param in lr_scalers:\n                    lr_scaler = lr_scalers[param]\n                    cur_lr_scalers[param] = lr_scaler\n\n            log.info('Parameter and initial learning rate summary:')\n            for param in cur_params:\n                param_name = param.name\n                if param_name is None:\n                    param_name = 'anon_param'\n                lr = learning_rate.get_value() * cur_lr_scalers.get(param,1.)\n                log.info('\\t' + param_name + ': ' + str(lr))\n","39":"Similar lines in 2 files\n==show_samples_mnist_paper:0\n==show_samples_tfd_paper:0\nfrom pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse\nfrom pylearn2.gui.patch_viewer import PatchViewer\nimport numpy as np\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\n\ngrid_shape = None\n\nrows = 4\nsample_cols = 5\n\n# For some reason format_as from VectorSpace is not working right\nsamples = model.generator.sample(rows * sample_cols).eval()\ntopo_samples = dataset.get_topological_view(samples)\n","40":"Similar lines in 2 files\n==show_samples_mnist_paper:22\n==show_samples_tfd_paper:22\n        is_color=False)\n\nX = dataset.X\ntopo = dataset.get_topological_view()\nindex = 0\nfor i in xrange(samples.shape[0]):\n    topo_sample = topo_samples[i, :, :, :]\n    pv.add_patch(topo_sample * 2. - 1., rescale=False)\n\n    if (i +1) % sample_cols == 0:\n        sample = samples[i, :]\n        dists = np.square(X - sample).sum(axis=1)\n        j = np.argmin(dists)\n        match = topo[j, :]\n        pv.add_patch(match * 2 -1, rescale=False, activation=1)\n\npv.show()","41":"Similar lines in 2 files\n==sgd:387\n==sgd_alt:391\n            for param in cur_params:\n                update = updates[param]\n                if update.name is None:\n                    update.name = 'censor(sgd_update(' + param.name + '))'\n                for update_val in get_debug_values(update):\n                    if np.any(np.isinf(update_val)):\n                        raise ValueError(\"debug value of %s contains infs\" %\n                                update.name)\n                    if np.any(np.isnan(update_val)):\n                        raise ValueError(\"debug value of %s contains nans\" %\n                                update.name)\n","42":"Similar lines in 2 files\n==sgd:340\n==sgd_alt:342\n            updates = OrderedDict()\n\n            assert (learn_discriminator or learn_generator) and not (learn_discriminator and learn_generator)\n\n            if learn_discriminator:\n                cur_params = model.discriminator.get_params()\n            else:\n                cur_params = model.generator.get_params()\n","43":"Similar lines in 3 files\n==show_inpaint_samples:0\n==show_samples_mnist_paper:0\n==show_samples_tfd_paper:0\nfrom pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse","44":"Similar lines in 2 files\n==show_inpaint_samples:25\n==show_samples:43\n    is_color = samples.shape[-1] == 3\nprint (samples.min(), samples.mean(), samples.max())\n# Hack for detecting MNIST [0, 1] values. Otherwise we assume centered images\nif samples.min() >0:\n    samples = samples * 2.0 - 1.0\nviewer = make_viewer(samples, grid_shape=grid_shape, is_color=is_color)\nviewer.show()","45":"Similar lines in 3 files\n==show_inpaint_samples:26\n==show_samples:44\n==show_samples_inpaint:51\nprint (samples.min(), samples.mean(), samples.max())\n# Hack for detecting MNIST [0, 1] values. Otherwise we assume centered images\nif samples.min() >0:\n    samples = samples * 2.0 - 1.0\nviewer = make_viewer(samples, grid_shape=grid_shape, is_color=is_color)\nviewer.show()","46":"Similar lines in 2 files\n==show_inpaint_samples:19\n==show_samples:35\nnum_colors = 1\nif total_dimension % 3 == 0:\n    num_colors = 3\nw = int(np.sqrt(total_dimension \/ num_colors))\nfrom pylearn2.space import Conv2DSpace\ndesired_space = Conv2DSpace(shape=[w, w], num_channels=num_colors, axes=('b',0,1,'c'))","47":"Similar lines in 5 files\n==show_inpaint_samples:0\n==show_samples:0\n==show_samples_mnist_paper:0\n==show_samples_tfd:0\n==show_samples_tfd_paper:0\nfrom pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()","48":"Similar lines in 2 files\n==sgd:400\n==sgd_alt:409\n            with log_timing(log, 'Compiling sgd_update'):\n                return function(theano_args,\n                                           updates=updates,\n                                           name='sgd_update',\n                                           on_unused_input='ignore',\n                                           mode=self.theano_function_mode)","49":"Similar lines in 2 files\n==show_samples:38\n==show_samples_tfd:11\n    w = int(np.sqrt(total_dimension \/ num_colors))\n    from pylearn2.space import Conv2DSpace\n    desired_space = Conv2DSpace(shape=[w, w], num_channels=num_colors, axes=('b',0,1,'c'))\n    samples = space.format_as(batch=model.generator.sample(100),\n            space=desired_space).eval()"},"number":{"0":"W0102","1":"W0201","2":"W0201","3":"W0201","4":"W0201","5":"W0201","6":"W0201","7":"W0201","8":"W0201","9":"W0201","10":"W0201","11":"W0201","12":"W0201","13":"W0201","14":"W0201","15":"W0201","16":"W0201","17":"W0102","18":"W0201","19":"W0201","20":"W0201","21":"W0201","22":"W0201","23":"W0201","24":"W0201","25":"W0201","26":"W0201","27":"W0201","28":"W0201","29":"W0201","30":"W0201","31":"W0201","32":"W0622","33":"R0801","34":"R0801","35":"R0801","36":"R0801","37":"R0801","38":"R0801","39":"R0801","40":"R0801","41":"R0801","42":"R0801","43":"R0801","44":"R0801","45":"R0801","46":"R0801","47":"R0801","48":"R0801","49":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint","36":"pylint","37":"pylint","38":"pylint","39":"pylint","40":"pylint","41":"pylint","42":"pylint","43":"pylint","44":"pylint","45":"pylint","46":"pylint","47":"pylint","48":"pylint","49":"pylint"},"lines_amount":{"0":1140,"1":1140,"2":1140,"3":1140,"4":1140,"5":1140,"6":1140,"7":1140,"8":1140,"9":1140,"10":1140,"11":1140,"12":1140,"13":1140,"14":1140,"15":1140,"16":1140,"17":1152,"18":1152,"19":1152,"20":1152,"21":1152,"22":1152,"23":1152,"24":1152,"25":1152,"26":1152,"27":1152,"28":1152,"29":1152,"30":1152,"31":1152,"32":53,"33":53,"34":53,"35":53,"36":53,"37":53,"38":53,"39":53,"40":53,"41":53,"42":53,"43":53,"44":53,"45":53,"46":53,"47":53,"48":53,"49":53},"commit":{"0":"1720041f51efcb92df61d1638f1a74aea2ae74c2","1":"1720041f51efcb92df61d1638f1a74aea2ae74c2","2":"1720041f51efcb92df61d1638f1a74aea2ae74c2","3":"1720041f51efcb92df61d1638f1a74aea2ae74c2","4":"1720041f51efcb92df61d1638f1a74aea2ae74c2","5":"1720041f51efcb92df61d1638f1a74aea2ae74c2","6":"1720041f51efcb92df61d1638f1a74aea2ae74c2","7":"1720041f51efcb92df61d1638f1a74aea2ae74c2","8":"1720041f51efcb92df61d1638f1a74aea2ae74c2","9":"1720041f51efcb92df61d1638f1a74aea2ae74c2","10":"1720041f51efcb92df61d1638f1a74aea2ae74c2","11":"1720041f51efcb92df61d1638f1a74aea2ae74c2","12":"1720041f51efcb92df61d1638f1a74aea2ae74c2","13":"1720041f51efcb92df61d1638f1a74aea2ae74c2","14":"1720041f51efcb92df61d1638f1a74aea2ae74c2","15":"1720041f51efcb92df61d1638f1a74aea2ae74c2","16":"1720041f51efcb92df61d1638f1a74aea2ae74c2","17":"1720041f51efcb92df61d1638f1a74aea2ae74c2","18":"1720041f51efcb92df61d1638f1a74aea2ae74c2","19":"1720041f51efcb92df61d1638f1a74aea2ae74c2","20":"1720041f51efcb92df61d1638f1a74aea2ae74c2","21":"1720041f51efcb92df61d1638f1a74aea2ae74c2","22":"1720041f51efcb92df61d1638f1a74aea2ae74c2","23":"1720041f51efcb92df61d1638f1a74aea2ae74c2","24":"1720041f51efcb92df61d1638f1a74aea2ae74c2","25":"1720041f51efcb92df61d1638f1a74aea2ae74c2","26":"1720041f51efcb92df61d1638f1a74aea2ae74c2","27":"1720041f51efcb92df61d1638f1a74aea2ae74c2","28":"1720041f51efcb92df61d1638f1a74aea2ae74c2","29":"1720041f51efcb92df61d1638f1a74aea2ae74c2","30":"1720041f51efcb92df61d1638f1a74aea2ae74c2","31":"1720041f51efcb92df61d1638f1a74aea2ae74c2","32":"1720041f51efcb92df61d1638f1a74aea2ae74c2","33":"1720041f51efcb92df61d1638f1a74aea2ae74c2","34":"1720041f51efcb92df61d1638f1a74aea2ae74c2","35":"1720041f51efcb92df61d1638f1a74aea2ae74c2","36":"1720041f51efcb92df61d1638f1a74aea2ae74c2","37":"1720041f51efcb92df61d1638f1a74aea2ae74c2","38":"1720041f51efcb92df61d1638f1a74aea2ae74c2","39":"1720041f51efcb92df61d1638f1a74aea2ae74c2","40":"1720041f51efcb92df61d1638f1a74aea2ae74c2","41":"1720041f51efcb92df61d1638f1a74aea2ae74c2","42":"1720041f51efcb92df61d1638f1a74aea2ae74c2","43":"1720041f51efcb92df61d1638f1a74aea2ae74c2","44":"1720041f51efcb92df61d1638f1a74aea2ae74c2","45":"1720041f51efcb92df61d1638f1a74aea2ae74c2","46":"1720041f51efcb92df61d1638f1a74aea2ae74c2","47":"1720041f51efcb92df61d1638f1a74aea2ae74c2","48":"1720041f51efcb92df61d1638f1a74aea2ae74c2","49":"1720041f51efcb92df61d1638f1a74aea2ae74c2"},"repo":{"0":"goodfeli\/adversarial","1":"goodfeli\/adversarial","2":"goodfeli\/adversarial","3":"goodfeli\/adversarial","4":"goodfeli\/adversarial","5":"goodfeli\/adversarial","6":"goodfeli\/adversarial","7":"goodfeli\/adversarial","8":"goodfeli\/adversarial","9":"goodfeli\/adversarial","10":"goodfeli\/adversarial","11":"goodfeli\/adversarial","12":"goodfeli\/adversarial","13":"goodfeli\/adversarial","14":"goodfeli\/adversarial","15":"goodfeli\/adversarial","16":"goodfeli\/adversarial","17":"goodfeli\/adversarial","18":"goodfeli\/adversarial","19":"goodfeli\/adversarial","20":"goodfeli\/adversarial","21":"goodfeli\/adversarial","22":"goodfeli\/adversarial","23":"goodfeli\/adversarial","24":"goodfeli\/adversarial","25":"goodfeli\/adversarial","26":"goodfeli\/adversarial","27":"goodfeli\/adversarial","28":"goodfeli\/adversarial","29":"goodfeli\/adversarial","30":"goodfeli\/adversarial","31":"goodfeli\/adversarial","32":"goodfeli\/adversarial","33":"goodfeli\/adversarial","34":"goodfeli\/adversarial","35":"goodfeli\/adversarial","36":"goodfeli\/adversarial","37":"goodfeli\/adversarial","38":"goodfeli\/adversarial","39":"goodfeli\/adversarial","40":"goodfeli\/adversarial","41":"goodfeli\/adversarial","42":"goodfeli\/adversarial","43":"goodfeli\/adversarial","44":"goodfeli\/adversarial","45":"goodfeli\/adversarial","46":"goodfeli\/adversarial","47":"goodfeli\/adversarial","48":"goodfeli\/adversarial","49":"goodfeli\/adversarial"},"stargazers":{"0":3217,"1":3217,"2":3217,"3":3217,"4":3217,"5":3217,"6":3217,"7":3217,"8":3217,"9":3217,"10":3217,"11":3217,"12":3217,"13":3217,"14":3217,"15":3217,"16":3217,"17":3217,"18":3217,"19":3217,"20":3217,"21":3217,"22":3217,"23":3217,"24":3217,"25":3217,"26":3217,"27":3217,"28":3217,"29":3217,"30":3217,"31":3217,"32":3217,"33":3217,"34":3217,"35":3217,"36":3217,"37":3217,"38":3217,"39":3217,"40":3217,"41":3217,"42":3217,"43":3217,"44":3217,"45":3217,"46":3217,"47":3217,"48":3217,"49":3217}}
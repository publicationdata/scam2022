{"type":{"0":"W","1":"W","2":"W","3":"W","4":"W","5":"W","6":"W","7":"W","8":"W","9":"W","10":"W","11":"W","12":"C","13":"C","14":"W","15":"W","16":"W","17":"C","18":"R","19":"R","20":"R","21":"R","22":"R","23":"R","24":"R","25":"R","26":"R","27":"R"},"module":{"0":"AverageMeter","1":"AverageMeter","2":"balancedsampler","3":"colab_interpolate","4":"colab_interpolate","5":"demo_MiddleBury","6":"demo_MiddleBury","7":"demo_MiddleBury","8":"demo_MiddleBury_slowmotion","9":"demo_MiddleBury_slowmotion","10":"demo_MiddleBury_slowmotion","11":"loss_function","12":"loss_function","13":"my_args","14":"train","15":"train","16":"train","17":"train","18":"train","19":"train","20":"train","21":"train","22":"train","23":"train","24":"train","25":"train","26":"train","27":"train"},"obj":{"0":"AverageMeter.update","1":"AverageMeter.update","2":"RandomBalancedSampler.__next__","3":"","4":"","5":"","6":"","7":"","8":"","9":"","10":"","11":"","12":"motion_sym_loss","13":"","14":"","15":"","16":"","17":"train","18":"","19":"","20":"","21":"","22":"","23":"","24":"","25":"","26":"","27":""},"lnum":{"0":15,"1":18,"2":20,"3":112,"4":10,"5":78,"6":131,"7":14,"8":74,"9":126,"10":11,"11":8,"12":50,"13":79,"14":8,"15":11,"16":12,"17":31,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1},"col":{"0":8,"1":8,"2":12,"3":17,"4":0,"5":8,"6":19,"7":0,"8":8,"9":19,"10":0,"11":0,"12":7,"13":3,"14":0,"15":0,"16":0,"17":11,"18":0,"19":0,"20":0,"21":0,"22":0,"23":0,"24":0,"25":0,"26":0,"27":0},"filename":{"0":"AverageMeter.py","1":"AverageMeter.py","2":"balancedsampler.py","3":"colab_interpolate.py","4":"colab_interpolate.py","5":"demo_MiddleBury.py","6":"demo_MiddleBury.py","7":"demo_MiddleBury.py","8":"demo_MiddleBury_slowmotion.py","9":"demo_MiddleBury_slowmotion.py","10":"demo_MiddleBury_slowmotion.py","11":"loss_function.py","12":"loss_function.py","13":"my_args.py","14":"train.py","15":"train.py","16":"train.py","17":"train.py","18":"train.py","19":"train.py","20":"train.py","21":"train.py","22":"train.py","23":"train.py","24":"train.py","25":"train.py","26":"train.py","27":"train.py"},"symbol":{"0":"attribute-defined-outside-init","1":"attribute-defined-outside-init","2":"attribute-defined-outside-init","3":"redefined-builtin","4":"wildcard-import","5":"redefined-builtin","6":"redefined-builtin","7":"wildcard-import","8":"redefined-builtin","9":"redefined-builtin","10":"wildcard-import","11":"wildcard-import","12":"singleton-comparison","13":"singleton-comparison","14":"wildcard-import","15":"wildcard-import","16":"wildcard-import","17":"singleton-comparison","18":"duplicate-code","19":"duplicate-code","20":"duplicate-code","21":"duplicate-code","22":"duplicate-code","23":"duplicate-code","24":"duplicate-code","25":"duplicate-code","26":"duplicate-code","27":"duplicate-code"},"text":{"0":"Attribute 'val' defined outside __init__","1":"Attribute 'avg' defined outside __init__","2":"Attribute 'indices' defined outside __init__","3":"Redefining built-in 'filter'","4":"Wildcard import AverageMeter","5":"Redefining built-in 'dir'","6":"Redefining built-in 'filter'","7":"Wildcard import AverageMeter","8":"Redefining built-in 'dir'","9":"Redefining built-in 'filter'","10":"Wildcard import AverageMeter","11":"Wildcard import lr_scheduler","12":"Comparison 'occlusion == None' should be 'occlusion is None'","13":"Comparison 'args.uid == None' should be 'args.uid is None'","14":"Wildcard import lr_scheduler","15":"Wildcard import AverageMeter","16":"Wildcard import loss_function","17":"Comparison 'args.SAVED_MODEL == None' should be 'args.SAVED_MODEL is None'","18":"Similar lines in 2 files\n==demo_MiddleBury:83\n==demo_MiddleBury_slowmotion:78\n        gt_path = os.path.join(MB_Other_GT, dir, \"frame10i11.png\")\n\n        X0 =  torch.from_numpy( np.transpose(imread(arguments_strFirst) , (2,0,1)).astype(\"float32\")\/ 255.0).type(dtype)\n        X1 =  torch.from_numpy( np.transpose(imread(arguments_strSecond) , (2,0,1)).astype(\"float32\")\/ 255.0).type(dtype)\n\n\n        y_ = torch.FloatTensor()\n\n        assert (X0.size(1) == X1.size(1))\n        assert (X0.size(2) == X1.size(2))\n\n        intWidth = X0.size(2)\n        intHeight = X0.size(1)\n        channel = X0.size(0)\n        if not channel == 3:\n            continue\n\n        if intWidth != ((intWidth >> 7) << 7):\n            intWidth_pad = (((intWidth >> 7) + 1) << 7)  # more than necessary\n            intPaddingLeft =int(( intWidth_pad - intWidth)\/2)\n            intPaddingRight = intWidth_pad - intWidth - intPaddingLeft\n        else:\n            intWidth_pad = intWidth\n            intPaddingLeft = 32\n            intPaddingRight= 32\n\n        if intHeight != ((intHeight >> 7) << 7):\n            intHeight_pad = (((intHeight >> 7) + 1) << 7)  # more than necessary\n            intPaddingTop = int((intHeight_pad - intHeight) \/ 2)\n            intPaddingBottom = intHeight_pad - intHeight - intPaddingTop\n        else:\n            intHeight_pad = intHeight\n            intPaddingTop = 32\n            intPaddingBottom = 32\n\n        pader = torch.nn.ReplicationPad2d([intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom])\n\n        torch.set_grad_enabled(False)\n        X0 = Variable(torch.unsqueeze(X0,0))\n        X1 = Variable(torch.unsqueeze(X1,0))\n        X0 = pader(X0)\n        X1 = pader(X1)\n\n        if use_cuda:\n            X0 = X0.cuda()\n            X1 = X1.cuda()\n        proc_end = time.time()\n        y_s,offset,filter = model(torch.stack((X0, X1),dim = 0))\n        y_ = y_s[save_which]\n\n        proc_timer.update(time.time() -proc_end)\n        tot_timer.update(time.time() - end)\n        end  = time.time()\n        print(\"*****************current image process time \\t \" + str(time.time()-proc_end )+\"s ******************\" )\n        if use_cuda:\n            X0 = X0.data.cpu().numpy()","19":"Similar lines in 2 files\n==demo_MiddleBury:28\n==demo_MiddleBury_slowmotion:25\n                                    filter_size = args.filter_size ,\n                                    timestep=args.time_step,\n                                    training=False)\n\nif args.use_cuda:\n    model = model.cuda()\n\nargs.SAVED_MODEL = '.\/model_weights\/best.pth'\nif os.path.exists(args.SAVED_MODEL):\n    print(\"The testing model weight is: \" + args.SAVED_MODEL)\n    if not args.use_cuda:\n        pretrained_dict = torch.load(args.SAVED_MODEL, map_location=lambda storage, loc: storage)\n        # model.load_state_dict(torch.load(args.SAVED_MODEL, map_location=lambda storage, loc: storage))\n    else:\n        pretrained_dict = torch.load(args.SAVED_MODEL)\n        # model.load_state_dict(torch.load(args.SAVED_MODEL))\n\n    model_dict = model.state_dict()\n    # 1. filter out unnecessary keys\n    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n    # 2. overwrite entries in the existing state dict\n    model_dict.update(pretrained_dict)\n    # 3. load the new state dict\n    model.load_state_dict(model_dict)\n    # 4. release the pretrained dict for saving memory\n    pretrained_dict = []\nelse:\n    print(\"*****************************************************************\")\n    print(\"**** We don't load any trained weights **************************\")\n    print(\"*****************************************************************\")\n\nmodel = model.eval() # deploy mode\n","20":"Similar lines in 2 files\n==demo_MiddleBury:62\n==demo_MiddleBury_slowmotion:58\nuse_cuda=args.use_cuda\nsave_which=args.save_which\ndtype = args.dtype\nunique_id =str(random.randint(0, 100000))\nprint(\"The unique id for current testing is: \" + str(unique_id))\n\ninterp_error = AverageMeter()\nif DO_MiddleBurryOther:\n    subdir = os.listdir(MB_Other_DATA)\n    gen_dir = os.path.join(MB_Other_RESULT, unique_id)\n    os.mkdir(gen_dir)\n\n    tot_timer = AverageMeter()\n    proc_timer = AverageMeter()\n    end = time.time()\n    for dir in subdir:\n        print(dir)\n        os.mkdir(os.path.join(gen_dir, dir))\n        arguments_strFirst = os.path.join(MB_Other_DATA, dir, \"frame10.png\")\n        arguments_strSecond = os.path.join(MB_Other_DATA, dir, \"frame11.png\")","21":"Similar lines in 2 files\n==colab_interpolate:115\n==demo_MiddleBury_slowmotion:133\n        X0 = X0.data.cpu().numpy()\n        if not isinstance(y_, list):\n            y_ = y_.data.cpu().numpy()\n        else:\n            y_ = [item.data.cpu().numpy() for item in y_]\n        offset = [offset_i.data.cpu().numpy() for offset_i in offset]\n        filter = [filter_i.data.cpu().numpy() for filter_i in filter]  if filter[0] is not None else None\n        X1 = X1.data.cpu().numpy()\n    else:\n        X0 = X0.data.numpy()\n        if not isinstance(y_, list):\n            y_ = y_.data.numpy()\n        else:\n            y_ = [item.data.numpy() for item in y_]\n        offset = [offset_i.data.numpy() for offset_i in offset]\n        filter = [filter_i.data.numpy() for filter_i in filter]\n        X1 = X1.data.numpy()\n","22":"Similar lines in 2 files\n==demo_MiddleBury:18\n==demo_MiddleBury_slowmotion:15\nDO_MiddleBurryOther = True\nMB_Other_DATA = \".\/MiddleBurySet\/other-data\/\"\nMB_Other_RESULT = \".\/MiddleBurySet\/other-result-author\/\"\nMB_Other_GT = \".\/MiddleBurySet\/other-gt-interp\/\"\nif not os.path.exists(MB_Other_RESULT):\n    os.mkdir(MB_Other_RESULT)\n\n\n","23":"Similar lines in 3 files\n==colab_interpolate:35\n==demo_MiddleBury:45\n==demo_MiddleBury_slowmotion:42\nmodel_dict = model.state_dict()\n# 1. filter out unnecessary keys\npretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n# 2. overwrite entries in the existing state dict\nmodel_dict.update(pretrained_dict)\n# 3. load the new state dict\nmodel.load_state_dict(model_dict)\n# 4. release the pretrained dict for saving memory\npretrained_dict = []","24":"Similar lines in 3 files\n==colab_interpolate:89\n==demo_MiddleBury:106\n==demo_MiddleBury_slowmotion:101\n            intPaddingLeft = 32\n            intPaddingRight= 32\n\n        if intHeight != ((intHeight >> 7) << 7):\n            intHeight_pad = (((intHeight >> 7) + 1) << 7)  # more than necessary\n            intPaddingTop = int((intHeight_pad - intHeight) \/ 2)\n            intPaddingBottom = intHeight_pad - intHeight - intPaddingTop\n        else:","25":"Similar lines in 3 files\n==colab_interpolate:136\n==demo_MiddleBury:154\n==demo_MiddleBury_slowmotion:156\n        offset = [np.transpose(offset_i[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0)) for offset_i in offset]\n        filter = [np.transpose(\n            filter_i[0, :, intPaddingTop:intPaddingTop + intHeight, intPaddingLeft: intPaddingLeft + intWidth],\n            (1, 2, 0)) for filter_i in filter]  if filter is not None else None\n        X1 = np.transpose(255.0 * X1.clip(0,1.0)[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0))\n","26":"Similar lines in 2 files\n==demo_MiddleBury:6\n==demo_MiddleBury_slowmotion:4\nimport random\nimport numpy as np\nimport numpy\nimport networks\nfrom my_args import  args","27":"Similar lines in 3 files\n==colab_interpolate:120\n==demo_MiddleBury:140\n==demo_MiddleBury_slowmotion:138\n            offset = [offset_i.data.cpu().numpy() for offset_i in offset]\n            filter = [filter_i.data.cpu().numpy() for filter_i in filter]  if filter[0] is not None else None\n            X1 = X1.data.cpu().numpy()\n        else:\n            X0 = X0.data.numpy()"},"number":{"0":"W0201","1":"W0201","2":"W0201","3":"W0622","4":"W0401","5":"W0622","6":"W0622","7":"W0401","8":"W0622","9":"W0622","10":"W0401","11":"W0401","12":"C0121","13":"C0121","14":"W0401","15":"W0401","16":"W0401","17":"C0121","18":"R0801","19":"R0801","20":"R0801","21":"R0801","22":"R0801","23":"R0801","24":"R0801","25":"R0801","26":"R0801","27":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint"},"lines_amount":{"0":19,"1":19,"2":58,"3":163,"4":163,"5":182,"6":182,"7":182,"8":186,"9":186,"10":186,"11":87,"12":87,"13":125,"14":264,"15":264,"16":264,"17":264,"18":264,"19":264,"20":264,"21":264,"22":264,"23":264,"24":264,"25":264,"26":264,"27":264},"commit":{"0":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","1":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","2":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","3":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","4":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","5":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","6":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","7":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","8":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","9":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","10":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","11":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","12":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","13":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","14":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","15":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","16":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","17":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","18":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","19":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","20":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","21":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","22":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","23":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","24":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","25":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","26":"9d9c0d7b3718dfcda9061c85efec472478a3aa86","27":"9d9c0d7b3718dfcda9061c85efec472478a3aa86"},"repo":{"0":"baowenbo\/DAIN","1":"baowenbo\/DAIN","2":"baowenbo\/DAIN","3":"baowenbo\/DAIN","4":"baowenbo\/DAIN","5":"baowenbo\/DAIN","6":"baowenbo\/DAIN","7":"baowenbo\/DAIN","8":"baowenbo\/DAIN","9":"baowenbo\/DAIN","10":"baowenbo\/DAIN","11":"baowenbo\/DAIN","12":"baowenbo\/DAIN","13":"baowenbo\/DAIN","14":"baowenbo\/DAIN","15":"baowenbo\/DAIN","16":"baowenbo\/DAIN","17":"baowenbo\/DAIN","18":"baowenbo\/DAIN","19":"baowenbo\/DAIN","20":"baowenbo\/DAIN","21":"baowenbo\/DAIN","22":"baowenbo\/DAIN","23":"baowenbo\/DAIN","24":"baowenbo\/DAIN","25":"baowenbo\/DAIN","26":"baowenbo\/DAIN","27":"baowenbo\/DAIN"}}
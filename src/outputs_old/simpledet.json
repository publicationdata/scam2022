{"type":{"0":"C","1":"W","2":"R","3":"C","4":"R","5":"R","6":"C","7":"W","8":"R","9":"R","10":"C","11":"C","12":"W","13":"R","14":"R","15":"R","16":"R","17":"R","18":"R","19":"R","20":"R","21":"R","22":"R","23":"R","24":"R","25":"R","26":"R","27":"R","28":"R","29":"R","30":"R","31":"R","32":"R","33":"R","34":"R","35":"R"},"module":{"0":"detection_infer_speed","1":"detection_test","2":"detection_test","3":"detection_test","4":"detection_test","5":"detection_train","6":"detection_train","7":"mask_test","8":"mask_test","9":"mask_test","10":"mask_test","11":"mask_test","12":"rpn_test","13":"rpn_test","14":"rpn_test","15":"rpn_test","16":"rpn_test","17":"rpn_test","18":"rpn_test","19":"rpn_test","20":"rpn_test","21":"rpn_test","22":"rpn_test","23":"rpn_test","24":"rpn_test","25":"rpn_test","26":"rpn_test","27":"rpn_test","28":"rpn_test","29":"rpn_test","30":"rpn_test","31":"rpn_test","32":"rpn_test","33":"rpn_test","34":"rpn_test","35":"rpn_test"},"obj":{"0":"","1":"","2":"","3":"","4":"","5":"train_net","6":"train_net","7":"","8":"","9":"","10":"","11":"","12":"","13":"","14":"","15":"","16":"","17":"","18":"","19":"","20":"","21":"","22":"","23":"","24":"","25":"","26":"","27":"","28":"","29":"","30":"","31":"","32":"","33":"","34":"","35":""},"lnum":{"0":48,"1":168,"2":51,"3":121,"4":298,"5":68,"6":147,"7":163,"8":55,"9":318,"10":329,"11":339,"12":136,"13":50,"14":217,"15":1,"16":1,"17":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1},"col":{"0":15,"1":17,"2":27,"3":23,"4":14,"5":23,"6":15,"7":17,"8":27,"9":14,"10":7,"11":8,"12":17,"13":27,"14":14,"15":0,"16":0,"17":0,"18":0,"19":0,"20":0,"21":0,"22":0,"23":0,"24":0,"25":0,"26":0,"27":0,"28":0,"29":0,"30":0,"31":0,"32":0,"33":0,"34":0,"35":0},"filename":{"0":"detection_infer_speed.py","1":"detection_test.py","2":"detection_test.py","3":"detection_test.py","4":"detection_test.py","5":"detection_train.py","6":"detection_train.py","7":"mask_test.py","8":"mask_test.py","9":"mask_test.py","10":"mask_test.py","11":"mask_test.py","12":"rpn_test.py","13":"rpn_test.py","14":"rpn_test.py","15":"rpn_test.py","16":"rpn_test.py","17":"rpn_test.py","18":"rpn_test.py","19":"rpn_test.py","20":"rpn_test.py","21":"rpn_test.py","22":"rpn_test.py","23":"rpn_test.py","24":"rpn_test.py","25":"rpn_test.py","26":"rpn_test.py","27":"rpn_test.py","28":"rpn_test.py","29":"rpn_test.py","30":"rpn_test.py","31":"rpn_test.py","32":"rpn_test.py","33":"rpn_test.py","34":"rpn_test.py","35":"rpn_test.py"},"symbol":{"0":"singleton-comparison","1":"redefined-builtin","2":"consider-using-with","3":"singleton-comparison","4":"consider-using-with","5":"consider-using-with","6":"singleton-comparison","7":"redefined-builtin","8":"consider-using-with","9":"consider-using-with","10":"singleton-comparison","11":"consider-using-enumerate","12":"redefined-builtin","13":"consider-using-with","14":"consider-using-with","15":"duplicate-code","16":"duplicate-code","17":"duplicate-code","18":"duplicate-code","19":"duplicate-code","20":"duplicate-code","21":"duplicate-code","22":"duplicate-code","23":"duplicate-code","24":"duplicate-code","25":"duplicate-code","26":"duplicate-code","27":"duplicate-code","28":"duplicate-code","29":"duplicate-code","30":"duplicate-code","31":"duplicate-code","32":"duplicate-code","33":"duplicate-code","34":"duplicate-code","35":"duplicate-code"},"text":{"0":"Comparison 'pGen.fp16 == False' should be 'pGen.fp16 is False' if checking for the singleton value False, or 'not pGen.fp16' if testing for falsiness","1":"Redefining built-in 'id'","2":"Consider using 'with' for resource-allocating operations","3":"Comparison 'pGen.fp16 == False' should be 'pGen.fp16 is False' if checking for the singleton value False, or 'not pGen.fp16' if testing for falsiness","4":"Consider using 'with' for resource-allocating operations","5":"Consider using 'with' for resource-allocating operations","6":"Comparison 'pGen.fp16 == False' should be 'pGen.fp16 is False' if checking for the singleton value False, or 'not pGen.fp16' if testing for falsiness","7":"Redefining built-in 'id'","8":"Consider using 'with' for resource-allocating operations","9":"Consider using 'with' for resource-allocating operations","10":"Comparison 'rescoring_mask == False' should be 'rescoring_mask is False' if checking for the singleton value False, or 'not rescoring_mask' if testing for falsiness","11":"Consider using enumerate instead of iterating with range and len","12":"Redefining built-in 'id'","13":"Consider using 'with' for resource-allocating operations","14":"Consider using 'with' for resource-allocating operations","15":"Similar lines in 2 files\n==detection_test:49\n==rpn_test:48\n    image_sets = pDataset.image_set\n    roidbs_all = [pkl.load(open(\"data\/cache\/{}.roidb\".format(i), \"rb\"), encoding=\"latin1\") for i in image_sets]\n    roidbs_all = reduce(lambda x, y: x + y, roidbs_all)\n\n    from pycocotools.coco import COCO\n    from pycocotools.cocoeval import COCOeval\n    from utils.roidb_to_coco import roidb_to_coco\n    if pTest.coco.annotation is not None:\n        coco = COCO(pTest.coco.annotation)\n    else:\n        coco = roidb_to_coco(roidbs_all)\n\n    data_queue = Queue(100)\n    result_queue = Queue()\n\n    execs = []\n    workers = []\n    coco_result = []\n    split_size = 1000\n\n    for index_split in range(int(math.ceil(len(roidbs_all) \/ split_size))):\n        print(\"evaluating [%d, %d)\" % (index_split * split_size, (index_split + 1) * split_size))\n        roidb = roidbs_all[index_split * split_size:(index_split + 1) * split_size]\n        roidb = pTest.process_roidb(roidb)\n        for i, x in enumerate(roidb):\n            x[\"rec_id\"] = np.array(i, dtype=np.float32)\n            x[\"im_id\"] = np.array(x[\"im_id\"], dtype=np.float32)\n\n        loader = Loader(roidb=roidb,\n                        transform=transform,\n                        data_name=data_name,\n                        label_name=label_name,\n                        batch_size=1,\n                        shuffle=False,\n                        num_worker=4,\n                        num_collector=2,\n                        worker_queue_depth=2,\n                        collector_queue_depth=2)\n\n        print(\"total number of images: {}\".format(loader.total_batch))\n\n        data_names = [k[0] for k in loader.provide_data]\n\n        if index_split == 0:","16":"Similar lines in 2 files\n==detection_test:132\n==rpn_test:100\n            for i in pKv.gpus:\n                ctx = mx.gpu(i)\n                mod = DetModule(sym, data_names=data_names, context=ctx)\n                mod.bind(data_shapes=loader.provide_data, for_training=False)\n                mod.set_params(arg_params, aux_params, allow_extra=False)\n                execs.append(mod)\n\n        all_outputs = []\n\n        if index_split == 0:\n            def eval_worker(exe, data_queue, result_queue):\n                while True:\n                    batch = data_queue.get()\n                    exe.forward(batch, is_train=False)\n                    out = [x.asnumpy() for x in exe.get_outputs()]\n                    result_queue.put(out)\n            for exe in execs:\n                workers.append(Thread(target=eval_worker, args=(exe, data_queue, result_queue)))\n            for w in workers:\n                w.daemon = True\n                w.start()\n\n        import time\n        t1_s = time.time()\n\n        def data_enqueue(loader, data_queue):\n            for batch in loader:\n                data_queue.put(batch)\n        enqueue_worker = Thread(target=data_enqueue, args=(loader, data_queue))\n        enqueue_worker.daemon = True\n        enqueue_worker.start()\n\n        for _ in range(loader.total_batch):\n            r = result_queue.get()\n","17":"Similar lines in 2 files\n==mask_test:69\n==rpn_test:66\n    split_size = 1000\n\n    for index_split in range(int(math.ceil(len(roidbs_all) \/ split_size))):\n        print(\"evaluating [%d, %d)\" % (index_split * split_size, (index_split + 1) * split_size))\n        roidb = roidbs_all[index_split * split_size:(index_split + 1) * split_size]\n        roidb = pTest.process_roidb(roidb)\n        for i, x in enumerate(roidb):\n            x[\"rec_id\"] = np.array(i, dtype=np.float32)\n            x[\"im_id\"] = np.array(x[\"im_id\"], dtype=np.float32)\n\n        loader = Loader(roidb=roidb,\n                        transform=transform,\n                        data_name=data_name,\n                        label_name=label_name,\n                        batch_size=1,\n                        shuffle=False,\n                        num_worker=4,\n                        num_collector=2,\n                        worker_queue_depth=2,\n                        collector_queue_depth=2)\n\n        print(\"total number of images: {}\".format(loader.total_batch))\n\n        data_names = [k[0] for k in loader.provide_data]\n\n        if index_split == 0:\n            arg_params, aux_params = load_checkpoint(pTest.model.prefix, pTest.model.epoch)\n            if pModel.process_weight is not None:\n                pModel.process_weight(sym, arg_params, aux_params)\n\n            # merge batch normalization to speedup test\n            from utils.graph_optimize import merge_bn","18":"Similar lines in 2 files\n==mask_test:23\n==rpn_test:18\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Test Detection')\n    # general\n    parser.add_argument('--config', help='config file path', type=str)\n    args = parser.parse_args()\n\n    config = importlib.import_module(args.config.replace('.py', '').replace('\/', '.'))\n    return config\n\n\nif __name__ == \"__main__\":\n    os.environ[\"MXNET_CUDNN_AUTOTUNE_DEFAULT\"] = \"0\"\n\n    config = parse_args()\n\n    pGen, pKv, pRpn, pRoi, pBbox, pDataset, pModel, pOpt, pTest, \\\n    transform, data_name, label_name, metric_list = config.get_config(is_train=False)\n    pGen = patch_config_as_nothrow(pGen)\n    pKv = patch_config_as_nothrow(pKv)\n    pRpn = patch_config_as_nothrow(pRpn)\n    pRoi = patch_config_as_nothrow(pRoi)\n    pBbox = patch_config_as_nothrow(pBbox)\n    pDataset = patch_config_as_nothrow(pDataset)\n    pModel = patch_config_as_nothrow(pModel)\n    pOpt = patch_config_as_nothrow(pOpt)\n    pTest = patch_config_as_nothrow(pTest)\n","19":"Similar lines in 2 files\n==detection_test:196\n==rpn_test:165\n        output_dict = {}\n        for rec in all_outputs:\n            im_id = rec[\"im_id\"]\n            if im_id not in output_dict:\n                output_dict[im_id] = dict(\n                    bbox_xyxy=[rec[\"bbox_xyxy\"]],\n                    cls_score=[rec[\"cls_score\"]]\n                )\n            else:\n                output_dict[im_id][\"bbox_xyxy\"].append(rec[\"bbox_xyxy\"])\n                output_dict[im_id][\"cls_score\"].append(rec[\"cls_score\"])\n\n        for k in output_dict:\n            if len(output_dict[k][\"bbox_xyxy\"]) > 1:\n                output_dict[k][\"bbox_xyxy\"] = np.concatenate(output_dict[k][\"bbox_xyxy\"])\n            else:\n                output_dict[k][\"bbox_xyxy\"] = output_dict[k][\"bbox_xyxy\"][0]\n\n            if len(output_dict[k][\"cls_score\"]) > 1:\n                output_dict[k][\"cls_score\"] = np.concatenate(output_dict[k][\"cls_score\"])\n            else:\n                output_dict[k][\"cls_score\"] = output_dict[k][\"cls_score\"][0]\n\n        t3_s = time.time()\n        print(\"aggregate uses: %.1f\" % (t3_s - t2_s))\n","20":"Similar lines in 2 files\n==detection_test:67\n==mask_test:69\n    split_size = 1000\n\n    for index_split in range(int(math.ceil(len(roidbs_all) \/ split_size))):\n        print(\"evaluating [%d, %d)\" % (index_split * split_size, (index_split + 1) * split_size))\n        roidb = roidbs_all[index_split * split_size:(index_split + 1) * split_size]\n        roidb = pTest.process_roidb(roidb)\n        for i, x in enumerate(roidb):\n            x[\"rec_id\"] = np.array(i, dtype=np.float32)\n            x[\"im_id\"] = np.array(x[\"im_id\"], dtype=np.float32)\n\n        loader = Loader(roidb=roidb,\n                        transform=transform,\n                        data_name=data_name,\n                        label_name=label_name,\n                        batch_size=1,\n                        shuffle=False,\n                        num_worker=4,\n                        num_collector=2,\n                        worker_queue_depth=2,\n                        collector_queue_depth=2)\n\n        print(\"total number of images: {}\".format(loader.total_batch))\n\n        data_names = [k[0] for k in loader.provide_data]\n\n        if index_split == 0:","21":"Similar lines in 3 files\n==detection_test:132\n==mask_test:121\n==rpn_test:100\n            for i in pKv.gpus:\n                ctx = mx.gpu(i)\n                mod = DetModule(sym, data_names=data_names, context=ctx)\n                mod.bind(data_shapes=loader.provide_data, for_training=False)\n                mod.set_params(arg_params, aux_params, allow_extra=False)\n                execs.append(mod)\n\n        all_outputs = []\n\n        if index_split == 0:\n            def eval_worker(exe, data_queue, result_queue):\n                while True:\n                    batch = data_queue.get()\n                    exe.forward(batch, is_train=False)\n                    out = [x.asnumpy() for x in exe.get_outputs()]\n                    result_queue.put(out)","22":"Similar lines in 2 files\n==detection_test:98\n==mask_test:106\n            worker_data_shape = dict(loader.provide_data + loader.provide_label)\n            for key in worker_data_shape:\n                worker_data_shape[key] = (pKv.batch_image,) + worker_data_shape[key][1:]\n            arg_shape, _, aux_shape = sym.infer_shape(**worker_data_shape)\n            _, out_shape, _ = sym.get_internals().infer_shape(**worker_data_shape)\n            out_shape_dict = list(zip(sym.get_internals().list_outputs(), out_shape))\n            _, out_shape, _ = sym.infer_shape(**worker_data_shape)\n            terminal_out_shape_dict = zip(sym.list_outputs(), out_shape)\n            print('parameter shape')\n            print(pprint.pformat([i for i in out_shape_dict if not i[0].endswith('output')]))\n            print('intermediate output shape')\n            print(pprint.pformat([i for i in out_shape_dict if i[0].endswith('output')]))\n            print('terminal output shape')\n            print(pprint.pformat([i for i in terminal_out_shape_dict]))\n","23":"Similar lines in 2 files\n==mask_test:5\n==rpn_test:4\nimport pickle as pkl\nfrom functools import reduce\nfrom queue import Queue\nfrom threading import Thread\n\nfrom core.detection_module import DetModule\nfrom core.detection_input import Loader\nfrom utils.load_model import load_checkpoint\nfrom utils.patch_config import patch_config_as_nothrow\n\nimport mxnet as mx\nimport numpy as np\n","24":"Similar lines in 2 files\n==detection_test:35\n==mask_test:38\n    pGen, pKv, pRpn, pRoi, pBbox, pDataset, pModel, pOpt, pTest, \\\n    transform, data_name, label_name, metric_list = config.get_config(is_train=False)\n    pGen = patch_config_as_nothrow(pGen)\n    pKv = patch_config_as_nothrow(pKv)\n    pRpn = patch_config_as_nothrow(pRpn)\n    pRoi = patch_config_as_nothrow(pRoi)\n    pBbox = patch_config_as_nothrow(pBbox)\n    pDataset = patch_config_as_nothrow(pDataset)\n    pModel = patch_config_as_nothrow(pModel)\n    pOpt = patch_config_as_nothrow(pOpt)\n    pTest = patch_config_as_nothrow(pTest)\n\n    sym = pModel.test_symbol","25":"Similar lines in 2 files\n==detection_test:35\n==rpn_test:33\n    pGen, pKv, pRpn, pRoi, pBbox, pDataset, pModel, pOpt, pTest, \\\n    transform, data_name, label_name, metric_list = config.get_config(is_train=False)\n    pGen = patch_config_as_nothrow(pGen)\n    pKv = patch_config_as_nothrow(pKv)\n    pRpn = patch_config_as_nothrow(pRpn)\n    pRoi = patch_config_as_nothrow(pRoi)\n    pBbox = patch_config_as_nothrow(pBbox)\n    pDataset = patch_config_as_nothrow(pDataset)\n    pModel = patch_config_as_nothrow(pModel)\n    pOpt = patch_config_as_nothrow(pOpt)\n    pTest = patch_config_as_nothrow(pTest)\n","26":"Similar lines in 4 files\n==detection_test:37\n==detection_train:21\n==mask_test:40\n==rpn_test:35\n    pGen = patch_config_as_nothrow(pGen)\n    pKv = patch_config_as_nothrow(pKv)\n    pRpn = patch_config_as_nothrow(pRpn)\n    pRoi = patch_config_as_nothrow(pRoi)\n    pBbox = patch_config_as_nothrow(pBbox)\n    pDataset = patch_config_as_nothrow(pDataset)\n    pModel = patch_config_as_nothrow(pModel)\n    pOpt = patch_config_as_nothrow(pOpt)\n    pTest = patch_config_as_nothrow(pTest)\n","27":"Similar lines in 2 files\n==detection_test:118\n==detection_train:144\n            if pModel.QuantizeTrainingParam is not None and pModel.QuantizeTrainingParam.quantize_flag:\n                pQuant = pModel.QuantizeTrainingParam\n                assert pGen.fp16 == False, \"current quantize training only support fp32 mode.\"\n                from utils.graph_optimize import attach_quantize_node\n                _, out_shape, _ = sym.get_internals().infer_shape(**worker_data_shape)\n                out_shape_dictoinary = dict(zip(sym.get_internals().list_outputs(), out_shape))\n                sym = attach_quantize_node(sym, out_shape_dictoinary, pQuant.WeightQuantizeParam,\n                                        pQuant.ActQuantizeParam, pQuant.quantized_op)\n","28":"Similar lines in 3 files\n==detection_test:160\n==mask_test:155\n==rpn_test:128\n        enqueue_worker = Thread(target=data_enqueue, args=(loader, data_queue))\n        enqueue_worker.daemon = True\n        enqueue_worker.start()\n\n        for _ in range(loader.total_batch):\n            r = result_queue.get()\n","29":"Similar lines in 3 files\n==detection_test:148\n==mask_test:139\n==rpn_test:116\n            for exe in execs:\n                workers.append(Thread(target=eval_worker, args=(exe, data_queue, result_queue)))\n            for w in workers:\n                w.daemon = True\n                w.start()\n\n        import time","30":"Similar lines in 2 files\n==detection_test:303\n==rpn_test:224\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n    t6_s = time.time()\n    print(\"coco eval uses: %.1f\" % (t6_s - t5_s))","31":"Similar lines in 2 files\n==detection_test:278\n==rpn_test:197\n                xs = det[:, 0]\n                ys = det[:, 1]\n                ws = det[:, 2] - xs + 1\n                hs = det[:, 3] - ys + 1\n                result += [\n                    {'image_id': int(iid),","32":"Similar lines in 3 files\n==detection_test:196\n==mask_test:213\n==rpn_test:165\n        output_dict = {}\n        for rec in all_outputs:\n            im_id = rec[\"im_id\"]\n            if im_id not in output_dict:\n                output_dict[im_id] = dict(\n                    bbox_xyxy=[rec[\"bbox_xyxy\"]],","33":"Similar lines in 3 files\n==detection_test:61\n==mask_test:62\n==rpn_test:60\n    data_queue = Queue(100)\n    result_queue = Queue()\n\n    execs = []\n    workers = []\n    coco_result = []","34":"Similar lines in 3 files\n==detection_test:49\n==mask_test:53\n==rpn_test:48\n    image_sets = pDataset.image_set\n    roidbs_all = [pkl.load(open(\"data\/cache\/{}.roidb\".format(i), \"rb\"), encoding=\"latin1\") for i in image_sets]\n    roidbs_all = reduce(lambda x, y: x + y, roidbs_all)\n\n    from pycocotools.coco import COCO\n    from pycocotools.cocoeval import COCOeval","35":"Similar lines in 2 files\n==detection_test:179\n==rpn_test:144\n            output_record = dict(\n                rec_id=rid,\n                im_id=id,\n                im_info=info,\n                bbox_xyxy=box,  # ndarray (n, class * 4) or (n, 4)"},"number":{"0":"C0121","1":"W0622","2":"R1732","3":"C0121","4":"R1732","5":"R1732","6":"C0121","7":"W0622","8":"R1732","9":"R1732","10":"C0121","11":"C0200","12":"W0622","13":"R1732","14":"R1732","15":"R0801","16":"R0801","17":"R0801","18":"R0801","19":"R0801","20":"R0801","21":"R0801","22":"R0801","23":"R0801","24":"R0801","25":"R0801","26":"R0801","27":"R0801","28":"R0801","29":"R0801","30":"R0801","31":"R0801","32":"R0801","33":"R0801","34":"R0801","35":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint"},"lines_amount":{"0":79,"1":310,"2":310,"3":310,"4":310,"5":312,"6":312,"7":351,"8":351,"9":351,"10":351,"11":351,"12":231,"13":231,"14":231,"15":231,"16":231,"17":231,"18":231,"19":231,"20":231,"21":231,"22":231,"23":231,"24":231,"25":231,"26":231,"27":231,"28":231,"29":231,"30":231,"31":231,"32":231,"33":231,"34":231,"35":231},"commit":{"0":"97413463f0bc3116f684eaf7031fd3dd6ded3149","1":"97413463f0bc3116f684eaf7031fd3dd6ded3149","2":"97413463f0bc3116f684eaf7031fd3dd6ded3149","3":"97413463f0bc3116f684eaf7031fd3dd6ded3149","4":"97413463f0bc3116f684eaf7031fd3dd6ded3149","5":"97413463f0bc3116f684eaf7031fd3dd6ded3149","6":"97413463f0bc3116f684eaf7031fd3dd6ded3149","7":"97413463f0bc3116f684eaf7031fd3dd6ded3149","8":"97413463f0bc3116f684eaf7031fd3dd6ded3149","9":"97413463f0bc3116f684eaf7031fd3dd6ded3149","10":"97413463f0bc3116f684eaf7031fd3dd6ded3149","11":"97413463f0bc3116f684eaf7031fd3dd6ded3149","12":"97413463f0bc3116f684eaf7031fd3dd6ded3149","13":"97413463f0bc3116f684eaf7031fd3dd6ded3149","14":"97413463f0bc3116f684eaf7031fd3dd6ded3149","15":"97413463f0bc3116f684eaf7031fd3dd6ded3149","16":"97413463f0bc3116f684eaf7031fd3dd6ded3149","17":"97413463f0bc3116f684eaf7031fd3dd6ded3149","18":"97413463f0bc3116f684eaf7031fd3dd6ded3149","19":"97413463f0bc3116f684eaf7031fd3dd6ded3149","20":"97413463f0bc3116f684eaf7031fd3dd6ded3149","21":"97413463f0bc3116f684eaf7031fd3dd6ded3149","22":"97413463f0bc3116f684eaf7031fd3dd6ded3149","23":"97413463f0bc3116f684eaf7031fd3dd6ded3149","24":"97413463f0bc3116f684eaf7031fd3dd6ded3149","25":"97413463f0bc3116f684eaf7031fd3dd6ded3149","26":"97413463f0bc3116f684eaf7031fd3dd6ded3149","27":"97413463f0bc3116f684eaf7031fd3dd6ded3149","28":"97413463f0bc3116f684eaf7031fd3dd6ded3149","29":"97413463f0bc3116f684eaf7031fd3dd6ded3149","30":"97413463f0bc3116f684eaf7031fd3dd6ded3149","31":"97413463f0bc3116f684eaf7031fd3dd6ded3149","32":"97413463f0bc3116f684eaf7031fd3dd6ded3149","33":"97413463f0bc3116f684eaf7031fd3dd6ded3149","34":"97413463f0bc3116f684eaf7031fd3dd6ded3149","35":"97413463f0bc3116f684eaf7031fd3dd6ded3149"},"repo":{"0":"TuSimple\/simpledet","1":"TuSimple\/simpledet","2":"TuSimple\/simpledet","3":"TuSimple\/simpledet","4":"TuSimple\/simpledet","5":"TuSimple\/simpledet","6":"TuSimple\/simpledet","7":"TuSimple\/simpledet","8":"TuSimple\/simpledet","9":"TuSimple\/simpledet","10":"TuSimple\/simpledet","11":"TuSimple\/simpledet","12":"TuSimple\/simpledet","13":"TuSimple\/simpledet","14":"TuSimple\/simpledet","15":"TuSimple\/simpledet","16":"TuSimple\/simpledet","17":"TuSimple\/simpledet","18":"TuSimple\/simpledet","19":"TuSimple\/simpledet","20":"TuSimple\/simpledet","21":"TuSimple\/simpledet","22":"TuSimple\/simpledet","23":"TuSimple\/simpledet","24":"TuSimple\/simpledet","25":"TuSimple\/simpledet","26":"TuSimple\/simpledet","27":"TuSimple\/simpledet","28":"TuSimple\/simpledet","29":"TuSimple\/simpledet","30":"TuSimple\/simpledet","31":"TuSimple\/simpledet","32":"TuSimple\/simpledet","33":"TuSimple\/simpledet","34":"TuSimple\/simpledet","35":"TuSimple\/simpledet"}}
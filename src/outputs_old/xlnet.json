{"type":{"0":"C","1":"W","2":"C","3":"C","4":"C","5":"W","6":"W","7":"W","8":"W","9":"W","10":"W","11":"W","12":"W","13":"W","14":"W","15":"W","16":"W","17":"R","18":"R","19":"W","20":"W","21":"R","22":"R","23":"R","24":"R","25":"R","26":"R","27":"R","28":"R","29":"R","30":"R","31":"R","32":"R","33":"R","34":"R","35":"R","36":"R","37":"R","38":"R","39":"R","40":"R","41":"R","42":"R","43":"R","44":"R","45":"R","46":"R","47":"R","48":"R","49":"R","50":"R","51":"R","52":"R","53":"R","54":"R","55":"R","56":"R","57":"R","58":"R","59":"R","60":"R","61":"R","62":"R","63":"R","64":"R","65":"R","66":"R"},"module":{"0":"model_utils","1":"model_utils","2":"run_race","3":"run_race","4":"run_squad","5":"tpu_estimator","6":"tpu_estimator","7":"tpu_estimator","8":"tpu_estimator","9":"tpu_estimator","10":"tpu_estimator","11":"tpu_estimator","12":"tpu_estimator","13":"tpu_estimator","14":"tpu_estimator","15":"tpu_estimator","16":"tpu_estimator","17":"tpu_estimator","18":"tpu_estimator","19":"tpu_estimator","20":"tpu_estimator","21":"xlnet","22":"xlnet","23":"xlnet","24":"xlnet","25":"xlnet","26":"xlnet","27":"xlnet","28":"xlnet","29":"xlnet","30":"xlnet","31":"xlnet","32":"xlnet","33":"xlnet","34":"xlnet","35":"xlnet","36":"xlnet","37":"xlnet","38":"xlnet","39":"xlnet","40":"xlnet","41":"xlnet","42":"xlnet","43":"xlnet","44":"xlnet","45":"xlnet","46":"xlnet","47":"xlnet","48":"xlnet","49":"xlnet","50":"xlnet","51":"xlnet","52":"xlnet","53":"xlnet","54":"xlnet","55":"xlnet","56":"xlnet","57":"xlnet","58":"xlnet","59":"xlnet","60":"xlnet","61":"xlnet","62":"xlnet","63":"xlnet","64":"xlnet","65":"xlnet","66":"xlnet"},"obj":{"0":"get_train_op","1":"AdamWeightDecayOptimizer.__init__","2":"convert_single_example","3":"get_examples","4":"_get_best_indexes","5":"TPUInfeedOutfeedSessionHook.begin","6":"TPUInfeedOutfeedSessionHook.begin","7":"TPUInfeedOutfeedSessionHook.begin","8":"TPUInfeedOutfeedSessionHook.begin","9":"TPUInfeedOutfeedSessionHook.after_create_session","10":"TPUInfeedOutfeedSessionHook.after_create_session","11":"_TPUStopAtStepHook.begin","12":"_TPUStopAtStepHook.begin","13":"_SetEvalIterationsHook.begin","14":"_StoppingPredictHook.begin","15":"_OutfeedHostCallHook.begin","16":"_OutfeedHostCallHook.begin","17":"TPUEstimator.train","18":"TPUEstimator.evaluate","19":"_CapturingContext.__enter__","20":"_CapturingContext.__enter__","21":"","22":"","23":"","24":"","25":"","26":"","27":"","28":"","29":"","30":"","31":"","32":"","33":"","34":"","35":"","36":"","37":"","38":"","39":"","40":"","41":"","42":"","43":"","44":"","45":"","46":"","47":"","48":"","49":"","50":"","51":"","52":"","53":"","54":"","55":"","56":"","57":"","58":"","59":"","60":"","61":"","62":"","63":"","64":"","65":"","66":""},"lnum":{"0":156,"1":298,"2":181,"3":258,"4":892,"5":448,"6":449,"7":451,"8":453,"9":519,"10":522,"11":617,"12":621,"13":656,"14":669,"15":1829,"16":1832,"17":2460,"18":2481,"19":3099,"20":3100,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"66":1},"col":{"0":4,"1":2,"2":2,"3":8,"4":2,"5":4,"6":4,"7":6,"8":6,"9":4,"10":4,"11":4,"12":4,"13":4,"14":4,"15":4,"16":4,"17":2,"18":2,"19":4,"20":4,"21":0,"22":0,"23":0,"24":0,"25":0,"26":0,"27":0,"28":0,"29":0,"30":0,"31":0,"32":0,"33":0,"34":0,"35":0,"36":0,"37":0,"38":0,"39":0,"40":0,"41":0,"42":0,"43":0,"44":0,"45":0,"46":0,"47":0,"48":0,"49":0,"50":0,"51":0,"52":0,"53":0,"54":0,"55":0,"56":0,"57":0,"58":0,"59":0,"60":0,"61":0,"62":0,"63":0,"64":0,"65":0,"66":0},"filename":{"0":"model_utils.py","1":"model_utils.py","2":"run_race.py","3":"run_race.py","4":"run_squad.py","5":"tpu_estimator.py","6":"tpu_estimator.py","7":"tpu_estimator.py","8":"tpu_estimator.py","9":"tpu_estimator.py","10":"tpu_estimator.py","11":"tpu_estimator.py","12":"tpu_estimator.py","13":"tpu_estimator.py","14":"tpu_estimator.py","15":"tpu_estimator.py","16":"tpu_estimator.py","17":"tpu_estimator.py","18":"tpu_estimator.py","19":"tpu_estimator.py","20":"tpu_estimator.py","21":"xlnet.py","22":"xlnet.py","23":"xlnet.py","24":"xlnet.py","25":"xlnet.py","26":"xlnet.py","27":"xlnet.py","28":"xlnet.py","29":"xlnet.py","30":"xlnet.py","31":"xlnet.py","32":"xlnet.py","33":"xlnet.py","34":"xlnet.py","35":"xlnet.py","36":"xlnet.py","37":"xlnet.py","38":"xlnet.py","39":"xlnet.py","40":"xlnet.py","41":"xlnet.py","42":"xlnet.py","43":"xlnet.py","44":"xlnet.py","45":"xlnet.py","46":"xlnet.py","47":"xlnet.py","48":"xlnet.py","49":"xlnet.py","50":"xlnet.py","51":"xlnet.py","52":"xlnet.py","53":"xlnet.py","54":"xlnet.py","55":"xlnet.py","56":"xlnet.py","57":"xlnet.py","58":"xlnet.py","59":"xlnet.py","60":"xlnet.py","61":"xlnet.py","62":"xlnet.py","63":"xlnet.py","64":"xlnet.py","65":"xlnet.py","66":"xlnet.py"},"symbol":{"0":"consider-using-enumerate","1":"dangerous-default-value","2":"consider-using-enumerate","3":"consider-using-enumerate","4":"consider-using-enumerate","5":"attribute-defined-outside-init","6":"attribute-defined-outside-init","7":"attribute-defined-outside-init","8":"attribute-defined-outside-init","9":"attribute-defined-outside-init","10":"attribute-defined-outside-init","11":"attribute-defined-outside-init","12":"attribute-defined-outside-init","13":"attribute-defined-outside-init","14":"attribute-defined-outside-init","15":"attribute-defined-outside-init","16":"attribute-defined-outside-init","17":"inconsistent-return-statements","18":"inconsistent-return-statements","19":"attribute-defined-outside-init","20":"attribute-defined-outside-init","21":"duplicate-code","22":"duplicate-code","23":"duplicate-code","24":"duplicate-code","25":"duplicate-code","26":"duplicate-code","27":"duplicate-code","28":"duplicate-code","29":"duplicate-code","30":"duplicate-code","31":"duplicate-code","32":"duplicate-code","33":"duplicate-code","34":"duplicate-code","35":"duplicate-code","36":"duplicate-code","37":"duplicate-code","38":"duplicate-code","39":"duplicate-code","40":"duplicate-code","41":"duplicate-code","42":"duplicate-code","43":"duplicate-code","44":"duplicate-code","45":"duplicate-code","46":"duplicate-code","47":"duplicate-code","48":"duplicate-code","49":"duplicate-code","50":"duplicate-code","51":"duplicate-code","52":"duplicate-code","53":"duplicate-code","54":"duplicate-code","55":"duplicate-code","56":"duplicate-code","57":"duplicate-code","58":"duplicate-code","59":"duplicate-code","60":"duplicate-code","61":"duplicate-code","62":"duplicate-code","63":"duplicate-code","64":"duplicate-code","65":"duplicate-code","66":"duplicate-code"},"text":{"0":"Consider using enumerate instead of iterating with range and len","1":"Dangerous default value [] as argument","2":"Consider using enumerate instead of iterating with range and len","3":"Consider using enumerate instead of iterating with range and len","4":"Consider using enumerate instead of iterating with range and len","5":"Attribute '_iterations_per_loop_var' defined outside __init__","6":"Attribute '_init_ops' defined outside __init__","7":"Attribute '_finalize_ops' defined outside __init__","8":"Attribute '_finalize_ops' defined outside __init__","9":"Attribute '_infeed_controller' defined outside __init__","10":"Attribute '_outfeed_controller' defined outside __init__","11":"Attribute '_global_step_tensor' defined outside __init__","12":"Attribute '_iterations_per_loop_var' defined outside __init__","13":"Attribute '_iterations_per_loop_var' defined outside __init__","14":"Attribute '_iterations_per_loop_var' defined outside __init__","15":"Attribute '_init_ops' defined outside __init__","16":"Attribute '_finalize_ops' defined outside __init__","17":"Either all return statements in a function should return an expression, or none of them should.","18":"Either all return statements in a function should return an expression, or none of them should.","19":"Attribute '_g' defined outside __init__","20":"Attribute '_old' defined outside __init__","21":"Similar lines in 2 files\n==train:98\n==train_gpu:85\nflags.DEFINE_integer(\"n_token\", 32000, help=\"Vocab size\")\n\n# Model config\nflags.DEFINE_integer(\"mem_len\", default=0,\n      help=\"Number of steps to cache\")\nflags.DEFINE_bool(\"same_length\", default=False,\n      help=\"Same length attention\")\nflags.DEFINE_integer(\"clamp_len\", default=-1,\n      help=\"Clamp length\")\n\nflags.DEFINE_integer(\"n_layer\", default=6,\n      help=\"Number of layers.\")\nflags.DEFINE_integer(\"d_model\", default=32,\n      help=\"Dimension of the model.\")\nflags.DEFINE_integer(\"d_embed\", default=32,\n      help=\"Dimension of the embeddings.\")\nflags.DEFINE_integer(\"n_head\", default=4,\n      help=\"Number of attention heads.\")\nflags.DEFINE_integer(\"d_head\", default=8,\n      help=\"Dimension of each attention head.\")\nflags.DEFINE_integer(\"d_inner\", default=32,\n      help=\"Dimension of inner hidden size in positionwise feed-forward.\")\nflags.DEFINE_float(\"dropout\", default=0.0,\n      help=\"Dropout rate.\")\nflags.DEFINE_float(\"dropatt\", default=0.0,\n      help=\"Attention dropout rate.\")\nflags.DEFINE_bool(\"untie_r\", default=False,\n      help=\"Untie r_w_bias and r_r_bias\")\nflags.DEFINE_string(\"summary_type\", default=\"last\",\n      help=\"Method used to summarize a sequence into a compact vector.\")\nflags.DEFINE_string(\"ff_activation\", default=\"relu\",\n      help=\"Activation type used in position-wise feed-forward.\")\nflags.DEFINE_bool(\"use_bfloat16\", False,\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n      enum_values=[\"normal\", \"uniform\"],\n      help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n      help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n      help=\"Initialization std when init is uniform.\")\n","22":"Similar lines in 2 files\n==run_classifier:45\n==run_race:46\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n      enum_values=[\"normal\", \"uniform\"],\n      help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n      help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n      help=\"Initialization std when init is uniform.\")\n\n# I\/O paths\nflags.DEFINE_bool(\"overwrite_data\", default=False,\n      help=\"If False, will use cached data if available.\")\nflags.DEFINE_string(\"init_checkpoint\", default=None,\n      help=\"checkpoint path for initializing the model. \"\n      \"Could be a pretrained model or a finetuned model.\")\nflags.DEFINE_string(\"output_dir\", default=\"\",\n      help=\"Output dir for TF records.\")\nflags.DEFINE_string(\"spiece_model_file\", default=\"\",\n      help=\"Sentence Piece model path.\")\nflags.DEFINE_string(\"model_dir\", default=\"\",\n      help=\"Directory for saving the finetuned model.\")\nflags.DEFINE_string(\"data_dir\", default=\"\",\n      help=\"Directory for input data.\")\n\n# TPUs and machines\nflags.DEFINE_bool(\"use_tpu\", default=False, help=\"whether to use TPU.\")\nflags.DEFINE_integer(\"num_hosts\", default=1, help=\"How many TPU hosts.\")\nflags.DEFINE_integer(\"num_core_per_host\", default=8,\n      help=\"8 for TPU v2 and v3-8, 16 for larger TPU v3 pod. In the context \"\n      \"of GPU training, it refers to the number of GPUs used.\")\nflags.DEFINE_string(\"tpu_job_name\", default=None, help=\"TPU worker job name.\")\nflags.DEFINE_string(\"tpu\", default=None, help=\"TPU name.\")\nflags.DEFINE_string(\"tpu_zone\", default=None, help=\"TPU zone.\")\nflags.DEFINE_string(\"gcp_project\", default=None, help=\"gcp project.\")\nflags.DEFINE_string(\"master\", default=None, help=\"master\")\nflags.DEFINE_integer(\"iterations\", default=1000,\n      help=\"number of iterations per TPU training loop.\")\n\n# Training\nflags.DEFINE_bool(\"do_train\", default=False, help=\"whether to do training\")","23":"Similar lines in 2 files\n==classifier_utils:16\n==run_race:140\nclass PaddingInputExample(object):\n  \"\"\"Fake example so the num input examples is a multiple of the batch size.\n  When running eval\/predict on the TPU, we need to pad the number of examples\n  to be a multiple of the batch size, because the TPU requires a fixed batch\n  size. The alternative is to drop the last batch, which is bad because it means\n  the entire output data won't be generated.\n  We use this class instead of `None` because treating `None` as padding\n  battches could cause silent errors.\n  \"\"\"\n\n\nclass InputFeatures(object):\n  \"\"\"A single set of features of data.\"\"\"\n\n  def __init__(self,\n               input_ids,\n               input_mask,\n               segment_ids,\n               label_id,\n               is_real_example=True):\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example\n\n","24":"Similar lines in 2 files\n==run_classifier:525\n==run_race:376\n    num_params = sum([np.prod(v.shape) for v in tf.trainable_variables()])\n    tf.logging.info('#params: {}'.format(num_params))\n\n    #### load pretrained models\n    scaffold_fn = model_utils.init_from_checkpoint(FLAGS)\n\n    #### Evaluation mode\n    if mode == tf.estimator.ModeKeys.EVAL:\n      assert FLAGS.num_hosts == 1\n\n      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n        eval_input_dict = {\n            'labels': label_ids,\n            'predictions': predictions,\n            'weights': is_real_example\n        }\n        accuracy = tf.metrics.accuracy(**eval_input_dict)\n\n        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n        return {\n            'eval_accuracy': accuracy,\n            'eval_loss': loss}\n","25":"Similar lines in 2 files\n==run_classifier:621\n==run_race:430\n        host_call = None\n\n      train_spec = tf.contrib.tpu.TPUEstimatorSpec(\n          mode=mode, loss=total_loss, train_op=train_op, host_call=host_call,\n          scaffold_fn=scaffold_fn)\n    else:\n      train_spec = tf.estimator.EstimatorSpec(\n          mode=mode, loss=total_loss, train_op=train_op)\n\n    return train_spec\n\n  return model_fn\n\n\ndef main(_):\n  tf.logging.set_verbosity(tf.logging.INFO)\n\n  #### Validate flags\n  if FLAGS.save_steps is not None:\n    FLAGS.iterations = min(FLAGS.iterations, FLAGS.save_steps)\n","26":"Similar lines in 2 files\n==run_race:325\n==run_squad:944\n  def _decode_record(record, name_to_features):\n    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n      t = example[name]\n      if t.dtype == tf.int64:\n        t = tf.cast(t, tf.int32)\n      example[name] = t\n\n    return example\n\n  def input_fn(params):\n    \"\"\"The actual input function.\"\"\"\n    if FLAGS.use_tpu:\n      batch_size = params[\"batch_size\"]\n    elif is_training:\n      batch_size = FLAGS.train_batch_size","27":"Similar lines in 2 files\n==run_race:45\n==run_squad:58\nflags.DEFINE_bool(\"use_bfloat16\", default=False,\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n                  enum_values=[\"normal\", \"uniform\"],\n                  help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n                   help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n                   help=\"Initialization std when init is uniform.\")\n\n# I\/O paths\nflags.DEFINE_bool(\"overwrite_data\", default=False,\n                  help=\"If False, will use cached data if available.\")\nflags.DEFINE_string(\"init_checkpoint\", default=None,\n                    help=\"checkpoint path for initializing the model. \"\n                    \"Could be a pretrained model or a finetuned model.\")","28":"Similar lines in 2 files\n==run_classifier:45\n==run_squad:59\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n                  enum_values=[\"normal\", \"uniform\"],\n                  help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n                   help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n                   help=\"Initialization std when init is uniform.\")\n\n# I\/O paths\nflags.DEFINE_bool(\"overwrite_data\", default=False,\n                  help=\"If False, will use cached data if available.\")\nflags.DEFINE_string(\"init_checkpoint\", default=None,\n                    help=\"checkpoint path for initializing the model. \"\n                    \"Could be a pretrained model or a finetuned model.\")","29":"Similar lines in 2 files\n==run_classifier:565\n==run_race:404\n      metric_args = [per_example_loss, label_ids, logits, is_real_example]\n\n      if FLAGS.use_tpu:\n        eval_spec = tf.contrib.tpu.TPUEstimatorSpec(\n            mode=mode,\n            loss=total_loss,\n            eval_metrics=(metric_fn, metric_args),\n            scaffold_fn=scaffold_fn)\n      else:\n        eval_spec = tf.estimator.EstimatorSpec(\n            mode=mode,\n            loss=total_loss,\n            eval_metric_ops=metric_fn(*metric_args))\n\n      return eval_spec\n","30":"Similar lines in 2 files\n==run_classifier:458\n==run_race:323\n  tf.logging.info(\"Input tfrecord file {}\".format(input_file))\n\n  def _decode_record(record, name_to_features):\n    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n      t = example[name]\n      if t.dtype == tf.int64:\n        t = tf.cast(t, tf.int32)\n      example[name] = t\n\n    return example\n","31":"Similar lines in 2 files\n==run_classifier:460\n==run_squad:944\n  def _decode_record(record, name_to_features):\n    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n      t = example[name]\n      if t.dtype == tf.int64:\n        t = tf.cast(t, tf.int32)\n      example[name] = t\n\n    return example\n","32":"Similar lines in 3 files\n==run_classifier:72\n==run_race:73\n==run_squad:104\nflags.DEFINE_bool(\"use_tpu\", default=False, help=\"whether to use TPU.\")\nflags.DEFINE_integer(\"num_hosts\", default=1, help=\"How many TPU hosts.\")\nflags.DEFINE_integer(\"num_core_per_host\", default=8,\n      help=\"8 for TPU v2 and v3-8, 16 for larger TPU v3 pod. In the context \"\n      \"of GPU training, it refers to the number of GPUs used.\")\nflags.DEFINE_string(\"tpu_job_name\", default=None, help=\"TPU worker job name.\")\nflags.DEFINE_string(\"tpu\", default=None, help=\"TPU name.\")\nflags.DEFINE_string(\"tpu_zone\", default=None, help=\"TPU zone.\")\nflags.DEFINE_string(\"gcp_project\", default=None, help=\"gcp project.\")\nflags.DEFINE_string(\"master\", default=None, help=\"master\")\nflags.DEFINE_integer(\"iterations\", default=1000,\n                     help=\"number of iterations per TPU training loop.\")\n\n# Training","33":"Similar lines in 2 files\n==run_classifier:44\n==train_gpu:117\nflags.DEFINE_bool(\"use_bfloat16\", False,\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n      enum_values=[\"normal\", \"uniform\"],\n      help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n      help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n      help=\"Initialization std when init is uniform.\")\n\n","34":"Similar lines in 3 files\n==run_race:46\n==run_squad:59\n==train_gpu:118\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n                  enum_values=[\"normal\", \"uniform\"],\n                  help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n                   help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n                   help=\"Initialization std when init is uniform.\")\n\n# I\/O paths","35":"Similar lines in 2 files\n==run_classifier:44\n==train:130\nflags.DEFINE_bool(\"use_bfloat16\", False,\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n      enum_values=[\"normal\", \"uniform\"],\n      help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n      help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n      help=\"Initialization std when init is uniform.\")\n","36":"Similar lines in 3 files\n==run_classifier:623\n==run_race:432\n==run_squad:1099\n      train_spec = tf.contrib.tpu.TPUEstimatorSpec(\n          mode=mode, loss=total_loss, train_op=train_op, host_call=host_call,\n          scaffold_fn=scaffold_fn)\n    else:\n      train_spec = tf.estimator.EstimatorSpec(\n          mode=mode, loss=total_loss, train_op=train_op)\n\n    return train_spec\n\n  return model_fn\n\n","37":"Similar lines in 2 files\n==run_classifier:435\n==run_race:303\n    features[\"is_real_example\"] = create_int_feature(\n        [int(feature.is_real_example)])\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n    writer.write(tf_example.SerializeToString())\n  writer.close()\n\n\ndef file_based_input_fn_builder(input_file, seq_length, is_training,\n                                drop_remainder):\n  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n","38":"Similar lines in 2 files\n==run_classifier:419\n==run_race:290\n    def create_int_feature(values):\n      f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n      return f\n\n    def create_float_feature(values):\n      f = tf.train.Feature(float_list=tf.train.FloatList(value=list(values)))\n      return f\n\n    features = collections.OrderedDict()\n    features[\"input_ids\"] = create_int_feature(feature.input_ids)\n    features[\"input_mask\"] = create_float_feature(feature.input_mask)\n    features[\"segment_ids\"] = create_int_feature(feature.segment_ids)","39":"Similar lines in 2 files\n==run_classifier:91\n==run_race:92\nflags.DEFINE_float(\"lr_layer_decay_rate\", 1.0,\n                   \"Top layer: lr[L] = FLAGS.learning_rate.\"\n                   \"Low layer: lr[l-1] = lr[l] * lr_layer_decay_rate.\")\nflags.DEFINE_float(\"min_lr_ratio\", default=0.0,\n      help=\"min lr ratio for cos decay.\")\nflags.DEFINE_float(\"clip\", default=1.0, help=\"Gradient clipping\")\nflags.DEFINE_integer(\"max_save\", default=0,\n      help=\"Max number of checkpoints to save. Use 0 to save all.\")\nflags.DEFINE_integer(\"save_steps\", default=None,\n      help=\"Save the model for every save_steps. \"\n      \"If None, not to save any model.\")\nflags.DEFINE_integer(\"train_batch_size\", default=8,","40":"Similar lines in 2 files\n==run_classifier:32\n==run_race:33\nflags.DEFINE_string(\"model_config_path\", default=None,\n      help=\"Model config path.\")\nflags.DEFINE_float(\"dropout\", default=0.1,\n      help=\"Dropout rate.\")\nflags.DEFINE_float(\"dropatt\", default=0.1,\n      help=\"Attention dropout rate.\")\nflags.DEFINE_integer(\"clamp_len\", default=-1,\n      help=\"Clamp length\")\nflags.DEFINE_string(\"summary_type\", default=\"last\",\n      help=\"Method used to summarize a sequence into a compact vector.\")\nflags.DEFINE_bool(\"use_summ_proj\", default=True,\n      help=\"Whether to use projection for summarizing sequences.\")","41":"Similar lines in 3 files\n==run_race:46\n==run_squad:59\n==train:131\n      help=\"Whether to use bfloat16.\")\n\n# Parameter initialization\nflags.DEFINE_enum(\"init\", default=\"normal\",\n                  enum_values=[\"normal\", \"uniform\"],\n                  help=\"Initialization method.\")\nflags.DEFINE_float(\"init_std\", default=0.02,\n                   help=\"Initialization std when init is normal.\")\nflags.DEFINE_float(\"init_range\", default=0.1,\n                   help=\"Initialization std when init is uniform.\")\n","42":"Similar lines in 2 files\n==run_classifier:588\n==run_squad:1045\n      }\n\n      if FLAGS.use_tpu:\n        output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n            mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n      else:\n        output_spec = tf.estimator.EstimatorSpec(\n            mode=mode, predictions=predictions)\n      return output_spec\n\n    #### Configuring the optimizer","43":"Similar lines in 2 files\n==run_classifier:499\n==run_race:356\n    d = d.apply(\n        tf.contrib.data.map_and_batch(\n            lambda record: _decode_record(record, name_to_features),\n            batch_size=batch_size,\n            drop_remainder=drop_remainder))\n\n    return d\n\n  return input_fn\n\n","44":"Similar lines in 2 files\n==train:51\n==train_gpu:41\nflags.DEFINE_float(\"learning_rate\", default=1e-4,\n      help=\"Maximum learning rate.\")\nflags.DEFINE_float(\"clip\", default=1.0,\n      help=\"Gradient clipping value.\")\n# lr decay\nflags.DEFINE_float(\"min_lr_ratio\", default=0.001,\n      help=\"Minimum ratio learning rate.\")\nflags.DEFINE_integer(\"warmup_steps\", default=0,\n      help=\"Number of steps for linear lr warmup.\")\nflags.DEFINE_float(\"adam_epsilon\", default=1e-8,","45":"Similar lines in 2 files\n==run_race:362\n==run_squad:1014\n    return d\n\n  return input_fn\n\n\ndef get_model_fn():\n  def model_fn(features, labels, mode, params):\n    #### Training or Evaluation\n    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","46":"Similar lines in 2 files\n==run_classifier:692\n==run_race:479\n        eval_batch_size=FLAGS.eval_batch_size)\n  else:\n    estimator = tf.estimator.Estimator(\n        model_fn=model_fn,\n        config=run_config)\n\n  if FLAGS.do_train:\n    train_file_base = \"{}.len-{}.train.tf_record\".format(\n        spm_basename, FLAGS.max_seq_length)\n    train_file = os.path.join(FLAGS.output_dir, train_file_base)","47":"Similar lines in 2 files\n==run_classifier:681\n==run_race:469\n  spm_basename = os.path.basename(FLAGS.spiece_model_file)\n\n  # If TPU is not available, this will fall back to normal Estimator on CPU\n  # or GPU.\n  if FLAGS.use_tpu:\n    estimator = tf.contrib.tpu.TPUEstimator(\n        use_tpu=FLAGS.use_tpu,\n        model_fn=model_fn,\n        config=run_config,\n        train_batch_size=FLAGS.train_batch_size,","48":"Similar lines in 2 files\n==run_classifier:21\n==run_race:23\nimport sentencepiece as spm\n\nfrom data_utils import SEP_ID, VOCAB_SIZE, CLS_ID\nimport model_utils\nimport function_builder\nfrom classifier_utils import PaddingInputExample\nfrom classifier_utils import convert_single_example\nfrom prepro_utils import preprocess_text, encode_ids\n\n# Model","49":"Similar lines in 2 files\n==run_classifier:8\n==run_race:7\nimport csv\nimport collections\nimport numpy as np\nimport time\nimport math\nimport json\nimport random\nfrom copy import copy\nfrom collections import defaultdict as dd\n","50":"Similar lines in 2 files\n==run_classifier:747\n==run_race:530\n    assert len(eval_examples) % FLAGS.eval_batch_size == 0\n    eval_steps = int(len(eval_examples) \/\/ FLAGS.eval_batch_size)\n\n    eval_input_fn = file_based_input_fn_builder(\n        input_file=eval_file,\n        seq_length=FLAGS.max_seq_length,\n        is_training=False,\n        drop_remainder=True)\n","51":"Similar lines in 2 files\n==train:234\n==train_gpu:194\n      perm_size=FLAGS.perm_size,\n      mask_alpha=FLAGS.mask_alpha,\n      mask_beta=FLAGS.mask_beta,\n      uncased=FLAGS.uncased,\n      num_passes=FLAGS.num_passes,\n      use_bfloat16=FLAGS.use_bfloat16,\n      num_predict=FLAGS.num_predict)\n","52":"Similar lines in 2 files\n==train:90\n==train_gpu:73\nflags.DEFINE_bool(\"bi_data\", default=True,\n      help=\"Use bidirectional data streams, i.e., forward & backward.\")\nflags.DEFINE_integer(\"mask_alpha\", default=6,\n      help=\"How many tokens to form a group.\")\nflags.DEFINE_integer(\"mask_beta\", default=1,\n      help=\"How many tokens to mask within each group.\")\nflags.DEFINE_integer(\"num_predict\", default=None,\n      help=\"Number of tokens to predict in partial prediction.\")","53":"Similar lines in 2 files\n==run_race:546\n==run_squad:1302\n    for key, val in ret.items():\n      log_str += \"{} {} | \".format(key, val)\n    tf.logging.info(log_str)\n    tf.logging.info(\"=\" * 80)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()","54":"Similar lines in 2 files\n==classifier_utils:8\n==run_race:131\nFLAGS = flags.FLAGS\n\nSEG_ID_A   = 0\nSEG_ID_B   = 1\nSEG_ID_CLS = 2\nSEG_ID_SEP = 3\nSEG_ID_PAD = 4\n","55":"Similar lines in 2 files\n==train:41\n==train_gpu:31\nflags.DEFINE_integer(\"num_passes\", default=1,\n      help=\"Number of passed used for training.\")\nflags.DEFINE_string(\"record_info_dir\", default=None,\n      help=\"Path to local directory containing `record_info-lm.json`.\")\nflags.DEFINE_string(\"model_dir\", default=None,\n      help=\"Estimator model_dir.\")\nflags.DEFINE_string(\"init_checkpoint\", default=None,","56":"Similar lines in 3 files\n==run_classifier:32\n==run_race:33\n==run_squad:48\nflags.DEFINE_string(\"model_config_path\", default=None,\n      help=\"Model config path.\")\nflags.DEFINE_float(\"dropout\", default=0.1,\n      help=\"Dropout rate.\")\nflags.DEFINE_float(\"dropatt\", default=0.1,\n      help=\"Attention dropout rate.\")\nflags.DEFINE_integer(\"clamp_len\", default=-1,","57":"Similar lines in 2 files\n==run_classifier:0\n==run_race:0\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom os.path import join\nfrom absl import flags\nimport os","58":"Similar lines in 2 files\n==run_squad:1093\n==train:182\n    host_call = function_builder.construct_scalar_host_call(\n        monitor_dict=monitor_dict,\n        model_dir=FLAGS.model_dir,\n        prefix=\"train\/\",\n        reduce_fn=tf.reduce_mean)\n","59":"Similar lines in 3 files\n==run_classifier:693\n==run_race:480\n==run_squad:1189\n  else:\n    estimator = tf.estimator.Estimator(\n        model_fn=model_fn,\n        config=run_config)\n\n  if FLAGS.do_train:","60":"Similar lines in 3 files\n==run_classifier:685\n==run_race:473\n==run_squad:1182\n  if FLAGS.use_tpu:\n    estimator = tf.contrib.tpu.TPUEstimator(\n        use_tpu=FLAGS.use_tpu,\n        model_fn=model_fn,\n        config=run_config,\n        train_batch_size=FLAGS.train_batch_size,","61":"Similar lines in 2 files\n==run_classifier:671\n==run_race:458\n  sp = spm.SentencePieceProcessor()\n  sp.Load(FLAGS.spiece_model_file)\n  def tokenize_fn(text):\n    text = preprocess_text(text, lower=FLAGS.uncased)\n    return encode_ids(sp, text)\n","62":"Similar lines in 2 files\n==run_classifier:476\n==run_race:341\n    if FLAGS.use_tpu:\n      batch_size = params[\"batch_size\"]\n    elif is_training:\n      batch_size = FLAGS.train_batch_size\n    elif FLAGS.do_eval:\n      batch_size = FLAGS.eval_batch_size","63":"Similar lines in 2 files\n==data_utils:2\n==xlnet:0\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os","64":"Similar lines in 2 files\n==train:70\n==train_gpu:60\nflags.DEFINE_integer(\"train_steps\", default=100000,\n      help=\"Total number of training steps.\")\nflags.DEFINE_integer(\"iterations\", default=1000,\n      help=\"Number of iterations per repeat loop.\")\nflags.DEFINE_integer(\"save_steps\", default=None,","65":"Similar lines in 3 files\n==run_classifier:615\n==run_squad:1093\n==train:182\n    host_call = function_builder.construct_scalar_host_call(\n        monitor_dict=monitor_dict,\n        model_dir=FLAGS.model_dir,\n        prefix=\"train\/\",\n        reduce_fn=tf.reduce_mean)","66":"Similar lines in 2 files\n==run_classifier:712\n==run_race:496\n    train_input_fn = file_based_input_fn_builder(\n        input_file=train_file,\n        seq_length=FLAGS.max_seq_length,\n        is_training=True,\n        drop_remainder=True)"},"number":{"0":"C0200","1":"W0102","2":"C0200","3":"C0200","4":"C0200","5":"W0201","6":"W0201","7":"W0201","8":"W0201","9":"W0201","10":"W0201","11":"W0201","12":"W0201","13":"W0201","14":"W0201","15":"W0201","16":"W0201","17":"R1710","18":"R1710","19":"W0201","20":"W0201","21":"R0801","22":"R0801","23":"R0801","24":"R0801","25":"R0801","26":"R0801","27":"R0801","28":"R0801","29":"R0801","30":"R0801","31":"R0801","32":"R0801","33":"R0801","34":"R0801","35":"R0801","36":"R0801","37":"R0801","38":"R0801","39":"R0801","40":"R0801","41":"R0801","42":"R0801","43":"R0801","44":"R0801","45":"R0801","46":"R0801","47":"R0801","48":"R0801","49":"R0801","50":"R0801","51":"R0801","52":"R0801","53":"R0801","54":"R0801","55":"R0801","56":"R0801","57":"R0801","58":"R0801","59":"R0801","60":"R0801","61":"R0801","62":"R0801","63":"R0801","64":"R0801","65":"R0801","66":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint","36":"pylint","37":"pylint","38":"pylint","39":"pylint","40":"pylint","41":"pylint","42":"pylint","43":"pylint","44":"pylint","45":"pylint","46":"pylint","47":"pylint","48":"pylint","49":"pylint","50":"pylint","51":"pylint","52":"pylint","53":"pylint","54":"pylint","55":"pylint","56":"pylint","57":"pylint","58":"pylint","59":"pylint","60":"pylint","61":"pylint","62":"pylint","63":"pylint","64":"pylint","65":"pylint","66":"pylint"},"lines_amount":{"0":400,"1":400,"2":555,"3":555,"4":1311,"5":3523,"6":3523,"7":3523,"8":3523,"9":3523,"10":3523,"11":3523,"12":3523,"13":3523,"14":3523,"15":3523,"16":3523,"17":3523,"18":3523,"19":3523,"20":3523,"21":293,"22":293,"23":293,"24":293,"25":293,"26":293,"27":293,"28":293,"29":293,"30":293,"31":293,"32":293,"33":293,"34":293,"35":293,"36":293,"37":293,"38":293,"39":293,"40":293,"41":293,"42":293,"43":293,"44":293,"45":293,"46":293,"47":293,"48":293,"49":293,"50":293,"51":293,"52":293,"53":293,"54":293,"55":293,"56":293,"57":293,"58":293,"59":293,"60":293,"61":293,"62":293,"63":293,"64":293,"65":293,"66":293},"commit":{"0":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","1":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","2":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","3":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","4":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","5":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","6":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","7":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","8":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","9":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","10":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","11":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","12":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","13":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","14":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","15":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","16":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","17":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","18":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","19":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","20":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","21":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","22":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","23":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","24":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","25":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","26":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","27":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","28":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","29":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","30":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","31":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","32":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","33":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","34":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","35":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","36":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","37":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","38":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","39":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","40":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","41":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","42":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","43":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","44":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","45":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","46":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","47":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","48":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","49":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","50":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","51":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","52":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","53":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","54":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","55":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","56":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","57":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","58":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","59":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","60":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","61":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","62":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","63":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","64":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","65":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660","66":"bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660"},"repo":{"0":"zihangdai\/xlnet","1":"zihangdai\/xlnet","2":"zihangdai\/xlnet","3":"zihangdai\/xlnet","4":"zihangdai\/xlnet","5":"zihangdai\/xlnet","6":"zihangdai\/xlnet","7":"zihangdai\/xlnet","8":"zihangdai\/xlnet","9":"zihangdai\/xlnet","10":"zihangdai\/xlnet","11":"zihangdai\/xlnet","12":"zihangdai\/xlnet","13":"zihangdai\/xlnet","14":"zihangdai\/xlnet","15":"zihangdai\/xlnet","16":"zihangdai\/xlnet","17":"zihangdai\/xlnet","18":"zihangdai\/xlnet","19":"zihangdai\/xlnet","20":"zihangdai\/xlnet","21":"zihangdai\/xlnet","22":"zihangdai\/xlnet","23":"zihangdai\/xlnet","24":"zihangdai\/xlnet","25":"zihangdai\/xlnet","26":"zihangdai\/xlnet","27":"zihangdai\/xlnet","28":"zihangdai\/xlnet","29":"zihangdai\/xlnet","30":"zihangdai\/xlnet","31":"zihangdai\/xlnet","32":"zihangdai\/xlnet","33":"zihangdai\/xlnet","34":"zihangdai\/xlnet","35":"zihangdai\/xlnet","36":"zihangdai\/xlnet","37":"zihangdai\/xlnet","38":"zihangdai\/xlnet","39":"zihangdai\/xlnet","40":"zihangdai\/xlnet","41":"zihangdai\/xlnet","42":"zihangdai\/xlnet","43":"zihangdai\/xlnet","44":"zihangdai\/xlnet","45":"zihangdai\/xlnet","46":"zihangdai\/xlnet","47":"zihangdai\/xlnet","48":"zihangdai\/xlnet","49":"zihangdai\/xlnet","50":"zihangdai\/xlnet","51":"zihangdai\/xlnet","52":"zihangdai\/xlnet","53":"zihangdai\/xlnet","54":"zihangdai\/xlnet","55":"zihangdai\/xlnet","56":"zihangdai\/xlnet","57":"zihangdai\/xlnet","58":"zihangdai\/xlnet","59":"zihangdai\/xlnet","60":"zihangdai\/xlnet","61":"zihangdai\/xlnet","62":"zihangdai\/xlnet","63":"zihangdai\/xlnet","64":"zihangdai\/xlnet","65":"zihangdai\/xlnet","66":"zihangdai\/xlnet"}}
{"type":{"0":"C","1":"R","2":"R","3":"R","4":"W","5":"W","6":"W","7":"W","8":"C","9":"R","10":"R","11":"R","12":"W","13":"W","14":"W","15":"W","16":"W","17":"W","18":"W","19":"R","20":"C","21":"R","22":"C","23":"C","24":"C","25":"W","26":"W","27":"W","28":"R","29":"C","30":"R","31":"C","32":"C","33":"C","34":"W","35":"W","36":"W","37":"R","38":"C","39":"R","40":"C","41":"C","42":"C","43":"W","44":"W","45":"W","46":"R","47":"C","48":"R","49":"C","50":"C","51":"C","52":"W","53":"W","54":"W","55":"W","56":"R","57":"C","58":"R","59":"C","60":"C","61":"C","62":"W","63":"W","64":"W","65":"R","66":"C","67":"R","68":"C","69":"C","70":"C","71":"W","72":"W","73":"W","74":"R","75":"C","76":"R","77":"C","78":"C","79":"C","80":"W","81":"W","82":"W","83":"R","84":"C","85":"R","86":"C","87":"C","88":"C","89":"W","90":"W","91":"W","92":"W","93":"R","94":"C","95":"R","96":"C","97":"C","98":"C","99":"W","100":"W","101":"W","102":"W","103":"R","104":"W","105":"W","106":"W","107":"R","108":"W","109":"R","110":"R","111":"R","112":"R","113":"R","114":"R","115":"R","116":"R","117":"R","118":"R","119":"R","120":"R","121":"R","122":"R","123":"R","124":"R","125":"R","126":"R","127":"R","128":"R","129":"R","130":"R","131":"R","132":"R","133":"R","134":"R","135":"R","136":"R","137":"R","138":"R","139":"R","140":"R","141":"R","142":"R","143":"R","144":"R","145":"R","146":"R","147":"R","148":"R","149":"R","150":"R","151":"R","152":"R","153":"R","154":"R","155":"R","156":"R","157":"R","158":"R","159":"R","160":"R","161":"R","162":"R","163":"R","164":"R","165":"R","166":"R","167":"R","168":"R","169":"R","170":"R","171":"R","172":"R","173":"R","174":"R","175":"R","176":"R","177":"R","178":"R","179":"R","180":"R","181":"R","182":"R","183":"R","184":"R","185":"R","186":"R","187":"R","188":"R","189":"R","190":"R","191":"R","192":"R","193":"R","194":"R","195":"R","196":"R","197":"R","198":"R","199":"R"},"module":{"0":"LanguageModel","1":"LanguageModel","2":"LanguageModel","3":"LanguageModel","4":"LanguageModel","5":"LanguageModel","6":"LanguageModel","7":"LanguageModel","8":"LanguageModel2","9":"LanguageModel2","10":"LanguageModel2","11":"LanguageModel2","12":"LanguageModel2","13":"LanguageModel2","14":"LanguageModel2","15":"LanguageModel2","16":"SpeechModel24","17":"SpeechModel24","18":"SpeechModel24","19":"SpeechModel24","20":"SpeechModel24","21":"SpeechModel24","22":"SpeechModel24","23":"SpeechModel24","24":"SpeechModel24","25":"SpeechModel25","26":"SpeechModel25","27":"SpeechModel25","28":"SpeechModel25","29":"SpeechModel25","30":"SpeechModel25","31":"SpeechModel25","32":"SpeechModel25","33":"SpeechModel25","34":"SpeechModel251","35":"SpeechModel251","36":"SpeechModel251","37":"SpeechModel251","38":"SpeechModel251","39":"SpeechModel251","40":"SpeechModel251","41":"SpeechModel251","42":"SpeechModel251","43":"SpeechModel251_limitless","44":"SpeechModel251_limitless","45":"SpeechModel251_limitless","46":"SpeechModel251_limitless","47":"SpeechModel251_limitless","48":"SpeechModel251_limitless","49":"SpeechModel251_limitless","50":"SpeechModel251_limitless","51":"SpeechModel251_limitless","52":"SpeechModel251_p","53":"SpeechModel251_p","54":"SpeechModel251_p","55":"SpeechModel251_p","56":"SpeechModel251_p","57":"SpeechModel251_p","58":"SpeechModel251_p","59":"SpeechModel251_p","60":"SpeechModel251_p","61":"SpeechModel251_p","62":"SpeechModel252","63":"SpeechModel252","64":"SpeechModel252","65":"SpeechModel252","66":"SpeechModel252","67":"SpeechModel252","68":"SpeechModel252","69":"SpeechModel252","70":"SpeechModel252","71":"SpeechModel26","72":"SpeechModel26","73":"SpeechModel26","74":"SpeechModel26","75":"SpeechModel26","76":"SpeechModel26","77":"SpeechModel26","78":"SpeechModel26","79":"SpeechModel26","80":"SpeechModel261","81":"SpeechModel261","82":"SpeechModel261","83":"SpeechModel261","84":"SpeechModel261","85":"SpeechModel261","86":"SpeechModel261","87":"SpeechModel261","88":"SpeechModel261","89":"SpeechModel261_p","90":"SpeechModel261_p","91":"SpeechModel261_p","92":"SpeechModel261_p","93":"SpeechModel261_p","94":"SpeechModel261_p","95":"SpeechModel261_p","96":"SpeechModel261_p","97":"SpeechModel261_p","98":"SpeechModel261_p","99":"asrserver","100":"readdata24","101":"readdata24","102":"readdata24","103":"readdata24","104":"readdata24_limitless","105":"readdata24_limitless","106":"readdata24_limitless","107":"readdata24_limitless","108":"testClient","109":"train_mspeech","110":"train_mspeech","111":"train_mspeech","112":"train_mspeech","113":"train_mspeech","114":"train_mspeech","115":"train_mspeech","116":"train_mspeech","117":"train_mspeech","118":"train_mspeech","119":"train_mspeech","120":"train_mspeech","121":"train_mspeech","122":"train_mspeech","123":"train_mspeech","124":"train_mspeech","125":"train_mspeech","126":"train_mspeech","127":"train_mspeech","128":"train_mspeech","129":"train_mspeech","130":"train_mspeech","131":"train_mspeech","132":"train_mspeech","133":"train_mspeech","134":"train_mspeech","135":"train_mspeech","136":"train_mspeech","137":"train_mspeech","138":"train_mspeech","139":"train_mspeech","140":"train_mspeech","141":"train_mspeech","142":"train_mspeech","143":"train_mspeech","144":"train_mspeech","145":"train_mspeech","146":"train_mspeech","147":"train_mspeech","148":"train_mspeech","149":"train_mspeech","150":"train_mspeech","151":"train_mspeech","152":"train_mspeech","153":"train_mspeech","154":"train_mspeech","155":"train_mspeech","156":"train_mspeech","157":"train_mspeech","158":"train_mspeech","159":"train_mspeech","160":"train_mspeech","161":"train_mspeech","162":"train_mspeech","163":"train_mspeech","164":"train_mspeech","165":"train_mspeech","166":"train_mspeech","167":"train_mspeech","168":"train_mspeech","169":"train_mspeech","170":"train_mspeech","171":"train_mspeech","172":"train_mspeech","173":"train_mspeech","174":"train_mspeech","175":"train_mspeech","176":"train_mspeech","177":"train_mspeech","178":"train_mspeech","179":"train_mspeech","180":"train_mspeech","181":"train_mspeech","182":"train_mspeech","183":"train_mspeech","184":"train_mspeech","185":"train_mspeech","186":"train_mspeech","187":"train_mspeech","188":"train_mspeech","189":"train_mspeech","190":"train_mspeech","191":"train_mspeech","192":"train_mspeech","193":"train_mspeech","194":"train_mspeech","195":"train_mspeech","196":"train_mspeech","197":"train_mspeech","198":"train_mspeech","199":"train_mspeech"},"obj":{"0":"ModelLanguage.decode","1":"ModelLanguage.GetSymbolDict","2":"ModelLanguage.GetLanguageModel","3":"ModelLanguage.GetPinyin","4":"ModelLanguage.LoadModel","5":"ModelLanguage.LoadModel","6":"ModelLanguage.LoadModel","7":"ModelLanguage.LoadModel","8":"ModelLanguage.decode","9":"ModelLanguage.GetSymbolDict","10":"ModelLanguage.GetLanguageModel","11":"ModelLanguage.GetPinyin","12":"ModelLanguage.LoadModel","13":"ModelLanguage.LoadModel","14":"ModelLanguage.LoadModel","15":"ModelLanguage.LoadModel","16":"","17":"","18":"","19":"ModelSpeech.SaveModel","20":"ModelSpeech.TestModel","21":"ModelSpeech.TestModel","22":"ModelSpeech.TestModel","23":"ModelSpeech.TestModel","24":"ModelSpeech.TestModel","25":"","26":"","27":"","28":"ModelSpeech.SaveModel","29":"ModelSpeech.TestModel","30":"ModelSpeech.TestModel","31":"ModelSpeech.TestModel","32":"ModelSpeech.TestModel","33":"ModelSpeech.TestModel","34":"","35":"","36":"","37":"ModelSpeech.SaveModel","38":"ModelSpeech.TestModel","39":"ModelSpeech.TestModel","40":"ModelSpeech.TestModel","41":"ModelSpeech.TestModel","42":"ModelSpeech.TestModel","43":"","44":"","45":"","46":"ModelSpeech.SaveModel","47":"ModelSpeech.TestModel","48":"ModelSpeech.TestModel","49":"ModelSpeech.TestModel","50":"ModelSpeech.TestModel","51":"ModelSpeech.TestModel","52":"","53":"","54":"","55":"","56":"ModelSpeech.SaveModel","57":"ModelSpeech.TestModel","58":"ModelSpeech.TestModel","59":"ModelSpeech.TestModel","60":"ModelSpeech.TestModel","61":"ModelSpeech.TestModel","62":"","63":"","64":"","65":"ModelSpeech.SaveModel","66":"ModelSpeech.TestModel","67":"ModelSpeech.TestModel","68":"ModelSpeech.TestModel","69":"ModelSpeech.TestModel","70":"ModelSpeech.TestModel","71":"","72":"","73":"","74":"ModelSpeech.SaveModel","75":"ModelSpeech.TestModel","76":"ModelSpeech.TestModel","77":"ModelSpeech.TestModel","78":"ModelSpeech.TestModel","79":"ModelSpeech.TestModel","80":"","81":"","82":"","83":"ModelSpeech.SaveModel","84":"ModelSpeech.TestModel","85":"ModelSpeech.TestModel","86":"ModelSpeech.TestModel","87":"ModelSpeech.TestModel","88":"ModelSpeech.TestModel","89":"","90":"","91":"","92":"","93":"ModelSpeech.SaveModel","94":"ModelSpeech.TestModel","95":"ModelSpeech.TestModel","96":"ModelSpeech.TestModel","97":"ModelSpeech.TestModel","98":"ModelSpeech.TestModel","99":"ASRTHTTPHandle.do_GET","100":"","101":"","102":"DataSpeech.__init__","103":"DataSpeech.GetSymbolList","104":"","105":"","106":"DataSpeech.__init__","107":"DataSpeech.GetSymbolList","108":"","109":"","110":"","111":"","112":"","113":"","114":"","115":"","116":"","117":"","118":"","119":"","120":"","121":"","122":"","123":"","124":"","125":"","126":"","127":"","128":"","129":"","130":"","131":"","132":"","133":"","134":"","135":"","136":"","137":"","138":"","139":"","140":"","141":"","142":"","143":"","144":"","145":"","146":"","147":"","148":"","149":"","150":"","151":"","152":"","153":"","154":"","155":"","156":"","157":"","158":"","159":"","160":"","161":"","162":"","163":"","164":"","165":"","166":"","167":"","168":"","169":"","170":"","171":"","172":"","173":"","174":"","175":"","176":"","177":"","178":"","179":"","180":"","181":"","182":"","183":"","184":"","185":"","186":"","187":"","188":"","189":"","190":"","191":"","192":"","193":"","194":"","195":"","196":"","197":"","198":"","199":""},"lnum":{"0":171,"1":186,"2":208,"3":225,"4":51,"5":52,"6":53,"7":54,"8":174,"9":189,"10":211,"11":228,"12":51,"13":52,"14":53,"15":54,"16":28,"17":29,"18":30,"19":202,"20":223,"21":224,"22":249,"23":253,"24":262,"25":28,"26":29,"27":30,"28":211,"29":232,"30":233,"31":258,"32":262,"33":271,"34":29,"35":30,"36":31,"37":225,"38":253,"39":254,"40":279,"41":284,"42":298,"43":29,"44":30,"45":31,"46":223,"47":251,"48":252,"49":277,"50":282,"51":296,"52":28,"53":29,"54":30,"55":31,"56":224,"57":245,"58":246,"59":271,"60":275,"61":285,"62":28,"63":29,"64":30,"65":228,"66":249,"67":250,"68":275,"69":279,"70":289,"71":28,"72":29,"73":30,"74":229,"75":250,"76":251,"77":276,"78":280,"79":289,"80":28,"81":29,"82":30,"83":237,"84":265,"85":266,"86":291,"87":296,"88":310,"89":28,"90":29,"91":30,"92":31,"93":241,"94":262,"95":263,"96":288,"97":292,"98":302,"99":55,"100":25,"101":26,"102":35,"103":247,"104":29,"105":30,"106":39,"107":252,"108":28,"109":1,"110":1,"111":1,"112":1,"113":1,"114":1,"115":1,"116":1,"117":1,"118":1,"119":1,"120":1,"121":1,"122":1,"123":1,"124":1,"125":1,"126":1,"127":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1,"134":1,"135":1,"136":1,"137":1,"138":1,"139":1,"140":1,"141":1,"142":1,"143":1,"144":1,"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1,"153":1,"154":1,"155":1,"156":1,"157":1,"158":1,"159":1,"160":1,"161":1,"162":1,"163":1,"164":1,"165":1,"166":1,"167":1,"168":1,"169":1,"170":1,"171":1,"172":1,"173":1,"174":1,"175":1,"176":1,"177":1,"178":1,"179":1,"180":1,"181":1,"182":1,"183":1,"184":1,"185":1,"186":1,"187":1,"188":1,"189":1,"190":1,"191":1,"192":1,"193":1,"194":1,"195":1,"196":1,"197":1,"198":1,"199":1},"col":{"0":2,"1":12,"2":12,"3":13,"4":2,"5":2,"6":2,"7":2,"8":2,"9":12,"10":12,"11":13,"12":2,"13":2,"14":2,"15":2,"16":0,"17":0,"18":0,"19":6,"20":6,"21":14,"22":23,"23":7,"24":6,"25":0,"26":0,"27":0,"28":6,"29":6,"30":14,"31":23,"32":7,"33":6,"34":0,"35":0,"36":0,"37":6,"38":6,"39":14,"40":59,"41":7,"42":6,"43":0,"44":0,"45":0,"46":6,"47":6,"48":14,"49":59,"50":7,"51":6,"52":0,"53":0,"54":0,"55":0,"56":6,"57":6,"58":14,"59":23,"60":7,"61":6,"62":0,"63":0,"64":0,"65":6,"66":6,"67":14,"68":23,"69":7,"70":6,"71":0,"72":0,"73":0,"74":6,"75":6,"76":14,"77":23,"78":7,"79":6,"80":0,"81":0,"82":0,"83":6,"84":6,"85":14,"86":59,"87":7,"88":6,"89":0,"90":0,"91":0,"92":0,"93":6,"94":6,"95":14,"96":23,"97":7,"98":6,"99":8,"100":0,"101":0,"102":26,"103":10,"104":0,"105":0,"106":26,"107":10,"108":0,"109":0,"110":0,"111":0,"112":0,"113":0,"114":0,"115":0,"116":0,"117":0,"118":0,"119":0,"120":0,"121":0,"122":0,"123":0,"124":0,"125":0,"126":0,"127":0,"128":0,"129":0,"130":0,"131":0,"132":0,"133":0,"134":0,"135":0,"136":0,"137":0,"138":0,"139":0,"140":0,"141":0,"142":0,"143":0,"144":0,"145":0,"146":0,"147":0,"148":0,"149":0,"150":0,"151":0,"152":0,"153":0,"154":0,"155":0,"156":0,"157":0,"158":0,"159":0,"160":0,"161":0,"162":0,"163":0,"164":0,"165":0,"166":0,"167":0,"168":0,"169":0,"170":0,"171":0,"172":0,"173":0,"174":0,"175":0,"176":0,"177":0,"178":0,"179":0,"180":0,"181":0,"182":0,"183":0,"184":0,"185":0,"186":0,"187":0,"188":0,"189":0,"190":0,"191":0,"192":0,"193":0,"194":0,"195":0,"196":0,"197":0,"198":0,"199":0},"filename":{"0":"LanguageModel.py","1":"LanguageModel.py","2":"LanguageModel.py","3":"LanguageModel.py","4":"LanguageModel.py","5":"LanguageModel.py","6":"LanguageModel.py","7":"LanguageModel.py","8":"LanguageModel2.py","9":"LanguageModel2.py","10":"LanguageModel2.py","11":"LanguageModel2.py","12":"LanguageModel2.py","13":"LanguageModel2.py","14":"LanguageModel2.py","15":"LanguageModel2.py","16":"SpeechModel24.py","17":"SpeechModel24.py","18":"SpeechModel24.py","19":"SpeechModel24.py","20":"SpeechModel24.py","21":"SpeechModel24.py","22":"SpeechModel24.py","23":"SpeechModel24.py","24":"SpeechModel24.py","25":"SpeechModel25.py","26":"SpeechModel25.py","27":"SpeechModel25.py","28":"SpeechModel25.py","29":"SpeechModel25.py","30":"SpeechModel25.py","31":"SpeechModel25.py","32":"SpeechModel25.py","33":"SpeechModel25.py","34":"SpeechModel251.py","35":"SpeechModel251.py","36":"SpeechModel251.py","37":"SpeechModel251.py","38":"SpeechModel251.py","39":"SpeechModel251.py","40":"SpeechModel251.py","41":"SpeechModel251.py","42":"SpeechModel251.py","43":"SpeechModel251_limitless.py","44":"SpeechModel251_limitless.py","45":"SpeechModel251_limitless.py","46":"SpeechModel251_limitless.py","47":"SpeechModel251_limitless.py","48":"SpeechModel251_limitless.py","49":"SpeechModel251_limitless.py","50":"SpeechModel251_limitless.py","51":"SpeechModel251_limitless.py","52":"SpeechModel251_p.py","53":"SpeechModel251_p.py","54":"SpeechModel251_p.py","55":"SpeechModel251_p.py","56":"SpeechModel251_p.py","57":"SpeechModel251_p.py","58":"SpeechModel251_p.py","59":"SpeechModel251_p.py","60":"SpeechModel251_p.py","61":"SpeechModel251_p.py","62":"SpeechModel252.py","63":"SpeechModel252.py","64":"SpeechModel252.py","65":"SpeechModel252.py","66":"SpeechModel252.py","67":"SpeechModel252.py","68":"SpeechModel252.py","69":"SpeechModel252.py","70":"SpeechModel252.py","71":"SpeechModel26.py","72":"SpeechModel26.py","73":"SpeechModel26.py","74":"SpeechModel26.py","75":"SpeechModel26.py","76":"SpeechModel26.py","77":"SpeechModel26.py","78":"SpeechModel26.py","79":"SpeechModel26.py","80":"SpeechModel261.py","81":"SpeechModel261.py","82":"SpeechModel261.py","83":"SpeechModel261.py","84":"SpeechModel261.py","85":"SpeechModel261.py","86":"SpeechModel261.py","87":"SpeechModel261.py","88":"SpeechModel261.py","89":"SpeechModel261_p.py","90":"SpeechModel261_p.py","91":"SpeechModel261_p.py","92":"SpeechModel261_p.py","93":"SpeechModel261_p.py","94":"SpeechModel261_p.py","95":"SpeechModel261_p.py","96":"SpeechModel261_p.py","97":"SpeechModel261_p.py","98":"SpeechModel261_p.py","99":"asrserver.py","100":"readdata24.py","101":"readdata24.py","102":"readdata24.py","103":"readdata24.py","104":"readdata24_limitless.py","105":"readdata24_limitless.py","106":"readdata24_limitless.py","107":"readdata24_limitless.py","108":"testClient.py","109":"train_mspeech.py","110":"train_mspeech.py","111":"train_mspeech.py","112":"train_mspeech.py","113":"train_mspeech.py","114":"train_mspeech.py","115":"train_mspeech.py","116":"train_mspeech.py","117":"train_mspeech.py","118":"train_mspeech.py","119":"train_mspeech.py","120":"train_mspeech.py","121":"train_mspeech.py","122":"train_mspeech.py","123":"train_mspeech.py","124":"train_mspeech.py","125":"train_mspeech.py","126":"train_mspeech.py","127":"train_mspeech.py","128":"train_mspeech.py","129":"train_mspeech.py","130":"train_mspeech.py","131":"train_mspeech.py","132":"train_mspeech.py","133":"train_mspeech.py","134":"train_mspeech.py","135":"train_mspeech.py","136":"train_mspeech.py","137":"train_mspeech.py","138":"train_mspeech.py","139":"train_mspeech.py","140":"train_mspeech.py","141":"train_mspeech.py","142":"train_mspeech.py","143":"train_mspeech.py","144":"train_mspeech.py","145":"train_mspeech.py","146":"train_mspeech.py","147":"train_mspeech.py","148":"train_mspeech.py","149":"train_mspeech.py","150":"train_mspeech.py","151":"train_mspeech.py","152":"train_mspeech.py","153":"train_mspeech.py","154":"train_mspeech.py","155":"train_mspeech.py","156":"train_mspeech.py","157":"train_mspeech.py","158":"train_mspeech.py","159":"train_mspeech.py","160":"train_mspeech.py","161":"train_mspeech.py","162":"train_mspeech.py","163":"train_mspeech.py","164":"train_mspeech.py","165":"train_mspeech.py","166":"train_mspeech.py","167":"train_mspeech.py","168":"train_mspeech.py","169":"train_mspeech.py","170":"train_mspeech.py","171":"train_mspeech.py","172":"train_mspeech.py","173":"train_mspeech.py","174":"train_mspeech.py","175":"train_mspeech.py","176":"train_mspeech.py","177":"train_mspeech.py","178":"train_mspeech.py","179":"train_mspeech.py","180":"train_mspeech.py","181":"train_mspeech.py","182":"train_mspeech.py","183":"train_mspeech.py","184":"train_mspeech.py","185":"train_mspeech.py","186":"train_mspeech.py","187":"train_mspeech.py","188":"train_mspeech.py","189":"train_mspeech.py","190":"train_mspeech.py","191":"train_mspeech.py","192":"train_mspeech.py","193":"train_mspeech.py","194":"train_mspeech.py","195":"train_mspeech.py","196":"train_mspeech.py","197":"train_mspeech.py","198":"train_mspeech.py","199":"train_mspeech.py"},"symbol":{"0":"consider-using-enumerate","1":"consider-using-with","2":"consider-using-with","3":"consider-using-with","4":"attribute-defined-outside-init","5":"attribute-defined-outside-init","6":"attribute-defined-outside-init","7":"attribute-defined-outside-init","8":"consider-using-enumerate","9":"consider-using-with","10":"consider-using-with","11":"consider-using-with","12":"attribute-defined-outside-init","13":"attribute-defined-outside-init","14":"attribute-defined-outside-init","15":"attribute-defined-outside-init","16":"wildcard-import","17":"wildcard-import","18":"wildcard-import","19":"consider-using-with","20":"singleton-comparison","21":"consider-using-with","22":"singleton-comparison","23":"singleton-comparison","24":"singleton-comparison","25":"wildcard-import","26":"wildcard-import","27":"wildcard-import","28":"consider-using-with","29":"singleton-comparison","30":"consider-using-with","31":"singleton-comparison","32":"singleton-comparison","33":"singleton-comparison","34":"wildcard-import","35":"wildcard-import","36":"wildcard-import","37":"consider-using-with","38":"singleton-comparison","39":"consider-using-with","40":"singleton-comparison","41":"singleton-comparison","42":"singleton-comparison","43":"wildcard-import","44":"wildcard-import","45":"wildcard-import","46":"consider-using-with","47":"singleton-comparison","48":"consider-using-with","49":"singleton-comparison","50":"singleton-comparison","51":"singleton-comparison","52":"wildcard-import","53":"wildcard-import","54":"wildcard-import","55":"wildcard-import","56":"consider-using-with","57":"singleton-comparison","58":"consider-using-with","59":"singleton-comparison","60":"singleton-comparison","61":"singleton-comparison","62":"wildcard-import","63":"wildcard-import","64":"wildcard-import","65":"consider-using-with","66":"singleton-comparison","67":"consider-using-with","68":"singleton-comparison","69":"singleton-comparison","70":"singleton-comparison","71":"wildcard-import","72":"wildcard-import","73":"wildcard-import","74":"consider-using-with","75":"singleton-comparison","76":"consider-using-with","77":"singleton-comparison","78":"singleton-comparison","79":"singleton-comparison","80":"wildcard-import","81":"wildcard-import","82":"wildcard-import","83":"consider-using-with","84":"singleton-comparison","85":"consider-using-with","86":"singleton-comparison","87":"singleton-comparison","88":"singleton-comparison","89":"wildcard-import","90":"wildcard-import","91":"wildcard-import","92":"wildcard-import","93":"consider-using-with","94":"singleton-comparison","95":"consider-using-with","96":"singleton-comparison","97":"singleton-comparison","98":"singleton-comparison","99":"attribute-defined-outside-init","100":"wildcard-import","101":"wildcard-import","102":"redefined-builtin","103":"consider-using-with","104":"wildcard-import","105":"wildcard-import","106":"redefined-builtin","107":"consider-using-with","108":"wildcard-import","109":"duplicate-code","110":"duplicate-code","111":"duplicate-code","112":"duplicate-code","113":"duplicate-code","114":"duplicate-code","115":"duplicate-code","116":"duplicate-code","117":"duplicate-code","118":"duplicate-code","119":"duplicate-code","120":"duplicate-code","121":"duplicate-code","122":"duplicate-code","123":"duplicate-code","124":"duplicate-code","125":"duplicate-code","126":"duplicate-code","127":"duplicate-code","128":"duplicate-code","129":"duplicate-code","130":"duplicate-code","131":"duplicate-code","132":"duplicate-code","133":"duplicate-code","134":"duplicate-code","135":"duplicate-code","136":"duplicate-code","137":"duplicate-code","138":"duplicate-code","139":"duplicate-code","140":"duplicate-code","141":"duplicate-code","142":"duplicate-code","143":"duplicate-code","144":"duplicate-code","145":"duplicate-code","146":"duplicate-code","147":"duplicate-code","148":"duplicate-code","149":"duplicate-code","150":"duplicate-code","151":"duplicate-code","152":"duplicate-code","153":"duplicate-code","154":"duplicate-code","155":"duplicate-code","156":"duplicate-code","157":"duplicate-code","158":"duplicate-code","159":"duplicate-code","160":"duplicate-code","161":"duplicate-code","162":"duplicate-code","163":"duplicate-code","164":"duplicate-code","165":"duplicate-code","166":"duplicate-code","167":"duplicate-code","168":"duplicate-code","169":"duplicate-code","170":"duplicate-code","171":"duplicate-code","172":"duplicate-code","173":"duplicate-code","174":"duplicate-code","175":"duplicate-code","176":"duplicate-code","177":"duplicate-code","178":"duplicate-code","179":"duplicate-code","180":"duplicate-code","181":"duplicate-code","182":"duplicate-code","183":"duplicate-code","184":"duplicate-code","185":"duplicate-code","186":"duplicate-code","187":"duplicate-code","188":"duplicate-code","189":"duplicate-code","190":"duplicate-code","191":"duplicate-code","192":"duplicate-code","193":"duplicate-code","194":"duplicate-code","195":"duplicate-code","196":"duplicate-code","197":"duplicate-code","198":"duplicate-code","199":"duplicate-code"},"text":{"0":"Consider using enumerate instead of iterating with range and len","1":"Consider using 'with' for resource-allocating operations","2":"Consider using 'with' for resource-allocating operations","3":"Consider using 'with' for resource-allocating operations","4":"Attribute 'dict_pinyin' defined outside __init__","5":"Attribute 'model1' defined outside __init__","6":"Attribute 'model2' defined outside __init__","7":"Attribute 'pinyin' defined outside __init__","8":"Consider using enumerate instead of iterating with range and len","9":"Consider using 'with' for resource-allocating operations","10":"Consider using 'with' for resource-allocating operations","11":"Consider using 'with' for resource-allocating operations","12":"Attribute 'dict_pinyin' defined outside __init__","13":"Attribute 'model1' defined outside __init__","14":"Attribute 'model2' defined outside __init__","15":"Attribute 'pinyin' defined outside __init__","16":"Wildcard import general_function.file_wav","17":"Wildcard import general_function.file_dict","18":"Wildcard import general_function.gen_func","19":"Consider using 'with' for resource-allocating operations","20":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","21":"Consider using 'with' for resource-allocating operations","22":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","23":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","24":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","25":"Wildcard import general_function.file_wav","26":"Wildcard import general_function.file_dict","27":"Wildcard import general_function.gen_func","28":"Consider using 'with' for resource-allocating operations","29":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","30":"Consider using 'with' for resource-allocating operations","31":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","32":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","33":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","34":"Wildcard import general_function.file_wav","35":"Wildcard import general_function.file_dict","36":"Wildcard import general_function.gen_func","37":"Consider using 'with' for resource-allocating operations","38":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","39":"Consider using 'with' for resource-allocating operations","40":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","41":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","42":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","43":"Wildcard import general_function.file_wav","44":"Wildcard import general_function.file_dict","45":"Wildcard import general_function.gen_func","46":"Consider using 'with' for resource-allocating operations","47":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","48":"Consider using 'with' for resource-allocating operations","49":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","50":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","51":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","52":"Wildcard import general_function.file_wav","53":"Wildcard import general_function.file_dict","54":"Wildcard import general_function.gen_func","55":"Wildcard import general_function.muti_gpu","56":"Consider using 'with' for resource-allocating operations","57":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","58":"Consider using 'with' for resource-allocating operations","59":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","60":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","61":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","62":"Wildcard import general_function.file_wav","63":"Wildcard import general_function.file_dict","64":"Wildcard import general_function.gen_func","65":"Consider using 'with' for resource-allocating operations","66":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","67":"Consider using 'with' for resource-allocating operations","68":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","69":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","70":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","71":"Wildcard import general_function.file_wav","72":"Wildcard import general_function.file_dict","73":"Wildcard import general_function.gen_func","74":"Consider using 'with' for resource-allocating operations","75":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","76":"Consider using 'with' for resource-allocating operations","77":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","78":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","79":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","80":"Wildcard import general_function.file_wav","81":"Wildcard import general_function.file_dict","82":"Wildcard import general_function.gen_func","83":"Consider using 'with' for resource-allocating operations","84":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","85":"Consider using 'with' for resource-allocating operations","86":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","87":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","88":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","89":"Wildcard import general_function.file_wav","90":"Wildcard import general_function.file_dict","91":"Wildcard import general_function.gen_func","92":"Wildcard import general_function.muti_gpu","93":"Consider using 'with' for resource-allocating operations","94":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","95":"Consider using 'with' for resource-allocating operations","96":"Comparison 'show_ratio == True' should be 'show_ratio is True' if checking for the singleton value True, or 'bool(show_ratio)' if testing for truthiness","97":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","98":"Comparison 'out_report == True' should be 'out_report is True' if checking for the singleton value True, or 'out_report' if testing for truthiness","99":"Attribute 'protocal_version' defined outside __init__","100":"Wildcard import general_function.file_wav","101":"Wildcard import general_function.file_dict","102":"Redefining built-in 'type'","103":"Consider using 'with' for resource-allocating operations","104":"Wildcard import general_function.file_wav","105":"Wildcard import general_function.file_dict","106":"Redefining built-in 'type'","107":"Consider using 'with' for resource-allocating operations","108":"Wildcard import general_function.file_wav","109":"Similar lines in 2 files\n==SpeechModel251_p:130\n==SpeechModel261_p:147\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#ada_d = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n\n\t\tmodel.build((self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\t\tmodel = ParallelModel(model, NUM_GPU)\n\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\t#print('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\tprint('[*Info] Create Model Successful, Compiles Model Successful. ')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n\n\tdef TrainModel(self, datapath, epoch = 2, save_step = 1000, batch_size = 32, filename = abspath + 'model_speech\/m' + ModelName + '\/speech_model'+ModelName):\n\t\t'''\n\t\t\u8bad\u7ec3\u6a21\u578b\n\t\t\u53c2\u6570\uff1a\n\t\t\tdatapath: \u6570\u636e\u4fdd\u5b58\u7684\u8def\u5f84\n\t\t\tepoch: \u8fed\u4ee3\u8f6e\u6570\n\t\t\tsave_step: \u6bcf\u591a\u5c11\u6b65\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n\t\t\tfilename: \u9ed8\u8ba4\u4fdd\u5b58\u6587\u4ef6\u540d\uff0c\u4e0d\u542b\u6587\u4ef6\u540e\u7f00\u540d\n\t\t'''\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.save_weights(filename+comment+'.model')\n\t\tself.base_model.save_weights(filename + comment + '.model.base')\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = ''\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif(i % 10 == 0 and show_ratio == True):\n\t\t\t\t\tprint('Test Count: ',i,'\/',data_count)\n\n\t\t\t\ttxt = ''\n\t\t\t\tif(out_report == True):\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\t\t\t\t\ttxt_obj.write(txt)\n\n\n\t\t\t#print('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')\n\t\t\tprint('*[Test Result] Speech Recognition ' + str_dataset + ' set word error ratio: ', word_error_num \/ words_num * 100, '%')\n\t\t\tif(out_report == True):\n\t\t\t\ttxt = '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm251\/speech_model251_e_0_step_98000.model')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n\t#print('*[\u63d0\u793a] \u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\uff1a\\n',r)","110":"Similar lines in 2 files\n==SpeechModel251_limitless:222\n==SpeechModel261:236\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True, io_step_print = 10, io_step_file = 10):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\n\t\tio_step_print\n\t\t\t\u4e3a\u4e86\u51cf\u5c11\u6d4b\u8bd5\u65f6\u6807\u51c6\u8f93\u51fa\u7684io\u5f00\u9500\uff0c\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u6765\u5b9e\u73b0\n\n\t\tio_step_file\n\t\t\t\u4e3a\u4e86\u51cf\u5c11\u6d4b\u8bd5\u65f6\u6587\u4ef6\u8bfb\u5199\u7684io\u5f00\u9500\uff0c\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u6765\u5b9e\u73b0\n\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = '\u6d4b\u8bd5\u62a5\u544a\\n\u6a21\u578b\u7f16\u53f7 ' + ModelName + '\\n\\n'\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif((i % io_step_print == 0 or i == data_count - 1) and show_ratio == True):\n\t\t\t\t\t#print('\u6d4b\u8bd5\u8fdb\u5ea6\uff1a',i,'\/',data_count)\n\t\t\t\t\tprint('Test Count: ',i,'\/',data_count)\n\n\n\t\t\t\tif(out_report == True):\n\t\t\t\t\tif(i % io_step_file == 0 or i == data_count - 1):\n\t\t\t\t\t\ttxt_obj.write(txt)\n\t\t\t\t\t\ttxt = ''\n\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\n\n\n\t\t\t#print('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')\n\t\t\tprint('*[Test Result] Speech Recognition ' + str_dataset + ' set word error ratio: ', word_error_num \/ words_num * 100, '%')\n\t\t\tif(out_report == True):\n\t\t\t\ttxt += '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt = ''\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752895%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm251\/speech_model251_e_0_step_100000.model')","111":"Similar lines in 2 files\n==SpeechModel251:126\n==SpeechModel251_limitless:124\n\t\tlayer_h16 = Dropout(0.3)(layer_h16)\n\t\tlayer_h17 = Dense(128, activation=\"relu\", use_bias=True, kernel_initializer='he_normal')(layer_h16) # \u5168\u8fde\u63a5\u5c42\n\t\tlayer_h17 = Dropout(0.3)(layer_h17)\n\t\tlayer_h18 = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(layer_h17) # \u5168\u8fde\u63a5\u5c42\n\n\t\ty_pred = Activation('softmax', name='Activation0')(layer_h18)\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#opt = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\t#print('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\tprint('[*Info] Create Model Successful, Compiles Model Successful. ')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n\n\tdef TrainModel(self, datapath, epoch = 2, save_step = 1000, batch_size = 32, filename = abspath + 'model_speech\/m' + ModelName + '\/speech_model'+ModelName):\n\t\t'''\n\t\t\u8bad\u7ec3\u6a21\u578b\n\t\t\u53c2\u6570\uff1a\n\t\t\tdatapath: \u6570\u636e\u4fdd\u5b58\u7684\u8def\u5f84\n\t\t\tepoch: \u8fed\u4ee3\u8f6e\u6570\n\t\t\tsave_step: \u6bcf\u591a\u5c11\u6b65\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n\t\t\tfilename: \u9ed8\u8ba4\u4fdd\u5b58\u6587\u4ef6\u540d\uff0c\u4e0d\u542b\u6587\u4ef6\u540e\u7f00\u540d\n\t\t'''\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.save_weights(filename + comment + '.model')\n\t\tself.base_model.save_weights(filename + comment + '.model.base')\n\t\t# \u9700\u8981\u5b89\u88c5 hdf5 \u6a21\u5757\n\t\tself._model.save(filename + comment + '.h5')\n\t\tself.base_model.save(filename + comment + '.base.h5')\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True, io_step_print = 10, io_step_file = 10):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\n\t\tio_step_print\n\t\t\t\u4e3a\u4e86\u51cf\u5c11\u6d4b\u8bd5\u65f6\u6807\u51c6\u8f93\u51fa\u7684io\u5f00\u9500\uff0c\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u6765\u5b9e\u73b0\n\n\t\tio_step_file\n\t\t\t\u4e3a\u4e86\u51cf\u5c11\u6d4b\u8bd5\u65f6\u6587\u4ef6\u8bfb\u5199\u7684io\u5f00\u9500\uff0c\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u6765\u5b9e\u73b0\n\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = '\u6d4b\u8bd5\u62a5\u544a\\n\u6a21\u578b\u7f16\u53f7 ' + ModelName + '\\n\\n'\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif((i % io_step_print == 0 or i == data_count - 1) and show_ratio == True):\n\t\t\t\t\t#print('\u6d4b\u8bd5\u8fdb\u5ea6\uff1a',i,'\/',data_count)\n\t\t\t\t\tprint('Test Count: ',i,'\/',data_count)\n\n\n\t\t\t\tif(out_report == True):\n\t\t\t\t\tif(i % io_step_file == 0 or i == data_count - 1):\n\t\t\t\t\t\ttxt_obj.write(txt)\n\t\t\t\t\t\ttxt = ''\n\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\n\n\n\t\t\t#print('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')\n\t\t\tprint('*[Test Result] Speech Recognition ' + str_dataset + ' set word error ratio: ', word_error_num \/ words_num * 100, '%')\n\t\t\tif(out_report == True):\n\t\t\t\ttxt += '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt = ''\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)","112":"Similar lines in 2 files\n==SpeechModel24:202\n==SpeechModel26:229\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = ''\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif(i % 10 == 0 and show_ratio == True):\n\t\t\t\t\tprint('\u6d4b\u8bd5\u8fdb\u5ea6\uff1a',i,'\/',data_count)\n\n\t\t\t\ttxt = ''\n\t\t\t\tif(out_report == True):\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\t\t\t\t\ttxt_obj.write(txt)\n\n\n\t\t\tprint('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')\n\t\t\tif(out_report == True):\n\t\t\t\ttxt = '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature2(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\timport tensorflow as tf\n\tfrom keras.backend.tensorflow_backend import set_session\n\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\tconfig = tf.ConfigProto()\n\tconfig.gpu_options.per_process_gpu_memory_fraction = 0.93\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\tset_session(tf.Session(config=config))\n\n\n\tdatapath = ''\n\tmodelpath = 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):","113":"Similar lines in 2 files\n==LanguageModel2:102\n==LanguageModel:99\n\tdef decode(self,list_syllable, yuzhi = 0.0001):\n\t\t'''\n\t\t\u5b9e\u73b0\u62fc\u97f3\u5411\u6587\u672c\u7684\u8f6c\u6362\n\t\t\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\n\t\t'''\n\t\t#assert self.dic_pinyin == null or self.model1 == null or self.model2 == null\n\t\tlist_words = []\n\n\t\tnum_pinyin = len(list_syllable)\n\t\t#print('======')\n\t\t#print('decode function: list_syllable\\n',list_syllable)\n\t\t#print(num_pinyin)\n\t\t# \u5f00\u59cb\u8bed\u97f3\u89e3\u7801\n\t\tfor i in range(num_pinyin):\n\t\t\t#print(i)\n\t\t\tls = ''\n\t\t\tif(list_syllable[i] in self.dict_pinyin): # \u5982\u679c\u8fd9\u4e2a\u62fc\u97f3\u5728\u6c49\u8bed\u62fc\u97f3\u5b57\u5178\u91cc\u7684\u8bdd\n\t\t\t\t# \u83b7\u53d6\u62fc\u97f3\u4e0b\u5c5e\u7684\u5b57\u7684\u5217\u8868\uff0cls\u5305\u542b\u4e86\u8be5\u62fc\u97f3\u5bf9\u5e94\u7684\u6240\u6709\u7684\u5b57\n\t\t\t\tls = self.dict_pinyin[list_syllable[i]]\n\t\t\telse:\n\t\t\t\tbreak\n\n\n\t\t\tif(i == 0):\n\t\t\t\t# \u7b2c\u4e00\u4e2a\u5b57\u505a\u521d\u59cb\u5904\u7406\n\t\t\t\tnum_ls = len(ls)\n\t\t\t\tfor j in range(num_ls):\n\t\t\t\t\ttuple_word = ['',0.0]\n\t\t\t\t\t# \u8bbe\u7f6e\u9a6c\u5c14\u79d1\u592b\u6a21\u578b\u521d\u59cb\u72b6\u6001\u503c\n\t\t\t\t\t# \u8bbe\u7f6e\u521d\u59cb\u6982\u7387\uff0c\u7f6e\u4e3a1.0\n\t\t\t\t\ttuple_word = [ls[j], 1.0]\n\t\t\t\t\t#print(tuple_word)\n\t\t\t\t\t# \u6dfb\u52a0\u5230\u53ef\u80fd\u7684\u53e5\u5b50\u5217\u8868\n\t\t\t\t\tlist_words.append(tuple_word)\n\n\t\t\t\t#print(list_words)\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\t# \u5f00\u59cb\u5904\u7406\u7d27\u8ddf\u5728\u7b2c\u4e00\u4e2a\u5b57\u540e\u9762\u7684\u5b57\n\t\t\t\tlist_words_2 = []\n\t\t\t\tnum_ls_word = len(list_words)\n\t\t\t\t#print('ls_wd: ',list_words)\n\t\t\t\tfor j in range(0, num_ls_word):\n\n\t\t\t\t\tnum_ls = len(ls)\n\t\t\t\t\tfor k in range(0, num_ls):\n\t\t\t\t\t\ttuple_word = ['',0.0]\n\t\t\t\t\t\ttuple_word = list(list_words[j]) # \u628a\u73b0\u6709\u7684\u6bcf\u4e00\u6761\u77ed\u8bed\u53d6\u51fa\u6765\n\t\t\t\t\t\t#print('tw1: ',tuple_word)\n\t\t\t\t\t\ttuple_word[0] = tuple_word[0] + ls[k] # \u5c1d\u8bd5\u6309\u7167\u4e0b\u4e00\u4e2a\u97f3\u53ef\u80fd\u5bf9\u5e94\u7684\u5168\u90e8\u7684\u5b57\u8fdb\u884c\u7ec4\u5408\n\t\t\t\t\t\t#print('ls[k]  ',ls[k])\n\n\t\t\t\t\t\ttmp_words = tuple_word[0][-2:] # \u53d6\u51fa\u7528\u4e8e\u8ba1\u7b97\u7684\u6700\u540e\u4e24\u4e2a\u5b57\n\t\t\t\t\t\t#print('tmp_words: ',tmp_words,tmp_words in self.model2)\n\t\t\t\t\t\tif(tmp_words in self.model2): # \u5224\u65ad\u5b83\u4eec\u662f\u4e0d\u662f\u518d\u72b6\u6001\u8f6c\u79fb\u8868\u91cc\n\t\t\t\t\t\t\t#print(tmp_words,tmp_words in self.model2)\n\t\t\t\t\t\t\ttuple_word[1] = tuple_word[1] * float(self.model2[tmp_words]) \/ float(self.model1[tmp_words[-2]])\n\t\t\t\t\t\t\t# \u6838\u5fc3\uff01\u5728\u5f53\u524d\u6982\u7387\u4e0a\u4e58\u8f6c\u79fb\u6982\u7387\uff0c\u516c\u5f0f\u5316\u7b80\u540e\u4e3a\u7b2cn-1\u548cn\u4e2a\u5b57\u51fa\u73b0\u7684\u6b21\u6570\u9664\u4ee5\u7b2cn-1\u4e2a\u5b57\u51fa\u73b0\u7684\u6b21\u6570\n\t\t\t\t\t\t\t#print(self.model2[tmp_words],self.model1[tmp_words[-2]])\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\ttuple_word[1] = 0.0\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t#print('tw2: ',tuple_word)\n\t\t\t\t\t\t#print(tuple_word[1] >= pow(yuzhi, i))\n\t\t\t\t\t\tif(tuple_word[1] >= pow(yuzhi, i)):\n\t\t\t\t\t\t\t# \u5927\u4e8e\u9608\u503c\u4e4b\u540e\u4fdd\u7559\uff0c\u5426\u5219\u4e22\u5f03\n\t\t\t\t\t\t\tlist_words_2.append(tuple_word)\n\n\t\t\t\tlist_words = list_words_2\n\t\t\t\t#print(list_words,'\\n')\n\t\t#print(list_words)\n\t\tfor i in range(0, len(list_words)):\n\t\t\tfor j in range(i + 1, len(list_words)):\n\t\t\t\tif(list_words[i][1] < list_words[j][1]):\n\t\t\t\t\ttmp = list_words[i]\n\t\t\t\t\tlist_words[i] = list_words[j]\n\t\t\t\t\tlist_words[j] = tmp\n\n\t\treturn list_words\n\t\tpass\n\n\tdef GetSymbolDict(self, dictfilename):\n\t\t'''\n\t\t\u8bfb\u53d6\u62fc\u97f3\u6c49\u5b57\u7684\u5b57\u5178\u6587\u4ef6\n\t\t\u8fd4\u56de\u8bfb\u53d6\u540e\u7684\u5b57\u5178\n\t\t'''\n\t\ttxt_obj = open(dictfilename, 'r', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\t\ttxt_text = txt_obj.read()\n\t\ttxt_obj.close()\n\t\ttxt_lines = txt_text.split('\\n') # \u6587\u672c\u5206\u5272\n\n\t\tdic_symbol = {} # \u521d\u59cb\u5316\u7b26\u53f7\u5b57\u5178\n\t\tfor i in txt_lines:\n\t\t\tlist_symbol=[] # \u521d\u59cb\u5316\u7b26\u53f7\u5217\u8868\n\t\t\tif(i!=''):\n\t\t\t\ttxt_l=i.split('\\t')\n\t\t\t\tpinyin = txt_l[0]\n\t\t\t\tfor word in txt_l[1]:\n\t\t\t\t\tlist_symbol.append(word)\n\t\t\tdic_symbol[pinyin] = list_symbol\n\n\t\treturn dic_symbol\n\n\tdef GetLanguageModel(self, modelLanFilename):\n\t\t'''\n\t\t\u8bfb\u53d6\u8bed\u8a00\u6a21\u578b\u7684\u6587\u4ef6\n\t\t\u8fd4\u56de\u8bfb\u53d6\u540e\u7684\u6a21\u578b\n\t\t'''\n\t\ttxt_obj = open(modelLanFilename, 'r', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\t\ttxt_text = txt_obj.read()\n\t\ttxt_obj.close()\n\t\ttxt_lines = txt_text.split('\\n') # \u6587\u672c\u5206\u5272\n\n\t\tdic_model = {} # \u521d\u59cb\u5316\u7b26\u53f7\u5b57\u5178\n\t\tfor i in txt_lines:\n\t\t\tif(i!=''):\n\t\t\t\ttxt_l=i.split('\\t')\n\t\t\t\tif(len(txt_l) == 1):\n\t\t\t\t\tcontinue\n\t\t\t\t#print(txt_l)\n\t\t\t\tdic_model[txt_l[0]] = txt_l[1]\n\n\t\treturn dic_model\n\n\tdef GetPinyin(self, filename):\n\t\tfile_obj = open(filename,'r',encoding='UTF-8')\n\t\ttxt_all = file_obj.read()\n\t\tfile_obj.close()\n\n\t\ttxt_lines = txt_all.split('\\n')\n\t\tdic={}\n\n\t\tfor line in txt_lines:\n\t\t\tif(line == ''):\n\t\t\t\tcontinue\n\t\t\tpinyin_split = line.split('\\t')\n\n\t\t\tlist_pinyin=pinyin_split[0]\n\n\t\t\tif(list_pinyin not in dic and int(pinyin_split[1]) > 1):\n\t\t\t\tdic[list_pinyin] = pinyin_split[1]\n\t\treturn dic\n\n\nif(__name__=='__main__'):\n\n\tml = ModelLanguage('model_language')\n\tml.LoadModel()\n\n\t#str_pinyin = ['zhe4','zhen1','shi4','ji2', 'hao3','de5']\n\t#str_pinyin = ['jin1', 'tian1', 'shi4', 'xing1', 'qi1', 'san1']\n\t#str_pinyin = ['ni3', 'hao3','a1']\n\t#str_pinyin = ['wo3','dui4','shi4','mei2','cuo4','ni3','hao3']\n\t#str_pinyin = ['wo3','dui4','shi4','tian1','mei2','na5','li3','hai4']\n\t#str_pinyin = ['ba3','zhe4','xie1','zuo4','wan2','wo3','jiu4','qu4','shui4','jiao4']\n\t#str_pinyin = ['wo3','qu4','a4','mei2','shi4','er2','la1']\n\t#str_pinyin = ['wo3', 'men5', 'qun2', 'li3', 'xiong1', 'di4', 'jian4', 'mei4', 'dou1', 'zai4', 'shuo1']\n\t#str_pinyin = ['su1', 'an1', 'ni3', 'sui4', 'li4', 'yun4', 'sui2', 'cong2', 'jiao4', 'ming2', 'tao2', 'qi3', 'yu2', 'peng2', 'ya4', 'yang4', 'chao1', 'dao3', 'jiang1', 'li3', 'yuan2', 'kang1', 'zhua1', 'zou3']\n\t#str_pinyin = ['da4', 'jia1', 'hao3']","114":"Similar lines in 2 files\n==readdata24:20\n==readdata24_limitless:24\nimport platform as plat\nimport os\n\nimport numpy as np\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\n\nimport random\n#import scipy.io.wavfile as wav\nfrom scipy.fftpack import fft\n\nclass DataSpeech():\n\n\n\tdef __init__(self, path, type, LoadToMem = False, MemWavCount = 10000):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u53c2\u6570\uff1a\n\t\t\tpath\uff1a\u6570\u636e\u5b58\u653e\u4f4d\u7f6e\u6839\u76ee\u5f55\n\t\t'''\n\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\n\t\tself.datapath = path; # \u6570\u636e\u5b58\u653e\u4f4d\u7f6e\u6839\u76ee\u5f55\n\t\tself.type = type # \u6570\u636e\u7c7b\u578b\uff0c\u5206\u4e3a\u4e09\u79cd\uff1a\u8bad\u7ec3\u96c6(train)\u3001\u9a8c\u8bc1\u96c6(dev)\u3001\u6d4b\u8bd5\u96c6(test)\n\n\t\tself.slash = ''\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\t\tself.dic_wavlist_thchs30 = {}\n\t\tself.dic_symbollist_thchs30 = {}\n\t\tself.dic_wavlist_stcmds = {}\n\t\tself.dic_symbollist_stcmds = {}\n\n\t\tself.SymbolNum = 0 # \u8bb0\u5f55\u62fc\u97f3\u7b26\u53f7\u6570\u91cf\n\t\tself.list_symbol = self.GetSymbolList() # \u5168\u90e8\u6c49\u8bed\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\tself.list_wavnum=[] # wav\u6587\u4ef6\u6807\u8bb0\u5217\u8868\n\t\tself.list_symbolnum=[] # symbol\u6807\u8bb0\u5217\u8868\n\n\t\tself.DataNum = 0 # \u8bb0\u5f55\u6570\u636e\u91cf\n\t\tself.LoadDataList()\n\n\t\tself.wavs_data = []\n\t\tself.LoadToMem = LoadToMem\n\t\tself.MemWavCount = MemWavCount\n\t\tpass\n\n\tdef LoadDataList(self):\n\t\t'''\n\t\t\u52a0\u8f7d\u7528\u4e8e\u8ba1\u7b97\u7684\u6570\u636e\u5217\u8868\n\t\t\u53c2\u6570\uff1a\n\t\t\ttype\uff1a\u9009\u53d6\u7684\u6570\u636e\u96c6\u7c7b\u578b\n\t\t\t\ttrain \u8bad\u7ec3\u96c6\n\t\t\t\tdev \u5f00\u53d1\u96c6\n\t\t\t\ttest \u6d4b\u8bd5\u96c6\n\t\t'''\n\t\t# \u8bbe\u5b9a\u9009\u53d6\u54ea\u4e00\u9879\u4f5c\u4e3a\u8981\u4f7f\u7528\u7684\u6570\u636e\u96c6\n\t\tif(self.type=='train'):\n\t\t\tfilename_wavlist_thchs30 = 'thchs30' + self.slash + 'train.wav.lst'\n\t\t\tfilename_wavlist_stcmds = 'st-cmds' + self.slash + 'train.wav.txt'\n\t\t\tfilename_symbollist_thchs30 = 'thchs30' + self.slash + 'train.syllable.txt'\n\t\t\tfilename_symbollist_stcmds = 'st-cmds' + self.slash + 'train.syllable.txt'\n\t\telif(self.type=='dev'):\n\t\t\tfilename_wavlist_thchs30 = 'thchs30' + self.slash + 'cv.wav.lst'\n\t\t\tfilename_wavlist_stcmds = 'st-cmds' + self.slash + 'dev.wav.txt'\n\t\t\tfilename_symbollist_thchs30 = 'thchs30' + self.slash + 'cv.syllable.txt'\n\t\t\tfilename_symbollist_stcmds = 'st-cmds' + self.slash + 'dev.syllable.txt'\n\t\telif(self.type=='test'):\n\t\t\tfilename_wavlist_thchs30 = 'thchs30' + self.slash + 'test.wav.lst'\n\t\t\tfilename_wavlist_stcmds = 'st-cmds' + self.slash + 'test.wav.txt'\n\t\t\tfilename_symbollist_thchs30 = 'thchs30' + self.slash + 'test.syllable.txt'\n\t\t\tfilename_symbollist_stcmds = 'st-cmds' + self.slash + 'test.syllable.txt'\n\t\telse:\n\t\t\tfilename_wavlist = '' # \u9ed8\u8ba4\u7559\u7a7a\n\t\t\tfilename_symbollist = ''\n\t\t# \u8bfb\u53d6\u6570\u636e\u5217\u8868\uff0cwav\u6587\u4ef6\u5217\u8868\u548c\u5176\u5bf9\u5e94\u7684\u7b26\u53f7\u5217\u8868\n\t\tself.dic_wavlist_thchs30,self.list_wavnum_thchs30 = get_wav_list(self.datapath + filename_wavlist_thchs30)\n\t\tself.dic_wavlist_stcmds,self.list_wavnum_stcmds = get_wav_list(self.datapath + filename_wavlist_stcmds)\n\n\t\tself.dic_symbollist_thchs30,self.list_symbolnum_thchs30 = get_wav_symbol(self.datapath + filename_symbollist_thchs30)\n\t\tself.dic_symbollist_stcmds,self.list_symbolnum_stcmds = get_wav_symbol(self.datapath + filename_symbollist_stcmds)\n\t\tself.DataNum = self.GetDataNum()\n\n\tdef GetDataNum(self):\n\t\t'''\n\t\t\u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\t\u5f53wav\u6570\u91cf\u548csymbol\u6570\u91cf\u4e00\u81f4\u7684\u65f6\u5019\u8fd4\u56de\u6b63\u786e\u7684\u503c\uff0c\u5426\u5219\u8fd4\u56de-1\uff0c\u4ee3\u8868\u51fa\u9519\u3002\n\t\t'''\n\t\tnum_wavlist_thchs30 = len(self.dic_wavlist_thchs30)\n\t\tnum_symbollist_thchs30 = len(self.dic_symbollist_thchs30)\n\t\tnum_wavlist_stcmds = len(self.dic_wavlist_stcmds)\n\t\tnum_symbollist_stcmds = len(self.dic_symbollist_stcmds)\n\t\tif(num_wavlist_thchs30 == num_symbollist_thchs30 and num_wavlist_stcmds == num_symbollist_stcmds):\n\t\t\tDataNum = num_wavlist_thchs30 + num_wavlist_stcmds\n\t\telse:\n\t\t\tDataNum = -1\n\n\t\treturn DataNum\n\n\n\tdef GetData(self,n_start,n_amount=1):\n\t\t'''\n\t\t\u8bfb\u53d6\u6570\u636e\uff0c\u8fd4\u56de\u795e\u7ecf\u7f51\u7edc\u8f93\u5165\u503c\u548c\u8f93\u51fa\u503c\u77e9\u9635(\u53ef\u76f4\u63a5\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u90a3\u79cd)\n\t\t\u53c2\u6570\uff1a\n\t\t\tn_start\uff1a\u4ece\u7f16\u53f7\u4e3an_start\u6570\u636e\u5f00\u59cb\u9009\u53d6\u6570\u636e\n\t\t\tn_amount\uff1a\u9009\u53d6\u7684\u6570\u636e\u6570\u91cf\uff0c\u9ed8\u8ba4\u4e3a1\uff0c\u5373\u4e00\u6b21\u4e00\u4e2awav\u6587\u4ef6\n\t\t\u8fd4\u56de\uff1a\n\t\t\t\u4e09\u4e2a\u5305\u542bwav\u7279\u5f81\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u8f93\u5165\u503c\uff0c\u548c\u4e00\u4e2a\u6807\u5b9a\u7684\u7c7b\u522b\u77e9\u9635\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u503c\n\t\t'''\n\t\tbili = 2\n\t\tif(self.type=='train'):\n\t\t\tbili = 11\n\n\t\t# \u8bfb\u53d6\u4e00\u4e2a\u6587\u4ef6\n\t\tif(n_start % bili == 0):\n\t\t\tfilename = self.dic_wavlist_thchs30[self.list_wavnum_thchs30[n_start \/\/ bili]]\n\t\t\tlist_symbol=self.dic_symbollist_thchs30[self.list_symbolnum_thchs30[n_start \/\/ bili]]\n\t\telse:\n\t\t\tn = n_start \/\/ bili * (bili - 1)\n\t\t\tyushu = n_start % bili\n\t\t\tlength=len(self.list_wavnum_stcmds)\n\t\t\tfilename = self.dic_wavlist_stcmds[self.list_wavnum_stcmds[(n + yushu - 1)%length]]\n\t\t\tlist_symbol=self.dic_symbollist_stcmds[self.list_symbolnum_stcmds[(n + yushu - 1)%length]]\n\n\t\tif('Windows' == plat.system()):\n\t\t\tfilename = filename.replace('\/','\\\\') # windows\u7cfb\u7edf\u4e0b\u9700\u8981\u6267\u884c\u8fd9\u4e00\u884c\uff0c\u5bf9\u6587\u4ef6\u8def\u5f84\u505a\u7279\u522b\u5904\u7406\n\n\t\twavsignal,fs=read_wav_data(self.datapath + filename)\n\n\t\t# \u83b7\u53d6\u8f93\u51fa\u7279\u5f81\n\n\t\tfeat_out=[]\n\t\t#print(\"\u6570\u636e\u7f16\u53f7\",n_start,filename)\n\t\tfor i in list_symbol:\n\t\t\tif(''!=i):\n\t\t\t\tn=self.SymbolToNum(i)\n\t\t\t\t#v=self.NumToVector(n)\n\t\t\t\t#feat_out.append(v)\n\t\t\t\tfeat_out.append(n)\n\t\t#print('feat_out:',feat_out)\n\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\tdata_input = GetFrequencyFeature3(wavsignal,fs)\n\t\t#data_input = np.array(data_input)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#arr_zero = np.zeros((1, 39), dtype=np.int16) #\u4e00\u4e2a\u5168\u662f0\u7684\u884c\u5411\u91cf\n\n\t\t#while(len(data_input)<1600): #\u957f\u5ea6\u4e0d\u591f\u65f6\u8865\u5168\u52301600","115":"Similar lines in 3 files\n==SpeechModel251_limitless:299\n==SpeechModel251_p:287\n==SpeechModel261_p:304\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm251\/speech_model251_e_0_step_98000.model')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n\t#print('*[\u63d0\u793a] \u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\uff1a\\n',r)","116":"Similar lines in 3 files\n==SpeechModel251_p:287\n==SpeechModel261:313\n==SpeechModel261_p:304\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm251\/speech_model251_e_0_step_98000.model')","117":"Similar lines in 3 files\n==SpeechModel24:202\n==SpeechModel25:211\n==SpeechModel26:229\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = ''\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif(i % 10 == 0 and show_ratio == True):\n\t\t\t\t\tprint('\u6d4b\u8bd5\u8fdb\u5ea6\uff1a',i,'\/',data_count)\n\n\t\t\t\ttxt = ''\n\t\t\t\tif(out_report == True):\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\t\t\t\t\ttxt_obj.write(txt)\n\n\n\t\t\tprint('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')\n\t\t\tif(out_report == True):\n\t\t\t\ttxt = '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()","118":"Similar lines in 2 files\n==SpeechModel252:288\n==SpeechModel25:270\n\t\t\tif(out_report == True):\n\t\t\t\ttxt = '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\timport tensorflow as tf\n\tfrom keras.backend.tensorflow_backend import set_session","119":"Similar lines in 2 files\n==SpeechModel251:224\n==SpeechModel261:236\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True, io_step_print = 10, io_step_file = 10):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\n\t\tio_step_print\n\t\t\t\u4e3a\u4e86\u51cf\u5c11\u6d4b\u8bd5\u65f6\u6807\u51c6\u8f93\u51fa\u7684io\u5f00\u9500\uff0c\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u6765\u5b9e\u73b0\n\n\t\tio_step_file\n\t\t\t\u4e3a\u4e86\u51cf\u5c11\u6d4b\u8bd5\u65f6\u6587\u4ef6\u8bfb\u5199\u7684io\u5f00\u9500\uff0c\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u8fd9\u4e2a\u53c2\u6570\u6765\u5b9e\u73b0\n\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = '\u6d4b\u8bd5\u62a5\u544a\\n\u6a21\u578b\u7f16\u53f7 ' + ModelName + '\\n\\n'\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif((i % io_step_print == 0 or i == data_count - 1) and show_ratio == True):\n\t\t\t\t\t#print('\u6d4b\u8bd5\u8fdb\u5ea6\uff1a',i,'\/',data_count)\n\t\t\t\t\tprint('Test Count: ',i,'\/',data_count)\n\n\n\t\t\t\tif(out_report == True):\n\t\t\t\t\tif(i % io_step_file == 0 or i == data_count - 1):\n\t\t\t\t\t\ttxt_obj.write(txt)\n\t\t\t\t\t\ttxt = ''\n\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\n\n\n\t\t\t#print('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')\n\t\t\tprint('*[Test Result] Speech Recognition ' + str_dataset + ' set word error ratio: ', word_error_num \/ words_num * 100, '%')\n\t\t\tif(out_report == True):\n\t\t\t\ttxt += '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt = ''\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)","120":"Similar lines in 4 files\n==SpeechModel251_p:284\n==SpeechModel252:288\n==SpeechModel25:270\n==SpeechModel261_p:301\n\t\t\tif(out_report == True):\n\t\t\t\ttxt = '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n","121":"Similar lines in 4 files\n==SpeechModel251_limitless:299\n==SpeechModel252:291\n==SpeechModel25:273\n==SpeechModel261:313\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n","122":"Similar lines in 2 files\n==SpeechModel251:351\n==SpeechModel251_limitless:356\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752895%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm251\/speech_model251_e_0_step_100000.h5')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\n\t#t1=time.time()\n\t#ms.TestModel(datapath, str_dataset='train', data_count = 128, out_report = True)\n\t#ms.TestModel(datapath, str_dataset='dev', data_count = 128, out_report = True)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#t2=time.time()\n\t#print('Test Model Time Cost:',t2-t1,'s')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n\t#print('*[\u63d0\u793a] \u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\uff1a\\n',r)","123":"Similar lines in 3 files\n==SpeechModel251:351\n==SpeechModel251_p:344\n==SpeechModel261_p:361\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm251\/speech_model251_e_0_step_98000.model')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n\t#print('*[\u63d0\u793a] \u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\uff1a\\n',r)","124":"Similar lines in 2 files\n==SpeechModel251:351\n==SpeechModel261:370\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\t#import tensorflow as tf\n\t#from keras.backend.tensorflow_backend import set_session\n\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\t#config = tf.ConfigProto()\n\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\t#set_session(tf.Session(config=config))\n\n\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm261\/speech_model261_e_0_step_100000.model')","125":"Similar lines in 3 files\n==SpeechModel251:132\n==SpeechModel251_limitless:130\n==SpeechModel261:147\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#opt = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\t#print('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\tprint('[*Info] Create Model Successful, Compiles Model Successful. ')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n\n\tdef TrainModel(self, datapath, epoch = 2, save_step = 1000, batch_size = 32, filename = abspath + 'model_speech\/m' + ModelName + '\/speech_model'+ModelName):\n\t\t'''\n\t\t\u8bad\u7ec3\u6a21\u578b\n\t\t\u53c2\u6570\uff1a\n\t\t\tdatapath: \u6570\u636e\u4fdd\u5b58\u7684\u8def\u5f84\n\t\t\tepoch: \u8fed\u4ee3\u8f6e\u6570\n\t\t\tsave_step: \u6bcf\u591a\u5c11\u6b65\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n\t\t\tfilename: \u9ed8\u8ba4\u4fdd\u5b58\u6587\u4ef6\u540d\uff0c\u4e0d\u542b\u6587\u4ef6\u540e\u7f00\u540d\n\t\t'''\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''","126":"Similar lines in 3 files\n==SpeechModel251_p:185\n==SpeechModel252:189\n==SpeechModel261_p:202\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.save_weights(filename+comment+'.model')\n\t\tself.base_model.save_weights(filename + comment + '.model.base')\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = ''\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif(i % 10 == 0 and show_ratio == True):","127":"Similar lines in 2 files\n==SpeechModel25:345\n==SpeechModel26:363\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\timport tensorflow as tf\n\tfrom keras.backend.tensorflow_backend import set_session\n\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\tconfig = tf.ConfigProto()\n\tconfig.gpu_options.per_process_gpu_memory_fraction = 0.93\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\tset_session(tf.Session(config=config))\n\n\n\tdatapath = ''\n\tmodelpath = 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\t#ms.LoadModel(modelpath + 'm26\/speech_model26_e_0_step_397000.model')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n\t#print('*[\u63d0\u793a] \u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\uff1a\\n',r)","128":"Similar lines in 5 files\n==SpeechModel24:261\n==SpeechModel251_p:284\n==SpeechModel252:288\n==SpeechModel261_p:301\n==SpeechModel26:288\n\t\t\tif(out_report == True):\n\t\t\t\ttxt = '*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a ' + str(word_error_num \/ words_num * 100) + ' %'\n\t\t\t\ttxt_obj.write(txt)\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()","129":"Similar lines in 3 files\n==SpeechModel251_p:157\n==SpeechModel261:170\n==SpeechModel261_p:174\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\t#print('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\tprint('[*Info] Create Model Successful, Compiles Model Successful. ')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n\n\tdef TrainModel(self, datapath, epoch = 2, save_step = 1000, batch_size = 32, filename = abspath + 'model_speech\/m' + ModelName + '\/speech_model'+ModelName):\n\t\t'''\n\t\t\u8bad\u7ec3\u6a21\u578b\n\t\t\u53c2\u6570\uff1a\n\t\t\tdatapath: \u6570\u636e\u4fdd\u5b58\u7684\u8def\u5f84\n\t\t\tepoch: \u8fed\u4ee3\u8f6e\u6570\n\t\t\tsave_step: \u6bcf\u591a\u5c11\u6b65\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n\t\t\tfilename: \u9ed8\u8ba4\u4fdd\u5b58\u6587\u4ef6\u540d\uff0c\u4e0d\u542b\u6587\u4ef6\u540e\u7f00\u540d\n\t\t'''\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.save_weights(filename+comment+'.model')\n\t\tself.base_model.save_weights(filename + comment + '.model.base')\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n","130":"Similar lines in 2 files\n==readdata24:230\n==readdata24_limitless:235\n\t\t\t\tlabel_length.append([len(data_labels)])\n\n\t\t\tlabel_length = np.matrix(label_length)\n\t\t\tinput_length = np.array([input_length]).T\n\t\t\t#input_length = np.array(input_length)\n\t\t\t#print('input_length:\\n',input_length)\n\t\t\t#X=X.reshape(batch_size, audio_length, 200, 1)\n\t\t\t#print(X)\n\t\t\tyield [X, y, input_length, label_length ], labels\n\t\tpass\n\n\tdef GetSymbolList(self):\n\t\t'''\n\t\t\u52a0\u8f7d\u62fc\u97f3\u7b26\u53f7\u5217\u8868\uff0c\u7528\u4e8e\u6807\u8bb0\u7b26\u53f7\n\t\t\u8fd4\u56de\u4e00\u4e2a\u5217\u8868list\u7c7b\u578b\u53d8\u91cf\n\t\t'''\n\t\ttxt_obj=open('dict.txt','r',encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\t\ttxt_text=txt_obj.read()\n\t\ttxt_lines=txt_text.split('\\n') # \u6587\u672c\u5206\u5272\n\t\tlist_symbol=[] # \u521d\u59cb\u5316\u7b26\u53f7\u5217\u8868\n\t\tfor i in txt_lines:\n\t\t\tif(i!=''):\n\t\t\t\ttxt_l=i.split('\\t')\n\t\t\t\tlist_symbol.append(txt_l[0])\n\t\ttxt_obj.close()\n\t\tlist_symbol.append('_')\n\t\tself.SymbolNum = len(list_symbol)\n\t\treturn list_symbol\n\n\tdef GetSymbolNum(self):\n\t\t'''\n\t\t\u83b7\u53d6\u62fc\u97f3\u7b26\u53f7\u6570\u91cf\n\t\t'''\n\t\treturn len(self.list_symbol)\n\n\tdef SymbolToNum(self,symbol):\n\t\t'''\n\t\t\u7b26\u53f7\u8f6c\u4e3a\u6570\u5b57\n\t\t'''\n\t\tif(symbol != ''):\n\t\t\treturn self.list_symbol.index(symbol)\n\t\treturn self.SymbolNum\n\n\tdef NumToVector(self,num):\n\t\t'''\n\t\t\u6570\u5b57\u8f6c\u4e3a\u5bf9\u5e94\u7684\u5411\u91cf\n\t\t'''\n\t\tv_tmp=[]\n\t\tfor i in range(0,len(self.list_symbol)):\n\t\t\tif(i==num):\n\t\t\t\tv_tmp.append(1)\n\t\t\telse:\n\t\t\t\tv_tmp.append(0)\n\t\tv=np.array(v_tmp)\n\t\treturn v\n\nif(__name__=='__main__'):\n\t#path='E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t#l=DataSpeech(path)\n\t#l.LoadDataList('train')\n\t#print(l.GetDataNum())\n\t#print(l.GetData(0))\n\t#aa=l.data_genetator()\n\t#for i in aa:\n\t\t#a,b=i\n\t#print(a,b)\n\tpass\n","131":"Similar lines in 4 files\n==SpeechModel24:264\n==SpeechModel251_limitless:299\n==SpeechModel261:313\n==SpeechModel26:291\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)\n\n\n\t\tr1 = K.get_value(r[0][0])\n\t\t#print('r1', r1)\n\n\n\t\t#r2 = K.get_value(r[1])\n\t\t#print(r2)\n\n\t\tr1=r1[0]\n\n\t\treturn r1\n\t\tpass\n\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()","132":"Similar lines in 2 files\n==SpeechModel251:50\n==SpeechModel251_p:48\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a\u5377\u79ef\u6c60\u5316\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\tCTC\u5c42\uff1a\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.05)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\tlayer_h3 = Dropout(0.05)(layer_h3)\n\t\tlayer_h4 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h3) # \u5377\u79ef\u5c42\n\t\tlayer_h4 = Dropout(0.1)(layer_h4)\n\t\tlayer_h5 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h4) # \u5377\u79ef\u5c42\n\t\tlayer_h6 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h5) # \u6c60\u5316\u5c42\n\n\t\tlayer_h6 = Dropout(0.1)(layer_h6)\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.15)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\n\t\tlayer_h9 = Dropout(0.15)(layer_h9)\n\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # \u5377\u79ef\u5c42\n\t\tlayer_h10 = Dropout(0.2)(layer_h10)\n\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # \u5377\u79ef\u5c42\n\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # \u6c60\u5316\u5c42\n\n\t\tlayer_h12 = Dropout(0.2)(layer_h12)\n\t\tlayer_h13 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h12) # \u5377\u79ef\u5c42","133":"Similar lines in 4 files\n==SpeechModel251:155\n==SpeechModel251_limitless:153\n==SpeechModel251_p:157\n==SpeechModel261_p:174\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\t#print('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\tprint('[*Info] Create Model Successful, Compiles Model Successful. ')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n\n\tdef TrainModel(self, datapath, epoch = 2, save_step = 1000, batch_size = 32, filename = abspath + 'model_speech\/m' + ModelName + '\/speech_model'+ModelName):\n\t\t'''\n\t\t\u8bad\u7ec3\u6a21\u578b\n\t\t\u53c2\u6570\uff1a\n\t\t\tdatapath: \u6570\u636e\u4fdd\u5b58\u7684\u8def\u5f84\n\t\t\tepoch: \u8fed\u4ee3\u8f6e\u6570\n\t\t\tsave_step: \u6bcf\u591a\u5c11\u6b65\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n\t\t\tfilename: \u9ed8\u8ba4\u4fdd\u5b58\u6587\u4ef6\u540d\uff0c\u4e0d\u542b\u6587\u4ef6\u540e\u7f00\u540d\n\t\t'''\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''","134":"Similar lines in 2 files\n==SpeechModel24:336\n==SpeechModel25:345\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\timport tensorflow as tf\n\tfrom keras.backend.tensorflow_backend import set_session\n\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\t#\u8fdb\u884c\u914d\u7f6e\uff0c\u4f7f\u752870%\u7684GPU\n\tconfig = tf.ConfigProto()\n\tconfig.gpu_options.per_process_gpu_memory_fraction = 0.93\n\t#config.gpu_options.allow_growth=True   #\u4e0d\u5168\u90e8\u5360\u6ee1\u663e\u5b58, \u6309\u9700\u5206\u914d\n\tset_session(tf.Session(config=config))\n\n\n\tdatapath = ''\n\tmodelpath = 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):","135":"Similar lines in 3 files\n==SpeechModel251:351\n==SpeechModel252:348\n==SpeechModel25:330\n\tdef RecognizeSpeech(self, wavsignal, fs):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u4e00\u4e2awav\u5e8f\u5217\u7684\u8bed\u97f3\n\t\t'''\n\n\t\t#data = self.data\n\t\t#data = DataSpeech('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6')\n\t\t#data.LoadDataList('dev')\n\t\t# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\n\t\t#data_input = GetMfccFeature(wavsignal, fs)\n\t\t#t0=time.time()\n\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n\t\t#t1=time.time()\n\t\t#print('time cost:',t1-t0)\n\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n","136":"Similar lines in 2 files\n==SpeechModel24:23\n==SpeechModel25:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *\n\n# LSTM_CNN\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape # , Flatten,LSTM,Convolution1D,MaxPooling1D,Merge\nfrom tensorflow.keras.layers import Conv1D,LSTM,MaxPooling1D, Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D #, Merge,Conv1D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta\n\nfrom readdata24 import DataSpeech\n\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a3*3\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u76ee\u6807\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n","137":"Similar lines in 4 files\n==SpeechModel24:202\n==SpeechModel252:228\n==SpeechModel25:211\n==SpeechModel26:229\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = ''\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif(i % 10 == 0 and show_ratio == True):\n\t\t\t\t\tprint('\u6d4b\u8bd5\u8fdb\u5ea6\uff1a',i,'\/',data_count)\n\n\t\t\t\ttxt = ''\n\t\t\t\tif(out_report == True):\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\t\t\t\t\ttxt_obj.write(txt)\n\n\n\t\t\tprint('*[\u6d4b\u8bd5\u7ed3\u679c] \u8bed\u97f3\u8bc6\u522b ' + str_dataset + ' \u96c6\u8bed\u97f3\u5355\u5b57\u9519\u8bef\u7387\uff1a', word_error_num \/ words_num * 100, '%')","138":"Similar lines in 2 files\n==SpeechModel251:34\n==SpeechModel251_limitless:32\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten\nfrom tensorflow.keras.layers import Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D #, Merge\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta, Adam\n\nfrom readdata24 import DataSpeech\n\nabspath = ''\nModelName='251'\n#NUM_GPU = 2\n\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a\u5377\u79ef\u6c60\u5316\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\tCTC\u5c42\uff1a\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n","139":"Similar lines in 2 files\n==SpeechModel252:47\n==SpeechModel26:45\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a39\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1500\uff08\u5927\u7ea615s\uff09\n\t\t\u9690\u85cf\u5c42\u4e00\uff1a1024\u4e2a\u795e\u7ecf\u5143\u7684\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\u4e8c\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\u4e09\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\u56db\uff1a\u5faa\u73af\u5c42\u3001LSTM\u5c42\n\t\t\u9690\u85cf\u5c42\u4e94\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\u516d\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n\t\t# \u6bcf\u4e00\u5e27\u4f7f\u752813\u7ef4mfcc\u7279\u5f81\u53ca\u517613\u7ef4\u4e00\u9636\u5dee\u5206\u548c13\u7ef4\u4e8c\u9636\u5dee\u5206\u8868\u793a\uff0c\u6700\u5927\u4fe1\u53f7\u5e8f\u5217\u957f\u5ea6\u4e3a1500\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.1)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408","140":"Similar lines in 3 files\n==SpeechModel24:336\n==SpeechModel252:363\n==SpeechModel26:363\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n\n\timport tensorflow as tf\n\tfrom keras.backend.tensorflow_backend import set_session","141":"Similar lines in 5 files\n==SpeechModel24:202\n==SpeechModel251_p:224\n==SpeechModel25:211\n==SpeechModel261_p:241\n==SpeechModel26:229\n\t\tf.write(filename+comment)\n\t\tf.close()\n\n\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True):\n\t\t'''\n\t\t\u6d4b\u8bd5\u68c0\u9a8c\u6a21\u578b\u6548\u679c\n\t\t'''\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n\n\t\t\ttxt = ''\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n\n\t\t\t\tif(i % 10 == 0 and show_ratio == True):","142":"Similar lines in 2 files\n==SpeechModel25:39\n==SpeechModel26:40\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta\n\nfrom readdata24 import DataSpeech\n\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a3*3\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u76ee\u6807\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n\t\t# \u6bcf\u4e00\u5e27\u4f7f\u752813\u7ef4mfcc\u7279\u5f81\u53ca\u517613\u7ef4\u4e00\u9636\u5dee\u5206\u548c13\u7ef4\u4e8c\u9636\u5dee\u5206\u8868\u793a\uff0c\u6700\u5927\u4fe1\u53f7\u5e8f\u5217\u957f\u5ea6\u4e3a1500","143":"Similar lines in 7 files\n==SpeechModel24:336\n==SpeechModel251:366\n==SpeechModel251_limitless:371\n==SpeechModel251_p:359\n==SpeechModel261:385\n==SpeechModel261_p:376\n==SpeechModel26:363\n\t\tinput_length = len(data_input)\n\t\tinput_length = input_length \/\/ 8\n\n\t\tdata_input = np.array(data_input, dtype = np.float)\n\t\t#print(data_input,data_input.shape)\n\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n\t\t#t2=time.time()\n\t\tr1 = self.Predict(data_input, input_length)\n\t\t#t3=time.time()\n\t\t#print('time cost:',t3-t2)\n\t\tlist_symbol_dic = GetSymbolList(self.datapath) # \u83b7\u53d6\u62fc\u97f3\u5217\u8868\n\n\n\t\tr_str=[]\n\t\tfor i in r1:\n\t\t\tr_str.append(list_symbol_dic[i])\n\n\t\treturn r_str\n\t\tpass\n\n\tdef RecognizeSpeech_FromFile(self, filename):\n\t\t'''\n\t\t\u6700\u7ec8\u505a\u8bed\u97f3\u8bc6\u522b\u7528\u7684\u51fd\u6570\uff0c\u8bc6\u522b\u6307\u5b9a\u6587\u4ef6\u540d\u7684\u8bed\u97f3\n\t\t'''\n\n\t\twavsignal,fs = read_wav_data(filename)\n\n\t\tr = self.RecognizeSpeech(wavsignal, fs)\n\n\t\treturn r\n\n\t\tpass\n\n\n\n\t@property\n\tdef model(self):\n\t\t'''\n\t\t\u8fd4\u56dekeras model\n\t\t'''\n\t\treturn self._model\n\n\nif(__name__=='__main__'):\n","144":"Similar lines in 2 files\n==SpeechModel251_p:46\n==SpeechModel261_p:47\nNUM_GPU = 2\n\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a\u5377\u79ef\u6c60\u5316\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\tCTC\u5c42\uff1a\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42","145":"Similar lines in 2 files\n==SpeechModel24:39\n==SpeechModel26:40\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta\n\nfrom readdata24 import DataSpeech\n\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\u4e00\uff1a3*3\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\u4e8c\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\u4e09\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\u56db\uff1a\u5faa\u73af\u5c42\u3001LSTM\/GRU\u5c42\n\t\t\u9690\u85cf\u5c42\u4e94\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\u516d\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa","146":"Similar lines in 2 files\n==SpeechModel24:110\n==SpeechModel25:119\n\t\tlayer_h12 = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(layer_h11) # \u5168\u8fde\u63a5\u5c42\n\n\t\ty_pred = Activation('softmax', name='Activation0')(layer_h12)\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\t#model.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\tada_d = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = ada_d)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\tprint('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n","147":"Similar lines in 7 files\n==SpeechModel24:264\n==SpeechModel251:301\n==SpeechModel251_p:287\n==SpeechModel252:291\n==SpeechModel25:273\n==SpeechModel261_p:304\n==SpeechModel26:291\n\t\t\t\ttxt_obj.close()\n\n\t\texcept StopIteration:\n\t\t\tprint('[Error] Model Test Error. please check data format.')\n\n\tdef Predict(self, data_input, input_len):\n\t\t'''\n\t\t\u9884\u6d4b\u7ed3\u679c\n\t\t\u8fd4\u56de\u8bed\u97f3\u8bc6\u522b\u540e\u7684\u62fc\u97f3\u7b26\u53f7\u5217\u8868\n\t\t'''\n\n\t\tbatch_size = 1\n\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n\n\t\tin_len[0] = input_len\n\n\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n\n\t\tfor i in range(batch_size):\n\t\t\tx_in[i,0:len(data_input)] = data_input\n\n\n\t\tbase_pred = self.base_model.predict(x = x_in)\n\n\t\t#print('base_pred:\\n', base_pred)\n\n\t\t#y_p = base_pred\n\t\t#for j in range(200):\n\t\t#\tmean = np.sum(y_p[0][j]) \/ y_p[0][j].shape[0]\n\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n\t\t#\tcount=0\n\t\t#\tfor i in range(y_p[0][j].shape[0]):\n\t\t#\t\tif(y_p[0][j][i] < mean):\n\t\t#\t\t\tcount += 1\n\t\t#\tprint('count:',count)\n\n\t\tbase_pred =base_pred[:, :, :]\n\t\t#base_pred =base_pred[:, 2:, :]\n\n\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n\n\t\t#print('r', r)","148":"Similar lines in 2 files\n==SpeechModel252:189\n==SpeechModel261:198\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.save_weights(filename+comment+'.model')\n\t\tself.base_model.save_weights(filename + comment + '.model.base')\n\t\tf = open('step'+ModelName+'.txt','w')\n\t\tf.write(filename+comment)\n\t\tf.close()\n","149":"Similar lines in 2 files\n==SpeechModel251:50\n==SpeechModel261_p:49\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a\u5377\u79ef\u6c60\u5316\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\tCTC\u5c42\uff1a\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42","150":"Similar lines in 2 files\n==SpeechModel252:47\n==SpeechModel25:44\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a39\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1500\uff08\u5927\u7ea615s\uff09\n\t\t\u9690\u85cf\u5c42\u4e00\uff1a1024\u4e2a\u795e\u7ecf\u5143\u7684\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\u4e8c\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\u4e09\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\u56db\uff1a\u5faa\u73af\u5c42\u3001LSTM\u5c42\n\t\t\u9690\u85cf\u5c42\u4e94\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\u516d\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''","151":"Similar lines in 5 files\n==SpeechModel24:44\n==SpeechModel251:50\n==SpeechModel251_p:48\n==SpeechModel261:49\n==SpeechModel261_p:49\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a\u5377\u79ef\u6c60\u5316\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\n\t\tCTC\u5c42\uff1a\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n\n\t\t'''\n\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n","152":"Similar lines in 9 files\n==SpeechModel24:44\n==SpeechModel251:50\n==SpeechModel251_limitless:48\n==SpeechModel251_p:48\n==SpeechModel252:47\n==SpeechModel25:44\n==SpeechModel261:49\n==SpeechModel261_p:49\n==SpeechModel26:45\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a3*3\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u76ee\u6807\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n","153":"Similar lines in 2 files\n==SpeechModel251:50\n==SpeechModel25:44\nclass ModelSpeech(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, datapath):\n\t\t'''\n\t\t\u521d\u59cb\u5316\n\t\t\u9ed8\u8ba4\u8f93\u51fa\u7684\u62fc\u97f3\u7684\u8868\u793a\u5927\u5c0f\u662f1428\uff0c\u53731427\u4e2a\u62fc\u97f3+1\u4e2a\u7a7a\u767d\u5757\n\t\t'''\n\t\tMS_OUTPUT_SIZE = 1428\n\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE # \u795e\u7ecf\u7f51\u7edc\u6700\u7ec8\u8f93\u51fa\u7684\u6bcf\u4e00\u4e2a\u5b57\u7b26\u5411\u91cf\u7ef4\u5ea6\u7684\u5927\u5c0f\n\t\t#self.BATCH_SIZE = BATCH_SIZE # \u4e00\u6b21\u8bad\u7ec3\u7684batch\n\t\tself.label_max_string_length = 64\n\t\tself.AUDIO_LENGTH = 1600\n\t\tself.AUDIO_FEATURE_LENGTH = 200\n\t\tself._model, self.base_model = self.CreateModel()\n\n\t\tself.datapath = datapath\n\t\tself.slash = ''\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\tif(self.slash != self.datapath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.datapath = self.datapath + self.slash\n\n\n\tdef CreateModel(self):\n\t\t'''\n\t\t\u5b9a\u4e49CNN\/LSTM\/CTC\u6a21\u578b\uff0c\u4f7f\u7528\u51fd\u6570\u5f0f\u6a21\u578b\n\t\t\u8f93\u5165\u5c42\uff1a200\u7ef4\u7684\u7279\u5f81\u503c\u5e8f\u5217\uff0c\u4e00\u6761\u8bed\u97f3\u6570\u636e\u7684\u6700\u5927\u957f\u5ea6\u8bbe\u4e3a1600\uff08\u5927\u7ea616s\uff09\n\t\t\u9690\u85cf\u5c42\uff1a3*3\u5377\u79ef\u5c42\n\t\t\u9690\u85cf\u5c42\uff1a\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2\n\t\t\u9690\u85cf\u5c42\uff1aDropout\u5c42\uff0c\u9700\u8981\u65ad\u5f00\u7684\u795e\u7ecf\u5143\u7684\u6bd4\u4f8b\u4e3a0.2\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\t\u9690\u85cf\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\n\t\t\u76ee\u6807\u8f93\u51fa\u5c42\uff1a\u5168\u8fde\u63a5\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u91cf\u4e3aself.MS_OUTPUT_SIZE\uff0c\u4f7f\u7528softmax\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\n\t\t\u8f93\u51fa\u5c42\uff1a\u81ea\u5b9a\u4e49\u5c42\uff0c\u5373CTC\u5c42\uff0c\u4f7f\u7528CTC\u7684loss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u8fde\u63a5\u6027\u65f6\u5e8f\u591a\u8f93\u51fa\n","154":"Similar lines in 2 files\n==SpeechModel251:117\n==SpeechModel251_p:115\n\t\tlayer_h14 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h13) # \u5377\u79ef\u5c42\n\t\tlayer_h15 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h14) # \u6c60\u5316\u5c42\n\n\t\t#test=Model(inputs = input_data, outputs = layer_h12)\n\t\t#test.summary()\n\n\t\tlayer_h16 = Reshape((200, 3200))(layer_h15) #Reshape\u5c42\n\t\t#layer_h5 = LSTM(256, activation='relu', use_bias=True, return_sequences=True)(layer_h4) # LSTM\u5c42\n\t\t#layer_h6 = Dropout(0.2)(layer_h5) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\tlayer_h16 = Dropout(0.3)(layer_h16)\n\t\tlayer_h17 = Dense(128, activation=\"relu\", use_bias=True, kernel_initializer='he_normal')(layer_h16) # \u5168\u8fde\u63a5\u5c42\n\t\tlayer_h17 = Dropout(0.3)(layer_h17)\n\t\tlayer_h18 = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(layer_h17) # \u5168\u8fde\u63a5\u5c42\n\n\t\ty_pred = Activation('softmax', name='Activation0')(layer_h18)\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#opt = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)","155":"Similar lines in 3 files\n==SpeechModel251:183\n==SpeechModel251_limitless:181\n==SpeechModel252:189\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n\n\tdef LoadModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName+'.model'):\n\t\t'''\n\t\t\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n\t\t'''\n\t\tself._model.load_weights(filename)\n\t\t#self.base_model.load_weights(filename + '.base')\n\n\tdef SaveModel(self,filename = abspath + 'model_speech\/m'+ModelName+'\/speech_model'+ModelName,comment=''):\n\t\t'''\n\t\t\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n\t\t'''","156":"Similar lines in 2 files\n==LanguageModel2:27\n==LanguageModel:27\nimport platform as plat\n\n\nclass ModelLanguage(): # \u8bed\u97f3\u6a21\u578b\u7c7b\n\tdef __init__(self, modelpath):\n\t\tself.modelpath = modelpath\n\t\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\n\t\tself.slash = ''\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash = '\\\\'\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash = '\/'\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash = '\/'\n\n\t\tif(self.slash != self.modelpath[-1]): # \u5728\u76ee\u5f55\u8def\u5f84\u672b\u5c3e\u589e\u52a0\u659c\u6760\n\t\t\tself.modelpath = self.modelpath + self.slash\n\n\t\tpass\n\n\tdef LoadModel(self):\n\t\tself.dict_pinyin = self.GetSymbolDict('dict.txt')\n\t\tself.model1 = self.GetLanguageModel(self.modelpath + 'language_model1.txt')\n\t\tself.model2 = self.GetLanguageModel(self.modelpath + 'language_model2.txt')\n\t\tself.pinyin = self.GetPinyin(self.modelpath + 'dic_pinyin.txt')\n\t\tmodel = (self.dict_pinyin, self.model1, self.model2 )\n\t\treturn model\n\t\tpass\n\n\tdef SpeechToText(self, list_syllable):\n\t\t'''\n\t\t\u8bed\u97f3\u8bc6\u522b\u4e13\u7528\u7684\u5904\u7406\u51fd\u6570\n\n\t\t\u5b9e\u73b0\u4ece\u8bed\u97f3\u62fc\u97f3\u7b26\u53f7\u5230\u6700\u7ec8\u6587\u672c\u7684\u8f6c\u6362","157":"Similar lines in 2 files\n==SpeechModel251:91\n==SpeechModel251_limitless:89\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.05)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\tlayer_h3 = Dropout(0.05)(layer_h3)\n\t\tlayer_h4 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h3) # \u5377\u79ef\u5c42\n\t\tlayer_h4 = Dropout(0.1)(layer_h4)\n\t\tlayer_h5 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h4) # \u5377\u79ef\u5c42\n\t\tlayer_h6 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h5) # \u6c60\u5316\u5c42\n\n\t\tlayer_h6 = Dropout(0.1)(layer_h6)\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.15)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\n\t\tlayer_h9 = Dropout(0.15)(layer_h9)\n\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # \u5377\u79ef\u5c42\n\t\tlayer_h10 = Dropout(0.2)(layer_h10)\n\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # \u5377\u79ef\u5c42\n\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # \u6c60\u5316\u5c42\n\n\t\tlayer_h12 = Dropout(0.2)(layer_h12)\n\t\tlayer_h13 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h12) # \u5377\u79ef\u5c42\n\t\tlayer_h13 = Dropout(0.2)(layer_h13)\n\t\tlayer_h14 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h13) # \u5377\u79ef\u5c42\n\t\tlayer_h15 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h14) # \u6c60\u5316\u5c42\n\n\t\t#test=Model(inputs = input_data, outputs = layer_h12)\n\t\t#test.summary()\n","158":"Similar lines in 2 files\n==SpeechModel252:138\n==SpeechModel26:140\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\tada_d = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = ada_d)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\tprint('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')","159":"Similar lines in 2 files\n==SpeechModel251_limitless:124\n==SpeechModel251_p:124\n\t\tlayer_h16 = Dropout(0.3)(layer_h16)\n\t\tlayer_h17 = Dense(128, activation=\"relu\", use_bias=True, kernel_initializer='he_normal')(layer_h16) # \u5168\u8fde\u63a5\u5c42\n\t\tlayer_h17 = Dropout(0.3)(layer_h17)\n\t\tlayer_h18 = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(layer_h17) # \u5168\u8fde\u63a5\u5c42\n\n\t\ty_pred = Activation('softmax', name='Activation0')(layer_h18)\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#opt = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)","160":"Similar lines in 2 files\n==SpeechModel251_limitless:89\n==SpeechModel251_p:89\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.05)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\tlayer_h3 = Dropout(0.05)(layer_h3)\n\t\tlayer_h4 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h3) # \u5377\u79ef\u5c42\n\t\tlayer_h4 = Dropout(0.1)(layer_h4)\n\t\tlayer_h5 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h4) # \u5377\u79ef\u5c42\n\t\tlayer_h6 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h5) # \u6c60\u5316\u5c42\n\n\t\tlayer_h6 = Dropout(0.1)(layer_h6)\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.15)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\n\t\tlayer_h9 = Dropout(0.15)(layer_h9)\n\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # \u5377\u79ef\u5c42\n\t\tlayer_h10 = Dropout(0.2)(layer_h10)\n\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # \u5377\u79ef\u5c42\n\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # \u6c60\u5316\u5c42\n\n\t\tlayer_h12 = Dropout(0.2)(layer_h12)\n\t\tlayer_h13 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h12) # \u5377\u79ef\u5c42","161":"Similar lines in 2 files\n==SpeechModel252:89\n==SpeechModel25:85\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.1)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\tlayer_h3 = Dropout(0.1)(layer_h3)\n\t\tlayer_h4 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h3) # \u5377\u79ef\u5c42\n\t\tlayer_h4 = Dropout(0.2)(layer_h4)\n\t\tlayer_h5 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h4) # \u5377\u79ef\u5c42\n\t\tlayer_h6 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h5) # \u6c60\u5316\u5c42\n\n\t\tlayer_h6 = Dropout(0.2)(layer_h6)\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.3)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\n\t\tlayer_h9 = Dropout(0.3)(layer_h9)\n\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # \u5377\u79ef\u5c42\n\t\tlayer_h10 = Dropout(0.4)(layer_h10)\n\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # \u5377\u79ef\u5c42\n\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # \u6c60\u5316\u5c42\n","162":"Similar lines in 9 files\n==SpeechModel24:163\n==SpeechModel251:183\n==SpeechModel251_limitless:181\n==SpeechModel251_p:185\n==SpeechModel252:189\n==SpeechModel25:172\n==SpeechModel261:198\n==SpeechModel261_p:202\n==SpeechModel26:190\n\t\tdata=DataSpeech(datapath, 'train')\n\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\n\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n\n\t\tfor epoch in range(epoch): # \u8fed\u4ee3\u8f6e\u6570\n\t\t\tprint('[running] train epoch %d .' % epoch)\n\t\t\tn_step = 0 # \u8fed\u4ee3\u6570\u636e\u6570\n\t\t\twhile True:\n\t\t\t\ttry:\n\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n\t\t\t\t\t# data_genetator\u662f\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\n\n\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n\t\t\t\t\tn_step += 1\n\t\t\t\texcept StopIteration:\n\t\t\t\t\tprint('[error] generator error. please check data format.')\n\t\t\t\t\tbreak\n\n\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n","163":"Similar lines in 2 files\n==SpeechModel251_p:130\n==SpeechModel261:147\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#ada_d = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)","164":"Similar lines in 4 files\n==SpeechModel251:132\n==SpeechModel251_limitless:130\n==SpeechModel261:147\n==SpeechModel261_p:147\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n\t\t#opt = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)","165":"Similar lines in 6 files\n==SpeechModel251:421\n==SpeechModel251_limitless:426\n==SpeechModel251_p:414\n==SpeechModel252:418\n==SpeechModel261:440\n==SpeechModel261_p:431\n\tdatapath =  abspath + ''\n\tmodelpath =  abspath + 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath =  abspath + 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\n\t#ms.LoadModel(modelpath + 'm252\\\\speech_model252_e_0_step_115500.model')","166":"Similar lines in 2 files\n==readdata24:181\n==readdata24_limitless:182\n\t\tdata_label = np.array(feat_out)\n\t\treturn data_input, data_label\n\n\tdef data_genetator(self, batch_size=32, audio_length = 1600):\n\t\t'''\n\t\t\u6570\u636e\u751f\u6210\u5668\u51fd\u6570\uff0c\u7528\u4e8eKeras\u7684generator_fit\u8bad\u7ec3\n\t\tbatch_size: \u4e00\u6b21\u4ea7\u751f\u7684\u6570\u636e\u91cf\n\t\t\u9700\u8981\u518d\u4fee\u6539\u3002\u3002\u3002\n\t\t'''\n\n\t\t#labels = []\n\t\t#for i in range(0,batch_size):\n\t\t#\t#input_length.append([1500])\n\t\t#\tlabels.append([0.0])\n\n\n\n\t\t#labels = np.array(labels, dtype = np.float)\n\t\tlabels = np.zeros((batch_size,1), dtype = np.float)\n\t\t#print(input_length,len(input_length))\n\n\t\twhile True:","167":"Similar lines in 9 files\n==SpeechModel24:226\n==SpeechModel251:256\n==SpeechModel251_limitless:254\n==SpeechModel251_p:248\n==SpeechModel252:252\n==SpeechModel25:235\n==SpeechModel261:268\n==SpeechModel261_p:265\n==SpeechModel26:253\n\t\t\tfor i in range(data_count):\n\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u5f00\u59cb\n\t\t\t\t# \u5f53\u8f93\u5165\u7684wav\u6587\u4ef6\u957f\u5ea6\u8fc7\u957f\u65f6\u81ea\u52a8\u8df3\u8fc7\u8be5\u6587\u4ef6\uff0c\u8f6c\u800c\u4f7f\u7528\u4e0b\u4e00\u4e2awav\u6587\u4ef6\u6765\u8fd0\u884c\n\t\t\t\tnum_bias = 0\n\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n\t\t\t\t\tnum_bias += 1\n\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n\t\t\t\t# \u6570\u636e\u683c\u5f0f\u51fa\u9519\u5904\u7406 \u7ed3\u675f\n\n\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] \/\/ 8)\n\n\t\t\t\twords_n = data_labels.shape[0] # \u83b7\u53d6\u6bcf\u4e2a\u53e5\u5b50\u7684\u5b57\u6570\n\t\t\t\twords_num += words_n # \u628a\u53e5\u5b50\u7684\u603b\u5b57\u6570\u52a0\u4e0a\n\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # \u83b7\u53d6\u7f16\u8f91\u8ddd\u79bb\n\t\t\t\tif(edit_distance <= words_n): # \u5f53\u7f16\u8f91\u8ddd\u79bb\u5c0f\u4e8e\u7b49\u4e8e\u53e5\u5b50\u5b57\u6570\u65f6\n\t\t\t\t\tword_error_num += edit_distance # \u4f7f\u7528\u7f16\u8f91\u8ddd\u79bb\u4f5c\u4e3a\u9519\u8bef\u5b57\u6570\n\t\t\t\telse: # \u5426\u5219\u80af\u5b9a\u662f\u589e\u52a0\u4e86\u4e00\u5806\u4e71\u4e03\u516b\u7cdf\u7684\u5947\u5947\u602a\u602a\u7684\u5b57\n\t\t\t\t\tword_error_num += words_n # \u5c31\u76f4\u63a5\u52a0\u53e5\u5b50\u672c\u6765\u7684\u603b\u5b57\u6570\u5c31\u597d\u4e86\n","168":"Similar lines in 3 files\n==SpeechModel24:133\n==SpeechModel25:142\n==SpeechModel26:160\n\t\tada_d = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n\n\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = ada_d)\n\n\n\t\t# captures output of softmax so we can decode the output during visualization\n\t\ttest_func = K.function([input_data], [y_pred])\n\n\t\tprint('[*\u63d0\u793a] \u521b\u5efa\u6a21\u578b\u6210\u529f\uff0c\u6a21\u578b\u7f16\u8bd1\u6210\u529f')\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n","169":"Similar lines in 3 files\n==SpeechModel24:23\n==SpeechModel252:23\n==SpeechModel25:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *\n\n# LSTM_CNN\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape # , Flatten,LSTM,Convolution1D,MaxPooling1D,Merge\nfrom tensorflow.keras.layers import Conv1D,LSTM,MaxPooling1D, Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D #, Merge,Conv1D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta\n\nfrom readdata24 import DataSpeech\n","170":"Similar lines in 7 files\n==SpeechModel251:132\n==SpeechModel251_limitless:130\n==SpeechModel251_p:130\n==SpeechModel252:138\n==SpeechModel261:147\n==SpeechModel261_p:147\n==SpeechModel26:140\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n\n\t\tmodel.summary()\n\n\t\t# clipnorm seems to speeds up convergence\n\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)","171":"Similar lines in 2 files\n==SpeechModel24:83\n==SpeechModel26:87\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.1)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408\n\t\tlayer_h3 = Dropout(0.2)(layer_h3)\n\t\tlayer_h4 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h3) # \u5377\u79ef\u5c42\n\t\tlayer_h4 = Dropout(0.2)(layer_h4)\n\t\tlayer_h5 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h4) # \u5377\u79ef\u5c42\n\t\tlayer_h6 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h5) # \u6c60\u5316\u5c42\n\n\t\tlayer_h6 = Dropout(0.3)(layer_h6)\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.3)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\t\t#test=Model(inputs = input_data, outputs = layer_h6)","172":"Similar lines in 3 files\n==SpeechModel24:401\n==SpeechModel25:410\n==SpeechModel26:428\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\t#ms.LoadModel(modelpath + 'm25\/speech_model25_e_0_step_545500.model')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n\t#print('*[\u63d0\u793a] \u8bed\u97f3\u8bc6\u522b\u7ed3\u679c\uff1a\\n',r)","173":"Similar lines in 9 files\n==SpeechModel24:209\n==SpeechModel251:239\n==SpeechModel251_limitless:237\n==SpeechModel251_p:231\n==SpeechModel252:235\n==SpeechModel25:218\n==SpeechModel261:251\n==SpeechModel261_p:248\n==SpeechModel26:236\n\t\tdata=DataSpeech(self.datapath, str_dataset)\n\t\t#data.LoadDataList(str_dataset)\n\t\tnum_data = data.GetDataNum() # \u83b7\u53d6\u6570\u636e\u7684\u6570\u91cf\n\t\tif(data_count <= 0 or data_count > num_data): # \u5f53data_count\u4e3a\u5c0f\u4e8e\u7b49\u4e8e0\u6216\u8005\u5927\u4e8e\u6d4b\u8bd5\u6570\u636e\u91cf\u7684\u503c\u65f6\uff0c\u5219\u4f7f\u7528\u5168\u90e8\u6570\u636e\u6765\u6d4b\u8bd5\n\t\t\tdata_count = num_data\n\n\t\ttry:\n\t\t\tran_num = random.randint(0,num_data - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\n\t\t\twords_num = 0\n\t\t\tword_error_num = 0\n\n\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n\t\t\tif(out_report == True):\n\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # \u6253\u5f00\u6587\u4ef6\u5e76\u8bfb\u5165\n","174":"Similar lines in 9 files\n==SpeechModel24:113\n==SpeechModel251:132\n==SpeechModel251_limitless:130\n==SpeechModel251_p:130\n==SpeechModel252:138\n==SpeechModel25:122\n==SpeechModel261:147\n==SpeechModel261_p:147\n==SpeechModel26:140\n\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n\t\t#model_data.summary()\n\n\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\t\t# Keras doesn't currently support loss funcs with extra parameters\n\t\t# so CTC loss is implemented in a lambda layer\n\n\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n\n\n\n\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n","175":"Similar lines in 2 files\n==SpeechModel261:32\n==SpeechModel261_p:32\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten\nfrom tensorflow.keras.layers import Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D,GRU #, Merge\nfrom tensorflow.keras.layers.merge import add, concatenate\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta, Adam\n\nfrom readdata24 import DataSpeech\n\nabspath = ''\nModelName='261'","176":"Similar lines in 2 files\n==SpeechModel251_p:23\n==SpeechModel261_p:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *\nfrom general_function.muti_gpu import *\n\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten","177":"Similar lines in 4 files\n==SpeechModel24:401\n==SpeechModel25:410\n==SpeechModel26:428\n==train_mspeech:54\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\t#ms.LoadModel(modelpath + 'm25\/speech_model25_e_0_step_545500.model')\n\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500)\n\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n\t#r = ms.RecognizeSpeech_FromFile('E:\\\\\u8bed\u97f3\u6570\u636e\u96c6\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')","178":"Similar lines in 2 files\n==test_mspeech:52\n==train_mspeech:51\nsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\nif(system_type == 'Windows'):\n\tdatapath = 'D:\\\\SpeechData'\n\tmodelpath = modelpath + '\\\\'\nelif(system_type == 'Linux'):\n\tdatapath = 'dataset'\n\tmodelpath = modelpath + '\/'\nelse:\n\tprint('*[Message] Unknown System\\n')\n\tdatapath = 'dataset'\n\tmodelpath = modelpath + '\/'\n\nms = ModelSpeech(datapath)\n","179":"Similar lines in 3 files\n==SpeechModel251:34\n==SpeechModel251_limitless:32\n==SpeechModel251_p:32\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten\nfrom tensorflow.keras.layers import Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D #, Merge\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD, Adadelta, Adam\n\nfrom readdata24 import DataSpeech\n\nabspath = ''\nModelName='251'","180":"Similar lines in 2 files\n==SpeechModel25:99\n==SpeechModel26:101\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.3)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\n\t\tlayer_h9 = Dropout(0.3)(layer_h9)\n\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # \u5377\u79ef\u5c42\n\t\tlayer_h10 = Dropout(0.4)(layer_h10)\n\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # \u5377\u79ef\u5c42\n\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # \u6c60\u5316\u5c42\n\n\t\t#test=Model(inputs = input_data, outputs = layer_h6)\n\t\t#test.summary()\n","181":"Similar lines in 5 files\n==SpeechModel24:23\n==SpeechModel252:23\n==SpeechModel25:23\n==SpeechModel261:23\n==SpeechModel26:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *\n\n# LSTM_CNN\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model","182":"Similar lines in 5 files\n==SpeechModel24:401\n==SpeechModel25:410\n==SpeechModel26:428\n==test:37\n==train_mspeech:54\n\tmodelpath = modelpath + '\\\\'\nelif(system_type == 'Linux'):\n\tdatapath = 'dataset'\n\tmodelpath = modelpath + '\/'\nelse:\n\tprint('*[Message] Unknown System\\n')\n\tdatapath = 'dataset'\n\tmodelpath = modelpath + '\/'\n\nms = ModelSpeech(datapath)\n\n#ms.LoadModel(modelpath + 'm22_2\\\\0\\\\speech_model22_e_0_step_257000.h5')","183":"Similar lines in 2 files\n==SpeechModel252:103\n==SpeechModel26:101\n\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # \u5377\u79ef\u5c42\n\t\tlayer_h7 = Dropout(0.3)(layer_h7)\n\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # \u5377\u79ef\u5c42\n\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # \u6c60\u5316\u5c42\n\n\t\tlayer_h9 = Dropout(0.3)(layer_h9)\n\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # \u5377\u79ef\u5c42\n\t\tlayer_h10 = Dropout(0.4)(layer_h10)\n\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # \u5377\u79ef\u5c42\n\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # \u6c60\u5316\u5c42\n","184":"Similar lines in 5 files\n==SpeechModel24:401\n==SpeechModel25:410\n==SpeechModel26:428\n==test:37\n==test_mspeech:55\n\tmodelpath = modelpath + '\\\\'\nelif(system_type == 'Linux'):\n\tdatapath = 'dataset'\n\tmodelpath = modelpath + '\/'\nelse:\n\tprint('*[Message] Unknown System\\n')\n\tdatapath = 'dataset'\n\tmodelpath = modelpath + '\/'\n\nms = ModelSpeech(datapath)\n","185":"Similar lines in 9 files\n==SpeechModel24:143\n==SpeechModel251:163\n==SpeechModel251_limitless:161\n==SpeechModel251_p:165\n==SpeechModel252:169\n==SpeechModel25:152\n==SpeechModel261:178\n==SpeechModel261_p:182\n==SpeechModel26:170\n\t\treturn model, model_data\n\n\tdef ctc_lambda_func(self, args):\n\t\ty_pred, labels, input_length, label_length = args\n\n\t\ty_pred = y_pred[:, :, :]\n\t\t#y_pred = y_pred[:, 2:, :]\n\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\n\n","186":"Similar lines in 2 files\n==readdata24:208\n==readdata24_limitless:211\n\t\t\tinput_length = []\n\t\t\tlabel_length = []\n\n\n\n\t\t\tfor i in range(batch_size):\n\t\t\t\tran_num = random.randint(0,self.DataNum - 1) # \u83b7\u53d6\u4e00\u4e2a\u968f\u673a\u6570\n\t\t\t\tdata_input, data_labels = self.GetData(ran_num)  # \u901a\u8fc7\u968f\u673a\u6570\u53d6\u4e00\u4e2a\u6570\u636e\n\t\t\t\t#data_input, data_labels = self.GetData((ran_num + i) % self.DataNum)  # \u4ece\u968f\u673a\u6570\u5f00\u59cb\u8fde\u7eed\u5411\u540e\u53d6\u4e00\u5b9a\u6570\u91cf\u6570\u636e\n","187":"Similar lines in 3 files\n==SpeechModel261:130\n==SpeechModel261_p:130\n==SpeechModel26:123\n\t\trnn_size=128\n\t\tgru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n\t\tgru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n\t\tgru1_merged = add([gru_1, gru_1b])\n\t\tgru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n\t\tgru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n\n\t\tgru2 = concatenate([gru_2, gru_2b])\n","188":"Similar lines in 9 files\n==SpeechModel251:434\n==SpeechModel251_limitless:439\n==SpeechModel251_p:427\n==SpeechModel252:431\n==SpeechModel261:453\n==SpeechModel261_p:444\n==SpeechModel26:431\n==test:40\n==train_mspeech:57\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n","189":"Similar lines in 4 files\n==SpeechModel24:391\n==SpeechModel25:400\n==SpeechModel26:418\n==test_mspeech:45\n\tdatapath = ''\n\tmodelpath = 'model_speech'\n\n\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):","190":"Similar lines in 6 files\n==SpeechModel24:251\n==SpeechModel251_p:273\n==SpeechModel252:277\n==SpeechModel25:260\n==SpeechModel261_p:290\n==SpeechModel26:278\n\t\t\t\ttxt = ''\n\t\t\t\tif(out_report == True):\n\t\t\t\t\ttxt += str(i) + '\\n'\n\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n\t\t\t\t\ttxt += '\\n'\n\t\t\t\t\ttxt_obj.write(txt)\n\n","191":"Similar lines in 6 files\n==SpeechModel24:23\n==SpeechModel251:24\n==SpeechModel252:23\n==SpeechModel25:23\n==SpeechModel261:23\n==SpeechModel26:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *\n\n# LSTM_CNN","192":"Similar lines in 7 files\n==SpeechModel251:434\n==SpeechModel251_limitless:439\n==SpeechModel251_p:427\n==SpeechModel252:431\n==SpeechModel261:453\n==SpeechModel261_p:444\n==test_mspeech:58\n\t\tmodelpath = modelpath + '\/'\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n","193":"Similar lines in 8 files\n==SpeechModel251:425\n==SpeechModel251_limitless:430\n==SpeechModel251_p:418\n==SpeechModel252:422\n==SpeechModel25:404\n==SpeechModel261:444\n==SpeechModel261_p:435\n==SpeechModel26:422\n\tif(not os.path.exists(modelpath)): # \u5224\u65ad\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\u662f\u5426\u5b58\u5728\n\t\tos.makedirs(modelpath) # \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5c31\u65b0\u5efa\u4e00\u4e2a\uff0c\u907f\u514d\u4e4b\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u65f6\u5019\u70b8\u6389\n\n\tsystem_type = plat.system() # \u7531\u4e8e\u4e0d\u540c\u7684\u7cfb\u7edf\u7684\u6587\u4ef6\u8def\u5f84\u8868\u793a\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u8fdb\u884c\u5224\u65ad\n\tif(system_type == 'Windows'):\n\t\tdatapath = 'E:\\\\\u8bed\u97f3\u6570\u636e\u96c6'\n\t\tmodelpath = modelpath + '\\\\'\n\telif(system_type == 'Linux'):","194":"Similar lines in 7 files\n==SpeechModel24:23\n==SpeechModel251:24\n==SpeechModel251_limitless:24\n==SpeechModel252:23\n==SpeechModel25:23\n==SpeechModel261:23\n==SpeechModel26:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *\n","195":"Similar lines in 9 files\n==SpeechModel24:405\n==SpeechModel251:435\n==SpeechModel251_limitless:440\n==SpeechModel251_p:428\n==SpeechModel252:432\n==SpeechModel25:414\n==SpeechModel261:454\n==SpeechModel261_p:445\n==SpeechModel26:432\n\telse:\n\t\tprint('*[Message] Unknown System\\n')\n\t\tdatapath = 'dataset'\n\t\tmodelpath = modelpath + '\/'\n\n\tms = ModelSpeech(datapath)\n\n\t#ms.LoadModel(modelpath + 'm25\/speech_model25_e_0_step_545500.model')","196":"Similar lines in 11 files\n==SpeechModel24:61\n==SpeechModel251:67\n==SpeechModel251_limitless:65\n==SpeechModel251_p:65\n==SpeechModel252:64\n==SpeechModel25:61\n==SpeechModel261:66\n==SpeechModel261_p:66\n==SpeechModel26:62\n==readdata24:47\n==readdata24_limitless:51\n\t\tif(system_type == 'Windows'):\n\t\t\tself.slash='\\\\' # \u53cd\u659c\u6760\n\t\telif(system_type == 'Linux'):\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760\n\t\telse:\n\t\t\tprint('*[Message] Unknown System\\n')\n\t\t\tself.slash='\/' # \u6b63\u659c\u6760","197":"Similar lines in 9 files\n==SpeechModel24:23\n==SpeechModel251:24\n==SpeechModel251_limitless:24\n==SpeechModel251_p:23\n==SpeechModel252:23\n==SpeechModel25:23\n==SpeechModel261:23\n==SpeechModel261_p:23\n==SpeechModel26:23\nimport platform as plat\nimport os\nimport time\n\nfrom general_function.file_wav import *\nfrom general_function.file_dict import *\nfrom general_function.gen_func import *","198":"Similar lines in 4 files\n==SpeechModel24:83\n==SpeechModel252:89\n==SpeechModel25:85\n==SpeechModel26:87\n\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n\n\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # \u5377\u79ef\u5c42\n\t\tlayer_h1 = Dropout(0.1)(layer_h1)\n\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # \u5377\u79ef\u5c42\n\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # \u6c60\u5316\u5c42\n\t\t#layer_h3 = Dropout(0.2)(layer_h2) # \u968f\u673a\u4e2d\u65ad\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u8fde\u63a5\uff0c\u9632\u6b62\u8fc7\u62df\u5408","199":"Similar lines in 5 files\n==SpeechModel251:34\n==SpeechModel251_limitless:32\n==SpeechModel251_p:32\n==SpeechModel261:32\n==SpeechModel261_p:32\nimport tensorflow.keras as kr\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten"},"number":{"0":"C0200","1":"R1732","2":"R1732","3":"R1732","4":"W0201","5":"W0201","6":"W0201","7":"W0201","8":"C0200","9":"R1732","10":"R1732","11":"R1732","12":"W0201","13":"W0201","14":"W0201","15":"W0201","16":"W0401","17":"W0401","18":"W0401","19":"R1732","20":"C0121","21":"R1732","22":"C0121","23":"C0121","24":"C0121","25":"W0401","26":"W0401","27":"W0401","28":"R1732","29":"C0121","30":"R1732","31":"C0121","32":"C0121","33":"C0121","34":"W0401","35":"W0401","36":"W0401","37":"R1732","38":"C0121","39":"R1732","40":"C0121","41":"C0121","42":"C0121","43":"W0401","44":"W0401","45":"W0401","46":"R1732","47":"C0121","48":"R1732","49":"C0121","50":"C0121","51":"C0121","52":"W0401","53":"W0401","54":"W0401","55":"W0401","56":"R1732","57":"C0121","58":"R1732","59":"C0121","60":"C0121","61":"C0121","62":"W0401","63":"W0401","64":"W0401","65":"R1732","66":"C0121","67":"R1732","68":"C0121","69":"C0121","70":"C0121","71":"W0401","72":"W0401","73":"W0401","74":"R1732","75":"C0121","76":"R1732","77":"C0121","78":"C0121","79":"C0121","80":"W0401","81":"W0401","82":"W0401","83":"R1732","84":"C0121","85":"R1732","86":"C0121","87":"C0121","88":"C0121","89":"W0401","90":"W0401","91":"W0401","92":"W0401","93":"R1732","94":"C0121","95":"R1732","96":"C0121","97":"C0121","98":"C0121","99":"W0201","100":"W0401","101":"W0401","102":"W0622","103":"R1732","104":"W0401","105":"W0401","106":"W0622","107":"R1732","108":"W0401","109":"R0801","110":"R0801","111":"R0801","112":"R0801","113":"R0801","114":"R0801","115":"R0801","116":"R0801","117":"R0801","118":"R0801","119":"R0801","120":"R0801","121":"R0801","122":"R0801","123":"R0801","124":"R0801","125":"R0801","126":"R0801","127":"R0801","128":"R0801","129":"R0801","130":"R0801","131":"R0801","132":"R0801","133":"R0801","134":"R0801","135":"R0801","136":"R0801","137":"R0801","138":"R0801","139":"R0801","140":"R0801","141":"R0801","142":"R0801","143":"R0801","144":"R0801","145":"R0801","146":"R0801","147":"R0801","148":"R0801","149":"R0801","150":"R0801","151":"R0801","152":"R0801","153":"R0801","154":"R0801","155":"R0801","156":"R0801","157":"R0801","158":"R0801","159":"R0801","160":"R0801","161":"R0801","162":"R0801","163":"R0801","164":"R0801","165":"R0801","166":"R0801","167":"R0801","168":"R0801","169":"R0801","170":"R0801","171":"R0801","172":"R0801","173":"R0801","174":"R0801","175":"R0801","176":"R0801","177":"R0801","178":"R0801","179":"R0801","180":"R0801","181":"R0801","182":"R0801","183":"R0801","184":"R0801","185":"R0801","186":"R0801","187":"R0801","188":"R0801","189":"R0801","190":"R0801","191":"R0801","192":"R0801","193":"R0801","194":"R0801","195":"R0801","196":"R0801","197":"R0801","198":"R0801","199":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint","36":"pylint","37":"pylint","38":"pylint","39":"pylint","40":"pylint","41":"pylint","42":"pylint","43":"pylint","44":"pylint","45":"pylint","46":"pylint","47":"pylint","48":"pylint","49":"pylint","50":"pylint","51":"pylint","52":"pylint","53":"pylint","54":"pylint","55":"pylint","56":"pylint","57":"pylint","58":"pylint","59":"pylint","60":"pylint","61":"pylint","62":"pylint","63":"pylint","64":"pylint","65":"pylint","66":"pylint","67":"pylint","68":"pylint","69":"pylint","70":"pylint","71":"pylint","72":"pylint","73":"pylint","74":"pylint","75":"pylint","76":"pylint","77":"pylint","78":"pylint","79":"pylint","80":"pylint","81":"pylint","82":"pylint","83":"pylint","84":"pylint","85":"pylint","86":"pylint","87":"pylint","88":"pylint","89":"pylint","90":"pylint","91":"pylint","92":"pylint","93":"pylint","94":"pylint","95":"pylint","96":"pylint","97":"pylint","98":"pylint","99":"pylint","100":"pylint","101":"pylint","102":"pylint","103":"pylint","104":"pylint","105":"pylint","106":"pylint","107":"pylint","108":"pylint","109":"pylint","110":"pylint","111":"pylint","112":"pylint","113":"pylint","114":"pylint","115":"pylint","116":"pylint","117":"pylint","118":"pylint","119":"pylint","120":"pylint","121":"pylint","122":"pylint","123":"pylint","124":"pylint","125":"pylint","126":"pylint","127":"pylint","128":"pylint","129":"pylint","130":"pylint","131":"pylint","132":"pylint","133":"pylint","134":"pylint","135":"pylint","136":"pylint","137":"pylint","138":"pylint","139":"pylint","140":"pylint","141":"pylint","142":"pylint","143":"pylint","144":"pylint","145":"pylint","146":"pylint","147":"pylint","148":"pylint","149":"pylint","150":"pylint","151":"pylint","152":"pylint","153":"pylint","154":"pylint","155":"pylint","156":"pylint","157":"pylint","158":"pylint","159":"pylint","160":"pylint","161":"pylint","162":"pylint","163":"pylint","164":"pylint","165":"pylint","166":"pylint","167":"pylint","168":"pylint","169":"pylint","170":"pylint","171":"pylint","172":"pylint","173":"pylint","174":"pylint","175":"pylint","176":"pylint","177":"pylint","178":"pylint","179":"pylint","180":"pylint","181":"pylint","182":"pylint","183":"pylint","184":"pylint","185":"pylint","186":"pylint","187":"pylint","188":"pylint","189":"pylint","190":"pylint","191":"pylint","192":"pylint","193":"pylint","194":"pylint","195":"pylint","196":"pylint","197":"pylint","198":"pylint","199":"pylint"},"lines_amount":{"0":264,"1":264,"2":264,"3":264,"4":264,"5":264,"6":264,"7":264,"8":268,"9":268,"10":268,"11":268,"12":268,"13":268,"14":268,"15":268,"16":421,"17":421,"18":421,"19":421,"20":421,"21":421,"22":421,"23":421,"24":421,"25":430,"26":430,"27":430,"28":430,"29":430,"30":430,"31":430,"32":430,"33":430,"34":458,"35":458,"36":458,"37":458,"38":458,"39":458,"40":458,"41":458,"42":458,"43":463,"44":463,"45":463,"46":463,"47":463,"48":463,"49":463,"50":463,"51":463,"52":445,"53":445,"54":445,"55":445,"56":445,"57":445,"58":445,"59":445,"60":445,"61":445,"62":449,"63":449,"64":449,"65":449,"66":449,"67":449,"68":449,"69":449,"70":449,"71":448,"72":448,"73":448,"74":448,"75":448,"76":448,"77":448,"78":448,"79":448,"80":477,"81":477,"82":477,"83":477,"84":477,"85":477,"86":477,"87":477,"88":477,"89":462,"90":462,"91":462,"92":462,"93":462,"94":462,"95":462,"96":462,"97":462,"98":462,"99":154,"100":298,"101":298,"102":298,"103":298,"104":303,"105":303,"106":303,"107":303,"108":45,"109":70,"110":70,"111":70,"112":70,"113":70,"114":70,"115":70,"116":70,"117":70,"118":70,"119":70,"120":70,"121":70,"122":70,"123":70,"124":70,"125":70,"126":70,"127":70,"128":70,"129":70,"130":70,"131":70,"132":70,"133":70,"134":70,"135":70,"136":70,"137":70,"138":70,"139":70,"140":70,"141":70,"142":70,"143":70,"144":70,"145":70,"146":70,"147":70,"148":70,"149":70,"150":70,"151":70,"152":70,"153":70,"154":70,"155":70,"156":70,"157":70,"158":70,"159":70,"160":70,"161":70,"162":70,"163":70,"164":70,"165":70,"166":70,"167":70,"168":70,"169":70,"170":70,"171":70,"172":70,"173":70,"174":70,"175":70,"176":70,"177":70,"178":70,"179":70,"180":70,"181":70,"182":70,"183":70,"184":70,"185":70,"186":70,"187":70,"188":70,"189":70,"190":70,"191":70,"192":70,"193":70,"194":70,"195":70,"196":70,"197":70,"198":70,"199":70},"commit":{"0":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","1":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","2":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","3":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","4":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","5":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","6":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","7":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","8":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","9":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","10":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","11":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","12":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","13":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","14":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","15":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","16":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","17":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","18":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","19":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","20":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","21":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","22":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","23":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","24":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","25":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","26":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","27":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","28":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","29":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","30":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","31":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","32":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","33":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","34":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","35":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","36":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","37":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","38":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","39":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","40":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","41":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","42":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","43":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","44":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","45":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","46":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","47":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","48":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","49":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","50":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","51":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","52":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","53":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","54":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","55":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","56":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","57":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","58":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","59":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","60":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","61":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","62":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","63":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","64":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","65":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","66":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","67":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","68":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","69":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","70":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","71":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","72":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","73":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","74":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","75":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","76":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","77":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","78":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","79":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","80":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","81":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","82":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","83":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","84":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","85":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","86":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","87":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","88":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","89":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","90":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","91":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","92":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","93":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","94":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","95":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","96":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","97":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","98":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","99":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","100":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","101":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","102":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","103":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","104":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","105":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","106":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","107":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","108":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","109":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","110":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","111":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","112":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","113":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","114":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","115":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","116":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","117":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","118":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","119":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","120":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","121":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","122":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","123":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","124":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","125":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","126":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","127":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","128":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","129":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","130":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","131":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","132":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","133":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","134":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","135":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","136":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","137":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","138":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","139":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","140":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","141":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","142":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","143":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","144":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","145":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","146":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","147":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","148":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","149":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","150":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","151":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","152":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","153":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","154":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","155":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","156":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","157":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","158":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","159":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","160":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","161":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","162":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","163":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","164":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","165":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","166":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","167":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","168":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","169":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","170":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","171":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","172":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","173":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","174":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","175":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","176":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","177":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","178":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","179":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","180":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","181":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","182":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","183":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","184":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","185":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","186":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","187":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","188":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","189":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","190":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","191":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","192":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","193":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","194":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","195":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","196":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","197":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","198":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca","199":"bcd919147ec8f3964c89eee2e6a27eef6f85ddca"},"repo":{"0":"nl8590687\/ASRT_SpeechRecognition","1":"nl8590687\/ASRT_SpeechRecognition","2":"nl8590687\/ASRT_SpeechRecognition","3":"nl8590687\/ASRT_SpeechRecognition","4":"nl8590687\/ASRT_SpeechRecognition","5":"nl8590687\/ASRT_SpeechRecognition","6":"nl8590687\/ASRT_SpeechRecognition","7":"nl8590687\/ASRT_SpeechRecognition","8":"nl8590687\/ASRT_SpeechRecognition","9":"nl8590687\/ASRT_SpeechRecognition","10":"nl8590687\/ASRT_SpeechRecognition","11":"nl8590687\/ASRT_SpeechRecognition","12":"nl8590687\/ASRT_SpeechRecognition","13":"nl8590687\/ASRT_SpeechRecognition","14":"nl8590687\/ASRT_SpeechRecognition","15":"nl8590687\/ASRT_SpeechRecognition","16":"nl8590687\/ASRT_SpeechRecognition","17":"nl8590687\/ASRT_SpeechRecognition","18":"nl8590687\/ASRT_SpeechRecognition","19":"nl8590687\/ASRT_SpeechRecognition","20":"nl8590687\/ASRT_SpeechRecognition","21":"nl8590687\/ASRT_SpeechRecognition","22":"nl8590687\/ASRT_SpeechRecognition","23":"nl8590687\/ASRT_SpeechRecognition","24":"nl8590687\/ASRT_SpeechRecognition","25":"nl8590687\/ASRT_SpeechRecognition","26":"nl8590687\/ASRT_SpeechRecognition","27":"nl8590687\/ASRT_SpeechRecognition","28":"nl8590687\/ASRT_SpeechRecognition","29":"nl8590687\/ASRT_SpeechRecognition","30":"nl8590687\/ASRT_SpeechRecognition","31":"nl8590687\/ASRT_SpeechRecognition","32":"nl8590687\/ASRT_SpeechRecognition","33":"nl8590687\/ASRT_SpeechRecognition","34":"nl8590687\/ASRT_SpeechRecognition","35":"nl8590687\/ASRT_SpeechRecognition","36":"nl8590687\/ASRT_SpeechRecognition","37":"nl8590687\/ASRT_SpeechRecognition","38":"nl8590687\/ASRT_SpeechRecognition","39":"nl8590687\/ASRT_SpeechRecognition","40":"nl8590687\/ASRT_SpeechRecognition","41":"nl8590687\/ASRT_SpeechRecognition","42":"nl8590687\/ASRT_SpeechRecognition","43":"nl8590687\/ASRT_SpeechRecognition","44":"nl8590687\/ASRT_SpeechRecognition","45":"nl8590687\/ASRT_SpeechRecognition","46":"nl8590687\/ASRT_SpeechRecognition","47":"nl8590687\/ASRT_SpeechRecognition","48":"nl8590687\/ASRT_SpeechRecognition","49":"nl8590687\/ASRT_SpeechRecognition","50":"nl8590687\/ASRT_SpeechRecognition","51":"nl8590687\/ASRT_SpeechRecognition","52":"nl8590687\/ASRT_SpeechRecognition","53":"nl8590687\/ASRT_SpeechRecognition","54":"nl8590687\/ASRT_SpeechRecognition","55":"nl8590687\/ASRT_SpeechRecognition","56":"nl8590687\/ASRT_SpeechRecognition","57":"nl8590687\/ASRT_SpeechRecognition","58":"nl8590687\/ASRT_SpeechRecognition","59":"nl8590687\/ASRT_SpeechRecognition","60":"nl8590687\/ASRT_SpeechRecognition","61":"nl8590687\/ASRT_SpeechRecognition","62":"nl8590687\/ASRT_SpeechRecognition","63":"nl8590687\/ASRT_SpeechRecognition","64":"nl8590687\/ASRT_SpeechRecognition","65":"nl8590687\/ASRT_SpeechRecognition","66":"nl8590687\/ASRT_SpeechRecognition","67":"nl8590687\/ASRT_SpeechRecognition","68":"nl8590687\/ASRT_SpeechRecognition","69":"nl8590687\/ASRT_SpeechRecognition","70":"nl8590687\/ASRT_SpeechRecognition","71":"nl8590687\/ASRT_SpeechRecognition","72":"nl8590687\/ASRT_SpeechRecognition","73":"nl8590687\/ASRT_SpeechRecognition","74":"nl8590687\/ASRT_SpeechRecognition","75":"nl8590687\/ASRT_SpeechRecognition","76":"nl8590687\/ASRT_SpeechRecognition","77":"nl8590687\/ASRT_SpeechRecognition","78":"nl8590687\/ASRT_SpeechRecognition","79":"nl8590687\/ASRT_SpeechRecognition","80":"nl8590687\/ASRT_SpeechRecognition","81":"nl8590687\/ASRT_SpeechRecognition","82":"nl8590687\/ASRT_SpeechRecognition","83":"nl8590687\/ASRT_SpeechRecognition","84":"nl8590687\/ASRT_SpeechRecognition","85":"nl8590687\/ASRT_SpeechRecognition","86":"nl8590687\/ASRT_SpeechRecognition","87":"nl8590687\/ASRT_SpeechRecognition","88":"nl8590687\/ASRT_SpeechRecognition","89":"nl8590687\/ASRT_SpeechRecognition","90":"nl8590687\/ASRT_SpeechRecognition","91":"nl8590687\/ASRT_SpeechRecognition","92":"nl8590687\/ASRT_SpeechRecognition","93":"nl8590687\/ASRT_SpeechRecognition","94":"nl8590687\/ASRT_SpeechRecognition","95":"nl8590687\/ASRT_SpeechRecognition","96":"nl8590687\/ASRT_SpeechRecognition","97":"nl8590687\/ASRT_SpeechRecognition","98":"nl8590687\/ASRT_SpeechRecognition","99":"nl8590687\/ASRT_SpeechRecognition","100":"nl8590687\/ASRT_SpeechRecognition","101":"nl8590687\/ASRT_SpeechRecognition","102":"nl8590687\/ASRT_SpeechRecognition","103":"nl8590687\/ASRT_SpeechRecognition","104":"nl8590687\/ASRT_SpeechRecognition","105":"nl8590687\/ASRT_SpeechRecognition","106":"nl8590687\/ASRT_SpeechRecognition","107":"nl8590687\/ASRT_SpeechRecognition","108":"nl8590687\/ASRT_SpeechRecognition","109":"nl8590687\/ASRT_SpeechRecognition","110":"nl8590687\/ASRT_SpeechRecognition","111":"nl8590687\/ASRT_SpeechRecognition","112":"nl8590687\/ASRT_SpeechRecognition","113":"nl8590687\/ASRT_SpeechRecognition","114":"nl8590687\/ASRT_SpeechRecognition","115":"nl8590687\/ASRT_SpeechRecognition","116":"nl8590687\/ASRT_SpeechRecognition","117":"nl8590687\/ASRT_SpeechRecognition","118":"nl8590687\/ASRT_SpeechRecognition","119":"nl8590687\/ASRT_SpeechRecognition","120":"nl8590687\/ASRT_SpeechRecognition","121":"nl8590687\/ASRT_SpeechRecognition","122":"nl8590687\/ASRT_SpeechRecognition","123":"nl8590687\/ASRT_SpeechRecognition","124":"nl8590687\/ASRT_SpeechRecognition","125":"nl8590687\/ASRT_SpeechRecognition","126":"nl8590687\/ASRT_SpeechRecognition","127":"nl8590687\/ASRT_SpeechRecognition","128":"nl8590687\/ASRT_SpeechRecognition","129":"nl8590687\/ASRT_SpeechRecognition","130":"nl8590687\/ASRT_SpeechRecognition","131":"nl8590687\/ASRT_SpeechRecognition","132":"nl8590687\/ASRT_SpeechRecognition","133":"nl8590687\/ASRT_SpeechRecognition","134":"nl8590687\/ASRT_SpeechRecognition","135":"nl8590687\/ASRT_SpeechRecognition","136":"nl8590687\/ASRT_SpeechRecognition","137":"nl8590687\/ASRT_SpeechRecognition","138":"nl8590687\/ASRT_SpeechRecognition","139":"nl8590687\/ASRT_SpeechRecognition","140":"nl8590687\/ASRT_SpeechRecognition","141":"nl8590687\/ASRT_SpeechRecognition","142":"nl8590687\/ASRT_SpeechRecognition","143":"nl8590687\/ASRT_SpeechRecognition","144":"nl8590687\/ASRT_SpeechRecognition","145":"nl8590687\/ASRT_SpeechRecognition","146":"nl8590687\/ASRT_SpeechRecognition","147":"nl8590687\/ASRT_SpeechRecognition","148":"nl8590687\/ASRT_SpeechRecognition","149":"nl8590687\/ASRT_SpeechRecognition","150":"nl8590687\/ASRT_SpeechRecognition","151":"nl8590687\/ASRT_SpeechRecognition","152":"nl8590687\/ASRT_SpeechRecognition","153":"nl8590687\/ASRT_SpeechRecognition","154":"nl8590687\/ASRT_SpeechRecognition","155":"nl8590687\/ASRT_SpeechRecognition","156":"nl8590687\/ASRT_SpeechRecognition","157":"nl8590687\/ASRT_SpeechRecognition","158":"nl8590687\/ASRT_SpeechRecognition","159":"nl8590687\/ASRT_SpeechRecognition","160":"nl8590687\/ASRT_SpeechRecognition","161":"nl8590687\/ASRT_SpeechRecognition","162":"nl8590687\/ASRT_SpeechRecognition","163":"nl8590687\/ASRT_SpeechRecognition","164":"nl8590687\/ASRT_SpeechRecognition","165":"nl8590687\/ASRT_SpeechRecognition","166":"nl8590687\/ASRT_SpeechRecognition","167":"nl8590687\/ASRT_SpeechRecognition","168":"nl8590687\/ASRT_SpeechRecognition","169":"nl8590687\/ASRT_SpeechRecognition","170":"nl8590687\/ASRT_SpeechRecognition","171":"nl8590687\/ASRT_SpeechRecognition","172":"nl8590687\/ASRT_SpeechRecognition","173":"nl8590687\/ASRT_SpeechRecognition","174":"nl8590687\/ASRT_SpeechRecognition","175":"nl8590687\/ASRT_SpeechRecognition","176":"nl8590687\/ASRT_SpeechRecognition","177":"nl8590687\/ASRT_SpeechRecognition","178":"nl8590687\/ASRT_SpeechRecognition","179":"nl8590687\/ASRT_SpeechRecognition","180":"nl8590687\/ASRT_SpeechRecognition","181":"nl8590687\/ASRT_SpeechRecognition","182":"nl8590687\/ASRT_SpeechRecognition","183":"nl8590687\/ASRT_SpeechRecognition","184":"nl8590687\/ASRT_SpeechRecognition","185":"nl8590687\/ASRT_SpeechRecognition","186":"nl8590687\/ASRT_SpeechRecognition","187":"nl8590687\/ASRT_SpeechRecognition","188":"nl8590687\/ASRT_SpeechRecognition","189":"nl8590687\/ASRT_SpeechRecognition","190":"nl8590687\/ASRT_SpeechRecognition","191":"nl8590687\/ASRT_SpeechRecognition","192":"nl8590687\/ASRT_SpeechRecognition","193":"nl8590687\/ASRT_SpeechRecognition","194":"nl8590687\/ASRT_SpeechRecognition","195":"nl8590687\/ASRT_SpeechRecognition","196":"nl8590687\/ASRT_SpeechRecognition","197":"nl8590687\/ASRT_SpeechRecognition","198":"nl8590687\/ASRT_SpeechRecognition","199":"nl8590687\/ASRT_SpeechRecognition"}}
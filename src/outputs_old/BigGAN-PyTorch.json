{"type":{"0":"W","1":"W","2":"R","3":"R","4":"R","5":"C","6":"W","7":"W","8":"W","9":"W","10":"W","11":"W","12":"W","13":"W","14":"W","15":"R","16":"R","17":"R","18":"R","19":"R","20":"R","21":"R","22":"R","23":"R","24":"R","25":"R","26":"R","27":"R","28":"R","29":"R","30":"R","31":"R","32":"R","33":"R","34":"R","35":"R"},"module":{"0":"datasets","1":"datasets","2":"datasets","3":"datasets","4":"inception_tf13","5":"inception_utils","6":"layers","7":"utils","8":"utils","9":"utils","10":"utils","11":"utils","12":"utils","13":"utils","14":"utils","15":"utils","16":"utils","17":"utils","18":"utils","19":"utils","20":"utils","21":"utils","22":"utils","23":"utils","24":"utils","25":"utils","26":"utils","27":"utils","28":"utils","29":"utils","30":"utils","31":"utils","32":"utils","33":"utils","34":"utils","35":"utils"},"obj":{"0":"find_classes","1":"make_dataset","2":"CIFAR10.__init__","3":"CIFAR10.__init__","4":"run._init_inception","5":"accumulate_inception_activations","6":"identity.forward","7":"ortho","8":"default_ortho","9":"Distribution.init_distribution","10":"Distribution.init_distribution","11":"Distribution.init_distribution","12":"Distribution.init_distribution","13":"Distribution.init_distribution","14":"Distribution.to","15":"","16":"","17":"","18":"","19":"","20":"","21":"","22":"","23":"","24":"","25":"","26":"","27":"","28":"","29":"","30":"","31":"","32":"","33":"","34":"","35":""},"lnum":{"0":33,"1":40,"2":268,"3":312,"4":92,"5":250,"6":55,"7":646,"8":661,"9":1062,"10":1063,"11":1065,"12":1065,"13":1067,"14":1081,"15":1,"16":1,"17":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1},"col":{"0":17,"1":17,"2":11,"3":11,"4":4,"5":42,"6":20,"7":0,"8":0,"9":4,"10":4,"11":6,"12":17,"13":6,"14":4,"15":0,"16":0,"17":0,"18":0,"19":0,"20":0,"21":0,"22":0,"23":0,"24":0,"25":0,"26":0,"27":0,"28":0,"29":0,"30":0,"31":0,"32":0,"33":0,"34":0,"35":0},"filename":{"0":"datasets.py","1":"datasets.py","2":"datasets.py","3":"datasets.py","4":"inception_tf13.py","5":"inception_utils.py","6":"layers.py","7":"utils.py","8":"utils.py","9":"utils.py","10":"utils.py","11":"utils.py","12":"utils.py","13":"utils.py","14":"utils.py","15":"utils.py","16":"utils.py","17":"utils.py","18":"utils.py","19":"utils.py","20":"utils.py","21":"utils.py","22":"utils.py","23":"utils.py","24":"utils.py","25":"utils.py","26":"utils.py","27":"utils.py","28":"utils.py","29":"utils.py","30":"utils.py","31":"utils.py","32":"utils.py","33":"utils.py","34":"utils.py","35":"utils.py"},"symbol":{"0":"redefined-builtin","1":"redefined-builtin","2":"consider-using-with","3":"consider-using-with","4":"consider-using-with","5":"len-as-condition","6":"redefined-builtin","7":"dangerous-default-value","8":"dangerous-default-value","9":"attribute-defined-outside-init","10":"attribute-defined-outside-init","11":"attribute-defined-outside-init","12":"attribute-defined-outside-init","13":"attribute-defined-outside-init","14":"attribute-defined-outside-init","15":"duplicate-code","16":"duplicate-code","17":"duplicate-code","18":"duplicate-code","19":"duplicate-code","20":"duplicate-code","21":"duplicate-code","22":"duplicate-code","23":"duplicate-code","24":"duplicate-code","25":"duplicate-code","26":"duplicate-code","27":"duplicate-code","28":"duplicate-code","29":"duplicate-code","30":"duplicate-code","31":"duplicate-code","32":"duplicate-code","33":"duplicate-code","34":"duplicate-code","35":"duplicate-code"},"text":{"0":"Redefining built-in 'dir'","1":"Redefining built-in 'dir'","2":"Consider using 'with' for resource-allocating operations","3":"Consider using 'with' for resource-allocating operations","4":"Consider using 'with' for resource-allocating operations","5":"Do not use `len(SEQUENCE)` without comparison to determine if a sequence is empty","6":"Redefining built-in 'input'","7":"Dangerous default value [] as argument","8":"Dangerous default value [] as argument","9":"Attribute 'dist_type' defined outside __init__","10":"Attribute 'dist_kwargs' defined outside __init__","11":"Attribute 'mean' defined outside __init__","12":"Attribute 'var' defined outside __init__","13":"Attribute 'num_categories' defined outside __init__","14":"Attribute 'data' defined outside __init__","15":"Similar lines in 2 files\n==BigGAN:168\n==BigGANdeep:202\n      if self.arch['attention'][self.arch['resolution'][index]]:\n        print('Adding attention layer in G at resolution %d' % self.arch['resolution'][index])\n        self.blocks[-1] += [layers.Attention(self.arch['out_channels'][index], self.which_conv)]\n\n    # Turn self.blocks into a ModuleList so that it's all properly registered.\n    self.blocks = nn.ModuleList([nn.ModuleList(block) for block in self.blocks])\n\n    # output layer: batchnorm-relu-conv.\n    # Consider using a non-spectral conv here\n    self.output_layer = nn.Sequential(layers.bn(self.arch['out_channels'][-1],\n                                                cross_replica=self.cross_replica,\n                                                mybn=self.mybn),\n                                    self.activation,\n                                    self.which_conv(self.arch['out_channels'][-1], 3))\n\n    # Initialize weights. Optionally skip init for testing.\n    if not skip_init:\n      self.init_weights()\n\n    # Set up optimizer\n    # If this is an EMA copy, no need for an optim, so just return now\n    if no_optim:\n      return\n    self.lr, self.B1, self.B2, self.adam_eps = G_lr, G_B1, G_B2, adam_eps\n    if G_mixed_precision:\n      print('Using fp16 adam in G...')\n      import utils\n      self.optim = utils.Adam16(params=self.parameters(), lr=self.lr,\n                           betas=(self.B1, self.B2), weight_decay=0,\n                           eps=self.adam_eps)\n    else:\n      self.optim = optim.Adam(params=self.parameters(), lr=self.lr,\n                           betas=(self.B1, self.B2), weight_decay=0,\n                           eps=self.adam_eps)\n\n    # LR scheduling, left here for forward compatibility\n    # self.lr_sched = {'itr' : 0}# if self.progressive else {}\n    # self.j = 0\n\n  # Initialize\n  def init_weights(self):\n    self.param_count = 0\n    for module in self.modules():\n      if (isinstance(module, nn.Conv2d)\n          or isinstance(module, nn.Linear)\n          or isinstance(module, nn.Embedding)):\n        if self.init == 'ortho':\n          init.orthogonal_(module.weight)\n        elif self.init == 'N02':\n          init.normal_(module.weight, 0, 0.02)\n        elif self.init in ['glorot', 'xavier']:\n          init.xavier_uniform_(module.weight)\n        else:\n          print('Init style not recognized...')\n        self.param_count += sum([p.data.nelement() for p in module.parameters()])\n    print('Param count for G''s initialized parameters: %d' % self.param_count)\n\n  # Note on this forward function: we pass in a y vector which has\n  # already been passed through G.shared to enable easy class-wise\n  # interpolation later. If we passed in the one-hot and then ran it through\n  # G.shared in this forward function, it would be harder to handle.","16":"Similar lines in 2 files\n==BigGAN:394\n==BigGANdeep:478\n    for index, blocklist in enumerate(self.blocks):\n      for block in blocklist:\n        h = block(h)\n    # Apply global sum pooling as in SN-GAN\n    h = torch.sum(self.activation(h), [2, 3])\n    # Get initial class-unconditional output\n    out = self.linear(h)\n    # Get projection of final featureset onto class vectors and add to evidence\n    out = out + torch.sum(self.embed(y) * h, 1, keepdim=True)\n    return out\n\n# Parallelized G_D to minimize cross-gpu communication\n# Without this, Generator outputs would get all-gathered and then rebroadcast.\nclass G_D(nn.Module):\n  def __init__(self, G, D):\n    super(G_D, self).__init__()\n    self.G = G\n    self.D = D\n\n  def forward(self, z, gy, x=None, dy=None, train_G=False, return_G_z=False,\n              split_D=False):\n    # If training G, enable grad tape\n    with torch.set_grad_enabled(train_G):\n      # Get Generator output given noise\n      G_z = self.G(z, self.G.shared(gy))\n      # Cast as necessary\n      if self.G.fp16 and not self.D.fp16:\n        G_z = G_z.float()\n      if self.D.fp16 and not self.G.fp16:\n        G_z = G_z.half()\n    # Split_D means to run D once with real data and once with fake,\n    # rather than concatenating along the batch dimension.\n    if split_D:\n      D_fake = self.D(G_z, gy)\n      if x is not None:\n        D_real = self.D(x, dy)\n        return D_fake, D_real\n      else:\n        if return_G_z:\n          return D_fake, G_z\n        else:\n          return D_fake\n    # If real data is provided, concatenate it with the Generator's output\n    # along the batch dimension for improved efficiency.\n    else:\n      D_input = torch.cat([G_z, x], 0) if x is not None else G_z\n      D_class = torch.cat([gy, dy], 0) if dy is not None else gy\n      # Get Discriminator output\n      D_out = self.D(D_input, D_class)\n      if x is not None:\n        return torch.split(D_out, [G_z.shape[0], x.shape[0]]) # D_fake, D_real\n      else:\n        if return_G_z:\n          return D_out, G_z\n        else:\n          return D_out","17":"Similar lines in 2 files\n==BigGAN:342\n==BigGANdeep:426\n      if self.arch['attention'][self.arch['resolution'][index]]:\n        print('Adding attention layer in D at resolution %d' % self.arch['resolution'][index])\n        self.blocks[-1] += [layers.Attention(self.arch['out_channels'][index],\n                                             self.which_conv)]\n    # Turn self.blocks into a ModuleList so that it's all properly registered.\n    self.blocks = nn.ModuleList([nn.ModuleList(block) for block in self.blocks])\n    # Linear output layer. The output dimension is typically 1, but may be\n    # larger if we're e.g. turning this into a VAE with an inference output\n    self.linear = self.which_linear(self.arch['out_channels'][-1], output_dim)\n    # Embedding for projection discrimination\n    self.embed = self.which_embedding(self.n_classes, self.arch['out_channels'][-1])\n\n    # Initialize weights\n    if not skip_init:\n      self.init_weights()\n\n    # Set up optimizer\n    self.lr, self.B1, self.B2, self.adam_eps = D_lr, D_B1, D_B2, adam_eps\n    if D_mixed_precision:\n      print('Using fp16 adam in D...')\n      import utils\n      self.optim = utils.Adam16(params=self.parameters(), lr=self.lr,\n                             betas=(self.B1, self.B2), weight_decay=0, eps=self.adam_eps)\n    else:\n      self.optim = optim.Adam(params=self.parameters(), lr=self.lr,\n                             betas=(self.B1, self.B2), weight_decay=0, eps=self.adam_eps)\n    # LR scheduling, left here for forward compatibility\n    # self.lr_sched = {'itr' : 0}# if self.progressive else {}\n    # self.j = 0\n\n  # Initialize\n  def init_weights(self):\n    self.param_count = 0\n    for module in self.modules():\n      if (isinstance(module, nn.Conv2d)\n          or isinstance(module, nn.Linear)\n          or isinstance(module, nn.Embedding)):\n        if self.init == 'ortho':\n          init.orthogonal_(module.weight)\n        elif self.init == 'N02':\n          init.normal_(module.weight, 0, 0.02)\n        elif self.init in ['glorot', 'xavier']:\n          init.xavier_uniform_(module.weight)\n        else:\n          print('Init style not recognized...')\n        self.param_count += sum([p.data.nelement() for p in module.parameters()])\n    print('Param count for D''s initialized parameters: %d' % self.param_count)\n\n  def forward(self, x, y=None):\n    # Run input conv","18":"Similar lines in 2 files\n==BigGAN:69\n==BigGANdeep:113\n    self.dim_z = dim_z\n    # The initial spatial dimensions\n    self.bottom_width = bottom_width\n    # Resolution of the output\n    self.resolution = resolution\n    # Kernel size?\n    self.kernel_size = G_kernel_size\n    # Attention?\n    self.attention = G_attn\n    # number of classes, for use in categorical conditional generation\n    self.n_classes = n_classes\n    # Use shared embeddings?\n    self.G_shared = G_shared\n    # Dimensionality of the shared embedding? Unused if not using G_shared\n    self.shared_dim = shared_dim if shared_dim > 0 else dim_z\n    # Hierarchical latent space?\n    self.hier = hier\n    # Cross replica batchnorm?\n    self.cross_replica = cross_replica\n    # Use my batchnorm?\n    self.mybn = mybn\n    # nonlinearity for residual blocks\n    self.activation = G_activation\n    # Initialization style\n    self.init = G_init\n    # Parameterization style\n    self.G_param = G_param\n    # Normalization style\n    self.norm_style = norm_style\n    # Epsilon for BatchNorm?\n    self.BN_eps = BN_eps\n    # Epsilon for Spectral Norm?\n    self.SN_eps = SN_eps\n    # fp16?\n    self.fp16 = G_fp16\n    # Architecture dict\n    self.arch = G_arch(self.ch, self.attention)[resolution]\n\n    # If using hierarchical latents, adjust z","19":"Similar lines in 2 files\n==BigGAN:296\n==BigGANdeep:374\n    self.resolution = resolution\n    # Kernel size\n    self.kernel_size = D_kernel_size\n    # Attention?\n    self.attention = D_attn\n    # Number of classes\n    self.n_classes = n_classes\n    # Activation\n    self.activation = D_activation\n    # Initialization style\n    self.init = D_init\n    # Parameterization style\n    self.D_param = D_param\n    # Epsilon for Spectral Norm?\n    self.SN_eps = SN_eps\n    # Fp16?\n    self.fp16 = D_fp16\n    # Architecture\n    self.arch = D_arch(self.ch, self.attention)[resolution]\n\n    # Which convs, batchnorms, and linear layers to use\n    # No option to turn off SN in D right now","20":"Similar lines in 2 files\n==BigGAN:119\n==BigGANdeep:153\n    if self.G_param == 'SN':\n      self.which_conv = functools.partial(layers.SNConv2d,\n                          kernel_size=3, padding=1,\n                          num_svs=num_G_SVs, num_itrs=num_G_SV_itrs,\n                          eps=self.SN_eps)\n      self.which_linear = functools.partial(layers.SNLinear,\n                          num_svs=num_G_SVs, num_itrs=num_G_SV_itrs,\n                          eps=self.SN_eps)\n    else:\n      self.which_conv = functools.partial(nn.Conv2d, kernel_size=3, padding=1)\n      self.which_linear = nn.Linear\n\n    # We use a non-spectral-normed embedding here regardless;\n    # For some reason applying SN to G's embedding seems to randomly cripple G\n    self.which_embedding = nn.Embedding\n    bn_linear = (functools.partial(self.which_linear, bias=False) if self.G_shared\n                 else self.which_embedding)\n    self.which_bn = functools.partial(layers.ccbn,\n                          which_linear=bn_linear,\n                          cross_replica=self.cross_replica,\n                          mybn=self.mybn,","21":"Similar lines in 2 files\n==BigGAN:34\n==BigGANdeep:76\n               'upsample' : [True] * 5,\n               'resolution' : [8, 16, 32, 64, 128],\n               'attention' : {2**i: (2**i in [int(item) for item in attention.split('_')])\n                              for i in range(3,8)}}\n  arch[64]  = {'in_channels' :  [ch * item for item in [16, 16, 8, 4]],\n               'out_channels' : [ch * item for item in [16, 8, 4, 2]],\n               'upsample' : [True] * 4,\n               'resolution' : [8, 16, 32, 64],\n               'attention' : {2**i: (2**i in [int(item) for item in attention.split('_')])\n                              for i in range(3,7)}}\n  arch[32]  = {'in_channels' :  [ch * item for item in [4, 4, 4]],\n               'out_channels' : [ch * item for item in [4, 4, 4]],\n               'upsample' : [True] * 3,\n               'resolution' : [8, 16, 32],\n               'attention' : {2**i: (2**i in [int(item) for item in attention.split('_')])\n                              for i in range(3,6)}}\n\n  return arch\n\nclass Generator(nn.Module):","22":"Similar lines in 2 files\n==sample:2\n==train:10\nimport functools\nimport math\nimport numpy as np\nfrom tqdm import tqdm, trange\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn import Parameter as P\nimport torchvision\n\n# Import my stuff\nimport inception_utils\nimport utils\nimport losses","23":"Similar lines in 2 files\n==BigGAN:0\n==BigGANdeep:0\nimport numpy as np\nimport math\nimport functools\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn import Parameter as P\n\nimport layers\nfrom sync_batchnorm import SynchronizedBatchNorm2d as SyncBatchNorm2d\n\n# BigGAN-deep: uses a different resblock and pattern\n\n\n# Architectures for G","24":"Similar lines in 2 files\n==BigGAN:318\n==BigGANdeep:397\n    if self.D_param == 'SN':\n      self.which_conv = functools.partial(layers.SNConv2d,\n                          kernel_size=3, padding=1,\n                          num_svs=num_D_SVs, num_itrs=num_D_SV_itrs,\n                          eps=self.SN_eps)\n      self.which_linear = functools.partial(layers.SNLinear,\n                          num_svs=num_D_SVs, num_itrs=num_D_SV_itrs,\n                          eps=self.SN_eps)\n      self.which_embedding = functools.partial(layers.SNEmbedding,\n                              num_svs=num_D_SVs, num_itrs=num_D_SV_itrs,\n                              eps=self.SN_eps)\n    # Prepare model\n    # self.blocks is a doubly-nested list of modules, the outer loop intended\n    # to be over blocks at a given resolution (resblocks and\/or self-attention)","25":"Similar lines in 2 files\n==BigGAN:55\n==BigGANdeep:97\n               G_kernel_size=3, G_attn='64', n_classes=1000,\n               num_G_SVs=1, num_G_SV_itrs=1,\n               G_shared=True, shared_dim=0, hier=False,\n               cross_replica=False, mybn=False,\n               G_activation=nn.ReLU(inplace=False),\n               G_lr=5e-5, G_B1=0.0, G_B2=0.999, adam_eps=1e-8,\n               BN_eps=1e-5, SN_eps=1e-12, G_mixed_precision=False, G_fp16=False,\n               G_init='ortho', skip_init=False, no_optim=False,\n               G_param='SN', norm_style='bn',\n               **kwargs):\n    super(Generator, self).__init__()\n    # Channel width mulitplier\n    self.ch = G_ch\n    # Number of resblocks per stage","26":"Similar lines in 2 files\n==BigGAN:285\n==BigGANdeep:361\n               D_kernel_size=3, D_attn='64', n_classes=1000,\n               num_D_SVs=1, num_D_SV_itrs=1, D_activation=nn.ReLU(inplace=False),\n               D_lr=2e-4, D_B1=0.0, D_B2=0.999, adam_eps=1e-8,\n               SN_eps=1e-12, output_dim=1, D_mixed_precision=False, D_fp16=False,\n               D_init='ortho', skip_init=False, D_param='SN', **kwargs):\n    super(Discriminator, self).__init__()\n    # Width multiplier\n    self.ch = D_ch\n    # Use Wide D as in BigGAN and SA-GAN or skinny D as in SN-GAN?\n    self.D_wide = D_wide\n    # Resolution","27":"Similar lines in 2 files\n==BigGAN:141\n==BigGANdeep:175\n                                      else self.n_classes),\n                          norm_style=self.norm_style,\n                          eps=self.BN_eps)\n\n\n    # Prepare model\n    # If not using shared embeddings, self.shared is just a passthrough\n    self.shared = (self.which_embedding(n_classes, self.shared_dim) if G_shared\n                    else layers.identity())\n    # First linear layer","28":"Similar lines in 2 files\n==inception_tf13:129\n==make_hdf5:101\ndef main():\n  # parse command line and run\n  parser = prepare_parser()\n  config = vars(parser.parse_args())\n  print(config)\n  run(config)\n\nif __name__ == '__main__':\n  main()","29":"Similar lines in 2 files\n==sample:54\n==train:58\n  torch.backends.cudnn.benchmark = True\n\n  # Import the model--this line allows us to dynamically select different files.\n  model = __import__(config['model'])\n  experiment_name = (config['experiment_name'] if config['experiment_name']\n                       else utils.name_from_config(config))\n  print('Experiment name is %s' % experiment_name)\n","30":"Similar lines in 2 files\n==BigGAN:276\n==BigGANdeep:352\n               'downsample' : [True, True, False, False],\n               'resolution' : [16, 16, 16, 16],\n               'attention' : {2**i: 2**i in [int(item) for item in attention.split('_')]\n                              for i in range(2,6)}}\n  return arch\n\nclass Discriminator(nn.Module):\n","31":"Similar lines in 3 files\n==calculate_inception_moments:81\n==inception_tf13:129\n==make_hdf5:101\ndef main():\n  # parse command line\n  parser = prepare_parser()\n  config = vars(parser.parse_args())\n  print(config)\n  run(config)\n","32":"Similar lines in 3 files\n==BigGAN:4\n==BigGANdeep:4\n==layers:4\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn import Parameter as P\n","33":"Similar lines in 2 files\n==BigGAN:26\n==BigGANdeep:68\n  arch[256] = {'in_channels' :  [ch * item for item in [16, 16, 8, 8, 4, 2]],\n               'out_channels' : [ch * item for item in [16,  8, 8, 4, 2, 1]],\n               'upsample' : [True] * 6,\n               'resolution' : [8, 16, 32, 64, 128, 256],\n               'attention' : {2**i: (2**i in [int(item) for item in attention.split('_')])\n                              for i in range(3,9)}}\n  arch[128] = {'in_channels' :  [ch * item for item in [16, 16, 8, 4, 2]],","34":"Similar lines in 4 files\n==inception_tf13:132\n==make_hdf5:104\n==sample:177\n==train:221\n  config = vars(parser.parse_args())\n  print(config)\n  run(config)\n\nif __name__ == '__main__':\n  main()","35":"Similar lines in 5 files\n==BigGAN:4\n==BigGANdeep:4\n==layers:4\n==sample:8\n==train:16\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn import Parameter as P"},"number":{"0":"W0622","1":"W0622","2":"R1732","3":"R1732","4":"R1732","5":"C1801","6":"W0622","7":"W0102","8":"W0102","9":"W0201","10":"W0201","11":"W0201","12":"W0201","13":"W0201","14":"W0201","15":"R0801","16":"R0801","17":"R0801","18":"R0801","19":"R0801","20":"R0801","21":"R0801","22":"R0801","23":"R0801","24":"R0801","25":"R0801","26":"R0801","27":"R0801","28":"R0801","29":"R0801","30":"R0801","31":"R0801","32":"R0801","33":"R0801","34":"R0801","35":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint","21":"pylint","22":"pylint","23":"pylint","24":"pylint","25":"pylint","26":"pylint","27":"pylint","28":"pylint","29":"pylint","30":"pylint","31":"pylint","32":"pylint","33":"pylint","34":"pylint","35":"pylint"},"lines_amount":{"0":363,"1":363,"2":363,"3":363,"4":138,"5":310,"6":459,"7":1194,"8":1194,"9":1194,"10":1194,"11":1194,"12":1194,"13":1194,"14":1194,"15":1194,"16":1194,"17":1194,"18":1194,"19":1194,"20":1194,"21":1194,"22":1194,"23":1194,"24":1194,"25":1194,"26":1194,"27":1194,"28":1194,"29":1194,"30":1194,"31":1194,"32":1194,"33":1194,"34":1194,"35":1194},"commit":{"0":"98459431a5d618d644d54cd1e9fceb1e5045648d","1":"98459431a5d618d644d54cd1e9fceb1e5045648d","2":"98459431a5d618d644d54cd1e9fceb1e5045648d","3":"98459431a5d618d644d54cd1e9fceb1e5045648d","4":"98459431a5d618d644d54cd1e9fceb1e5045648d","5":"98459431a5d618d644d54cd1e9fceb1e5045648d","6":"98459431a5d618d644d54cd1e9fceb1e5045648d","7":"98459431a5d618d644d54cd1e9fceb1e5045648d","8":"98459431a5d618d644d54cd1e9fceb1e5045648d","9":"98459431a5d618d644d54cd1e9fceb1e5045648d","10":"98459431a5d618d644d54cd1e9fceb1e5045648d","11":"98459431a5d618d644d54cd1e9fceb1e5045648d","12":"98459431a5d618d644d54cd1e9fceb1e5045648d","13":"98459431a5d618d644d54cd1e9fceb1e5045648d","14":"98459431a5d618d644d54cd1e9fceb1e5045648d","15":"98459431a5d618d644d54cd1e9fceb1e5045648d","16":"98459431a5d618d644d54cd1e9fceb1e5045648d","17":"98459431a5d618d644d54cd1e9fceb1e5045648d","18":"98459431a5d618d644d54cd1e9fceb1e5045648d","19":"98459431a5d618d644d54cd1e9fceb1e5045648d","20":"98459431a5d618d644d54cd1e9fceb1e5045648d","21":"98459431a5d618d644d54cd1e9fceb1e5045648d","22":"98459431a5d618d644d54cd1e9fceb1e5045648d","23":"98459431a5d618d644d54cd1e9fceb1e5045648d","24":"98459431a5d618d644d54cd1e9fceb1e5045648d","25":"98459431a5d618d644d54cd1e9fceb1e5045648d","26":"98459431a5d618d644d54cd1e9fceb1e5045648d","27":"98459431a5d618d644d54cd1e9fceb1e5045648d","28":"98459431a5d618d644d54cd1e9fceb1e5045648d","29":"98459431a5d618d644d54cd1e9fceb1e5045648d","30":"98459431a5d618d644d54cd1e9fceb1e5045648d","31":"98459431a5d618d644d54cd1e9fceb1e5045648d","32":"98459431a5d618d644d54cd1e9fceb1e5045648d","33":"98459431a5d618d644d54cd1e9fceb1e5045648d","34":"98459431a5d618d644d54cd1e9fceb1e5045648d","35":"98459431a5d618d644d54cd1e9fceb1e5045648d"},"repo":{"0":"ajbrock\/BigGAN-PyTorch","1":"ajbrock\/BigGAN-PyTorch","2":"ajbrock\/BigGAN-PyTorch","3":"ajbrock\/BigGAN-PyTorch","4":"ajbrock\/BigGAN-PyTorch","5":"ajbrock\/BigGAN-PyTorch","6":"ajbrock\/BigGAN-PyTorch","7":"ajbrock\/BigGAN-PyTorch","8":"ajbrock\/BigGAN-PyTorch","9":"ajbrock\/BigGAN-PyTorch","10":"ajbrock\/BigGAN-PyTorch","11":"ajbrock\/BigGAN-PyTorch","12":"ajbrock\/BigGAN-PyTorch","13":"ajbrock\/BigGAN-PyTorch","14":"ajbrock\/BigGAN-PyTorch","15":"ajbrock\/BigGAN-PyTorch","16":"ajbrock\/BigGAN-PyTorch","17":"ajbrock\/BigGAN-PyTorch","18":"ajbrock\/BigGAN-PyTorch","19":"ajbrock\/BigGAN-PyTorch","20":"ajbrock\/BigGAN-PyTorch","21":"ajbrock\/BigGAN-PyTorch","22":"ajbrock\/BigGAN-PyTorch","23":"ajbrock\/BigGAN-PyTorch","24":"ajbrock\/BigGAN-PyTorch","25":"ajbrock\/BigGAN-PyTorch","26":"ajbrock\/BigGAN-PyTorch","27":"ajbrock\/BigGAN-PyTorch","28":"ajbrock\/BigGAN-PyTorch","29":"ajbrock\/BigGAN-PyTorch","30":"ajbrock\/BigGAN-PyTorch","31":"ajbrock\/BigGAN-PyTorch","32":"ajbrock\/BigGAN-PyTorch","33":"ajbrock\/BigGAN-PyTorch","34":"ajbrock\/BigGAN-PyTorch","35":"ajbrock\/BigGAN-PyTorch"}}
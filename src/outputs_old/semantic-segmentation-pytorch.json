{"type":{"0":"C","1":"R","2":"R","3":"R","4":"R","5":"R","6":"R","7":"R","8":"R","9":"R","10":"R","11":"R","12":"R","13":"R","14":"R","15":"R","16":"R","17":"R","18":"R","19":"R","20":"R"},"module":{"0":"test","1":"train","2":"train","3":"train","4":"train","5":"train","6":"train","7":"train","8":"train","9":"train","10":"train","11":"train","12":"train","13":"train","14":"train","15":"train","16":"train","17":"train","18":"train","19":"train","20":"train"},"obj":{"0":"","1":"","2":"","3":"","4":"","5":"","6":"","7":"","8":"","9":"","10":"","11":"","12":"","13":"","14":"","15":"","16":"","17":"","18":"","19":"","20":""},"lnum":{"0":192,"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"17":1,"18":1,"19":1,"20":1},"col":{"0":11,"1":0,"2":0,"3":0,"4":0,"5":0,"6":0,"7":0,"8":0,"9":0,"10":0,"11":0,"12":0,"13":0,"14":0,"15":0,"16":0,"17":0,"18":0,"19":0,"20":0},"filename":{"0":"test.py","1":"train.py","2":"train.py","3":"train.py","4":"train.py","5":"train.py","6":"train.py","7":"train.py","8":"train.py","9":"train.py","10":"train.py","11":"train.py","12":"train.py","13":"train.py","14":"train.py","15":"train.py","16":"train.py","17":"train.py","18":"train.py","19":"train.py","20":"train.py"},"symbol":{"0":"len-as-condition","1":"duplicate-code","2":"duplicate-code","3":"duplicate-code","4":"duplicate-code","5":"duplicate-code","6":"duplicate-code","7":"duplicate-code","8":"duplicate-code","9":"duplicate-code","10":"duplicate-code","11":"duplicate-code","12":"duplicate-code","13":"duplicate-code","14":"duplicate-code","15":"duplicate-code","16":"duplicate-code","17":"duplicate-code","18":"duplicate-code","19":"duplicate-code","20":"duplicate-code"},"text":{"0":"Do not use `len(SEQUENCE)` without comparison to determine if a sequence is empty","1":"Similar lines in 2 files\n==eval_multipro:177\n==train:213\n    )\n    parser.add_argument(\n        \"--cfg\",\n        default=\"config\/ade20k-resnet50dilated-ppm_deepsup.yaml\",\n        metavar=\"FILE\",\n        help=\"path to config file\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--gpus\",\n        default=\"0-3\",\n        help=\"gpus to use, e.g. 0-3 or 0,1,2,3\"\n    )\n    parser.add_argument(\n        \"opts\",\n        help=\"Modify config options using the command-line\",\n        default=None,\n        nargs=argparse.REMAINDER,\n    )\n    args = parser.parse_args()\n\n    cfg.merge_from_file(args.cfg)\n    cfg.merge_from_list(args.opts)\n    # cfg.freeze()\n\n    logger = setup_logger(distributed_rank=0)   # TODO\n    logger.info(\"Loaded configuration file {}\".format(args.cfg))\n    logger.info(\"Running with config:\\n{}\".format(cfg))\n\n    # absolute paths of model weights","2":"Similar lines in 2 files\n==eval:164\n==eval_multipro:189\n    )\n    parser.add_argument(\n        \"opts\",\n        help=\"Modify config options using the command-line\",\n        default=None,\n        nargs=argparse.REMAINDER,\n    )\n    args = parser.parse_args()\n\n    cfg.merge_from_file(args.cfg)\n    cfg.merge_from_list(args.opts)\n    # cfg.freeze()\n\n    logger = setup_logger(distributed_rank=0)   # TODO\n    logger.info(\"Loaded configuration file {}\".format(args.cfg))\n    logger.info(\"Running with config:\\n{}\".format(cfg))\n\n    # absolute paths of model weights\n    cfg.MODEL.weights_encoder = os.path.join(\n        cfg.DIR, 'encoder_' + cfg.VAL.checkpoint)\n    cfg.MODEL.weights_decoder = os.path.join(\n        cfg.DIR, 'decoder_' + cfg.VAL.checkpoint)\n    assert os.path.exists(cfg.MODEL.weights_encoder) and \\\n        os.path.exists(cfg.MODEL.weights_decoder), \"checkpoint does not exitst!\"\n\n    if not os.path.isdir(os.path.join(cfg.DIR, \"result\")):\n        os.makedirs(os.path.join(cfg.DIR, \"result\"))\n","3":"Similar lines in 2 files\n==eval:15\n==eval_multipro:16\nfrom mit_semseg.lib.nn import user_scattered_collate, async_copy_to\nfrom mit_semseg.lib.utils import as_numpy\nfrom PIL import Image\nfrom tqdm import tqdm\n\ncolors = loadmat('data\/color150.mat')['colors']\n\n\ndef visualize_result(data, pred, dir_result):\n    (img, seg, info) = data\n\n    # segmentation\n    seg_color = colorEncode(seg, colors)\n\n    # prediction\n    pred_color = colorEncode(pred, colors)\n\n    # aggregate images and save\n    im_vis = np.concatenate((img, seg_color, pred_color),\n                            axis=1).astype(np.uint8)\n\n    img_name = info.split('\/')[-1]\n    Image.fromarray(im_vis).save(os.path.join(dir_result, img_name.replace('.jpg', '.png')))\n\n","4":"Similar lines in 2 files\n==eval:164\n==train:225\n    )\n    parser.add_argument(\n        \"opts\",\n        help=\"Modify config options using the command-line\",\n        default=None,\n        nargs=argparse.REMAINDER,\n    )\n    args = parser.parse_args()\n\n    cfg.merge_from_file(args.cfg)\n    cfg.merge_from_list(args.opts)\n    # cfg.freeze()\n\n    logger = setup_logger(distributed_rank=0)   # TODO\n    logger.info(\"Loaded configuration file {}\".format(args.cfg))\n    logger.info(\"Running with config:\\n{}\".format(cfg))\n\n    # absolute paths of model weights","5":"Similar lines in 2 files\n==eval:143\n==eval_multipro:168\n    print('Evaluation Done!')\n\n\nif __name__ == '__main__':\n    assert LooseVersion(torch.__version__) >= LooseVersion('0.4.0'), \\\n        'PyTorch>=0.4.0 is required'\n\n    parser = argparse.ArgumentParser(\n        description=\"PyTorch Semantic Segmentation Validation\"\n    )\n    parser.add_argument(\n        \"--cfg\",\n        default=\"config\/ade20k-resnet50dilated-ppm_deepsup.yaml\",\n        metavar=\"FILE\",\n        help=\"path to config file\",\n        type=str,\n    )\n    parser.add_argument(","6":"Similar lines in 4 files\n==eval:164\n==eval_multipro:189\n==test:157\n==train:225\n    )\n    parser.add_argument(\n        \"opts\",\n        help=\"Modify config options using the command-line\",\n        default=None,\n        nargs=argparse.REMAINDER,\n    )\n    args = parser.parse_args()\n\n    cfg.merge_from_file(args.cfg)\n    cfg.merge_from_list(args.opts)\n    # cfg.freeze()\n\n    logger = setup_logger(distributed_rank=0)   # TODO\n    logger.info(\"Loaded configuration file {}\".format(args.cfg))\n    logger.info(\"Running with config:\\n{}\".format(cfg))\n","7":"Similar lines in 2 files\n==eval:110\n==eval_multipro:100\n    net_encoder = ModelBuilder.build_encoder(\n        arch=cfg.MODEL.arch_encoder.lower(),\n        fc_dim=cfg.MODEL.fc_dim,\n        weights=cfg.MODEL.weights_encoder)\n    net_decoder = ModelBuilder.build_decoder(\n        arch=cfg.MODEL.arch_decoder.lower(),\n        fc_dim=cfg.MODEL.fc_dim,\n        num_class=cfg.DATASET.num_class,\n        weights=cfg.MODEL.weights_decoder,\n        use_softmax=True)\n\n    crit = nn.NLLLoss(ignore_index=-1)\n\n    segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n","8":"Similar lines in 2 files\n==eval:152\n==test:144\n    )\n    parser.add_argument(\n        \"--cfg\",\n        default=\"config\/ade20k-resnet50dilated-ppm_deepsup.yaml\",\n        metavar=\"FILE\",\n        help=\"path to config file\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--gpu\",\n        default=0,","9":"Similar lines in 2 files\n==eval:59\n==test:66\n            scores = torch.zeros(1, cfg.DATASET.num_class, segSize[0], segSize[1])\n            scores = async_copy_to(scores, gpu)\n\n            for img in img_resized_list:\n                feed_dict = batch_data.copy()\n                feed_dict['img_data'] = img\n                del feed_dict['img_ori']\n                del feed_dict['info']\n                feed_dict = async_copy_to(feed_dict, gpu)\n\n                # forward pass","10":"Similar lines in 2 files\n==eval:116\n==test:103\n        fc_dim=cfg.MODEL.fc_dim,\n        num_class=cfg.DATASET.num_class,\n        weights=cfg.MODEL.weights_decoder,\n        use_softmax=True)\n\n    crit = nn.NLLLoss(ignore_index=-1)\n\n    segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n\n    # Dataset and Loader","11":"Similar lines in 2 files\n==eval_multipro:177\n==test:144\n    )\n    parser.add_argument(\n        \"--cfg\",\n        default=\"config\/ade20k-resnet50dilated-ppm_deepsup.yaml\",\n        metavar=\"FILE\",\n        help=\"path to config file\",\n        type=str,\n    )\n    parser.add_argument(","12":"Similar lines in 2 files\n==eval_multipro:106\n==test:103\n        fc_dim=cfg.MODEL.fc_dim,\n        num_class=cfg.DATASET.num_class,\n        weights=cfg.MODEL.weights_decoder,\n        use_softmax=True)\n\n    crit = nn.NLLLoss(ignore_index=-1)\n\n    segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n","13":"Similar lines in 3 files\n==eval:152\n==test:144\n==train:213\n    )\n    parser.add_argument(\n        \"--cfg\",\n        default=\"config\/ade20k-resnet50dilated-ppm_deepsup.yaml\",\n        metavar=\"FILE\",\n        help=\"path to config file\",\n        type=str,\n    )\n    parser.add_argument(","14":"Similar lines in 3 files\n==eval:110\n==eval_multipro:100\n==train:143\n    net_encoder = ModelBuilder.build_encoder(\n        arch=cfg.MODEL.arch_encoder.lower(),\n        fc_dim=cfg.MODEL.fc_dim,\n        weights=cfg.MODEL.weights_encoder)\n    net_decoder = ModelBuilder.build_decoder(\n        arch=cfg.MODEL.arch_decoder.lower(),\n        fc_dim=cfg.MODEL.fc_dim,\n        num_class=cfg.DATASET.num_class,","15":"Similar lines in 2 files\n==eval:133\n==test:119\n        shuffle=False,\n        collate_fn=user_scattered_collate,\n        num_workers=5,\n        drop_last=True)\n\n    segmentation_module.cuda()\n\n    # Main loop","16":"Similar lines in 2 files\n==eval:3\n==test:2\nimport argparse\nfrom distutils.version import LooseVersion\n# Numerical libs\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom scipy.io import loadmat","17":"Similar lines in 2 files\n==eval:87\n==eval_multipro:75\n        if cfg.VAL.visualize:\n            visualize_result(\n                (batch_data['img_ori'], seg_label, batch_data['info']),\n                pred,\n                os.path.join(cfg.DIR, 'result')\n            )\n","18":"Similar lines in 2 files\n==eval:7\n==eval_multipro:8\nimport torch\nimport torch.nn as nn\nfrom scipy.io import loadmat\n# Our libs\nfrom mit_semseg.config import cfg\nfrom mit_semseg.dataset import ValDataset\nfrom mit_semseg.models import ModelBuilder, SegmentationModule","19":"Similar lines in 2 files\n==eval:130\n==eval_multipro:92\n    loader_val = torch.utils.data.DataLoader(\n        dataset_val,\n        batch_size=cfg.VAL.batch_size,\n        shuffle=False,\n        collate_fn=user_scattered_collate,","20":"Similar lines in 3 files\n==eval:62\n==eval_multipro:55\n==test:69\n            for img in img_resized_list:\n                feed_dict = batch_data.copy()\n                feed_dict['img_data'] = img\n                del feed_dict['img_ori']\n                del feed_dict['info']"},"number":{"0":"C1801","1":"R0801","2":"R0801","3":"R0801","4":"R0801","5":"R0801","6":"R0801","7":"R0801","8":"R0801","9":"R0801","10":"R0801","11":"R0801","12":"R0801","13":"R0801","14":"R0801","15":"R0801","16":"R0801","17":"R0801","18":"R0801","19":"R0801","20":"R0801"},"linter":{"0":"pylint","1":"pylint","2":"pylint","3":"pylint","4":"pylint","5":"pylint","6":"pylint","7":"pylint","8":"pylint","9":"pylint","10":"pylint","11":"pylint","12":"pylint","13":"pylint","14":"pylint","15":"pylint","16":"pylint","17":"pylint","18":"pylint","19":"pylint","20":"pylint"},"lines_amount":{"0":199,"1":274,"2":274,"3":274,"4":274,"5":274,"6":274,"7":274,"8":274,"9":274,"10":274,"11":274,"12":274,"13":274,"14":274,"15":274,"16":274,"17":274,"18":274,"19":274,"20":274},"commit":{"0":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","1":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","2":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","3":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","4":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","5":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","6":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","7":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","8":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","9":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","10":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","11":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","12":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","13":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","14":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","15":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","16":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","17":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","18":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","19":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b","20":"8f27c9b97d2ca7c6e05333d5766d144bf7d8c31b"},"repo":{"0":"CSAILVision\/semantic-segmentation-pytorch","1":"CSAILVision\/semantic-segmentation-pytorch","2":"CSAILVision\/semantic-segmentation-pytorch","3":"CSAILVision\/semantic-segmentation-pytorch","4":"CSAILVision\/semantic-segmentation-pytorch","5":"CSAILVision\/semantic-segmentation-pytorch","6":"CSAILVision\/semantic-segmentation-pytorch","7":"CSAILVision\/semantic-segmentation-pytorch","8":"CSAILVision\/semantic-segmentation-pytorch","9":"CSAILVision\/semantic-segmentation-pytorch","10":"CSAILVision\/semantic-segmentation-pytorch","11":"CSAILVision\/semantic-segmentation-pytorch","12":"CSAILVision\/semantic-segmentation-pytorch","13":"CSAILVision\/semantic-segmentation-pytorch","14":"CSAILVision\/semantic-segmentation-pytorch","15":"CSAILVision\/semantic-segmentation-pytorch","16":"CSAILVision\/semantic-segmentation-pytorch","17":"CSAILVision\/semantic-segmentation-pytorch","18":"CSAILVision\/semantic-segmentation-pytorch","19":"CSAILVision\/semantic-segmentation-pytorch","20":"CSAILVision\/semantic-segmentation-pytorch"}}